{
  "hash": "ddb8b4e5371918479b522d46f244847c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Space-Time Prediction of Bike Share Demand: Philadelphia Indego\"\nauthor: \"Christine, Demi\"\ndate: \"2025-12-01\"\noutput: \n  html_document:\n    toc: true\n    toc_float: true\n    code_folding: show\n    code_download: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n------------------------------------------------------------------------\n\n# PART 1: Compare 2024 Q3 with 2025 Q1\n\n## 1. Setup\n\n### 1.1 Load libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Core tidyverse\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Spatial data\nlibrary(sf)\nlibrary(tigris)\n\n# Census data\nlibrary(tidycensus)\n\n# Weather data\nlibrary(riem)  # For Philadelphia weather from ASOS stations\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(ggplot2)\n\n# here!\nlibrary(here)\n# Get rid of scientific notation. We gotta look good!\noptions(scipen = 999)\n\nSys.setlocale(\"LC_TIME\", \"English\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"English_United States.1252\"\n```\n\n\n:::\n:::\n\n\n### 1.2 Define Themes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n:::\n\n\n### 1.3 Set Census API Key\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_api_key(\"42bf8a20a3df1def380f330cf7edad0dd5842ce6\", overwrite = TRUE, install = TRUE)\n```\n:::\n\n\n\n\n------------------------------------------------------------------------\n\n## 2. Data Import & Preparation\n\n### 2.1 Load Indego Trip Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read Q3 2024 data\nindego_q3<- read_csv(here(\"assignments/assignment_5/indego-trips-2024-q3.csv\"))\n# Read Q1 2025 data\nindego_q1<- read_csv(here(\"assignments/assignment_5/indego-trips-2025-q1.csv\"))\n```\n:::\n\n\n#### Why Q3?\n- **Extreme Seasonal Variation:** This selection allows us to compare \"peak season\" (Summer) against \"off-peak season\" (Winter). Comparing to Q1, Q3 represents the warmest months with ideal biking conditions and high leisure activity.  \n- **Model Generalizability:** By training models on two drastically different quarters, we can test whether our predictive features (such as spatial lags or rush-hour indicators) remain robust across different volume levels.  \n- **Behavioral Shifts:** Summer data is more likely to be diverse, which likely includes a mix of commuters, tourists, and recreational riders, whereas winter data isolates the \"core user\" base—resilient commuters who rely on Indego regardless of the weather.\n\n### 2.2 Examine the Data Structure\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego_q3$start_time_obj <- mdy_hm(indego_q3$start_time)\nindego_q1$start_time_obj <- mdy_hm(indego_q1$start_time)\n\ncomparison_df <- data.frame(\n  Metric = c(\n    \"Total Trips\", \n    \"Date Range\", \n    \"Unique Start Stations\",\n    \"Trip: One Way\",\n    \"Trip: Round Trip\",\n    \"Bike: Standard\",\n    \"Bike: Electric\",\n    \"Passholder: Day Pass\",\n    \"Passholder: Walk-up\"\n  ),\n  \n  Q3_2024 = c(\n    nrow(indego_q3),\n    paste(format(min(indego_q3$start_time_obj), \"%Y-%m-%d\"), \"to\", format(max(indego_q3$start_time_obj), \"%Y-%m-%d\")),\n    length(unique(indego_q3$start_station)),\n    sum(indego_q3$trip_route_category == \"One Way\", na.rm = TRUE),\n    sum(indego_q3$trip_route_category == \"Round Trip\", na.rm = TRUE),\n    sum(indego_q3$bike_type == \"standard\", na.rm = TRUE),\n    sum(indego_q3$bike_type == \"electric\", na.rm = TRUE),\n    sum(indego_q3$passholder_type == \"Day Pass\", na.rm = TRUE),\n    sum(indego_q3$passholder_type == \"Walk-up\", na.rm = TRUE)\n  ),\n  \n  Q1_2025 = c(\n    nrow(indego_q1),\n    paste(format(min(indego_q1$start_time_obj), \"%Y-%m-%d\"), \"to\", format(max(indego_q1$start_time_obj), \"%Y-%m-%d\")),\n    length(unique(indego_q1$start_station)),\n    sum(indego_q1$trip_route_category == \"One Way\", na.rm = TRUE),\n    sum(indego_q1$trip_route_category == \"Round Trip\", na.rm = TRUE),\n    sum(indego_q1$bike_type == \"standard\", na.rm = TRUE),\n    sum(indego_q1$bike_type == \"electric\", na.rm = TRUE),\n    sum(indego_q1$passholder_type == \"Day Pass\", na.rm = TRUE),\n    sum(indego_q1$passholder_type == \"Walk-up\", na.rm = TRUE)\n  )\n)\n\nkable(comparison_df, caption = \"Comparison of Indego Q3 2024 vs Q1 2025\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Comparison of Indego Q3 2024 vs Q1 2025\n\n|Metric                |Q3_2024                  |Q1_2025                  |\n|:---------------------|:------------------------|:------------------------|\n|Total Trips           |408408                   |201588                   |\n|Date Range            |2024-07-01 to 2024-09-30 |2025-01-01 to 2025-03-31 |\n|Unique Start Stations |261                      |265                      |\n|Trip: One Way         |380939                   |190792                   |\n|Trip: Round Trip      |27469                    |10796                    |\n|Bike: Standard        |171569                   |72027                    |\n|Bike: Electric        |236839                   |129561                   |\n|Passholder: Day Pass  |22885                    |5494                     |\n|Passholder: Walk-up   |13308                    |10419                    |\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# How many trips?\ncat(\"Total trips in Q3 2024:\", nrow(indego_q3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal trips in Q3 2024: 408408 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Total trips in Q1 2025:\", nrow(indego_q1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal trips in Q1 2025: 201588 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Date range\ncat(\"Q3 Date range:\", \n    format(min(mdy_hm(indego_q3$start_time)), \"%Y-%m-%d\"), \n    \"to\", \n    format(max(mdy_hm(indego_q3$start_time)), \"%Y-%m-%d\"), \n    \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nQ3 Date range: 2024-07-01 to 2024-09-30 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Q1 Date range:\", \n    format(min(mdy_hm(indego_q1$start_time)), \"%Y-%m-%d\"), \n    \"to\", \n    format(max(mdy_hm(indego_q1$start_time)), \"%Y-%m-%d\"), \n    \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nQ1 Date range: 2025-01-01 to 2025-03-31 \n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique stations?\ncat(\"Unique start stations q3:\", length(unique(indego_q3$start_station)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnique start stations q3: 261 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Unique start stations q1:\", length(unique(indego_q1$start_station)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnique start stations q1: 265 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Trip types\ntable(indego_q3$trip_route_category)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   One Way Round Trip \n    380939      27469 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(indego_q1$trip_route_category)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   One Way Round Trip \n    190792      10796 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Passholder types\ntable(indego_q3$passholder_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n Day Pass  Indego30 Indego365   Walk-up \n    22885    239857    132358     13308 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Bike types\ntable(indego_q3$bike_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nelectric standard \n  236839   171569 \n```\n\n\n:::\n:::\n\n\n### 2.3 Create Time Bins\n\n\n::: {.cell}\n\n```{.r .cell-code}\npanel_q3_base <- indego_q3 %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE), \n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n\n\n# Look at temporal features\nhead(panel_q3_base %>% select(start_datetime, interval60, week, dotw, hour, weekend))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  start_datetime      interval60           week dotw   hour weekend\n  <dttm>              <dttm>              <dbl> <ord> <int>   <dbl>\n1 2024-07-01 00:02:00 2024-07-01 00:00:00    27 Mon       0       0\n2 2024-07-01 00:03:00 2024-07-01 00:00:00    27 Mon       0       0\n3 2024-07-01 00:04:00 2024-07-01 00:00:00    27 Mon       0       0\n4 2024-07-01 00:05:00 2024-07-01 00:00:00    27 Mon       0       0\n5 2024-07-01 00:06:00 2024-07-01 00:00:00    27 Mon       0       0\n6 2024-07-01 00:06:00 2024-07-01 00:00:00    27 Mon       0       0\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"2024 Q3 Base Panel:\", format(nrow(panel_q3_base), big.mark = \",\"), \"rows\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2024 Q3 Base Panel: 408,408 rows\n```\n\n\n:::\n\n```{.r .cell-code}\npanel_q1_base <- indego_q1 %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE, locale = \"en_US.UTF-8\"),\n    dotw = wday(interval60, label = TRUE, locale = \"en_US.UTF-8\"),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n# Look at temporal features\nhead(panel_q1_base %>% select(start_datetime, interval60, week, dotw, hour, weekend))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  start_datetime      interval60           week dotw   hour weekend\n  <dttm>              <dttm>              <dbl> <ord> <int>   <dbl>\n1 2025-01-01 00:00:00 2025-01-01 00:00:00     1 Wed       0       0\n2 2025-01-01 00:04:00 2025-01-01 00:00:00     1 Wed       0       0\n3 2025-01-01 00:05:00 2025-01-01 00:00:00     1 Wed       0       0\n4 2025-01-01 00:05:00 2025-01-01 00:00:00     1 Wed       0       0\n5 2025-01-01 00:08:00 2025-01-01 00:00:00     1 Wed       0       0\n6 2025-01-01 00:14:00 2025-01-01 00:00:00     1 Wed       0       0\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"2025 Q1 Base Panel:\", format(nrow(panel_q1_base), big.mark = \",\"), \"rows\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2025 Q1 Base Panel: 201,588 rows\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## 3. Exploratory Analysis\n\n### 3.1 Daily Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Daily trip counts\ndaily_trips_q3 <- panel_q3_base %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\ndaily_trips_q3_plot <- ggplot(daily_trips_q3, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q3 2024\",\n    subtitle = \"Summer demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n\ndaily_trips_q1 <- panel_q1_base %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\ndaily_trips_q1_plot <- ggplot(daily_trips_q1, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q1 2025\",\n    subtitle = \"Winter demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n\nlibrary(patchwork)\ndaily_trips_q3_plot / daily_trips_q1_plot\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/trips_over_time-1.png){width=672}\n:::\n:::\n\n\n**Question:** What patterns do you see? How does ridership change over\ntime?\n\nWe find that...\n\n### 3.2 Hourly Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Average trips by hour and day type\nhourly_patterns_q3 <- panel_q3_base %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nhourly_trips_q3_plot <- ggplot(hourly_patterns_q3, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns in 2024 Q3\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n\nhourly_patterns_q1 <- panel_q1_base %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nhourly_trips_q1_plot <- ggplot(hourly_patterns_q1, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns in 2025 Q1\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n\nhourly_trips_q3_plot / hourly_trips_q1_plot\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/hourly_patterns-1.png){width=672}\n:::\n:::\n\n\n**Question:** When are the peak hours? How do weekends differ from\nweekdays?\n\n------------------------------------------------------------------------\n\n## 4. Get Philadelphia Spatial Context\n\n### 4.1 Load Philadelphia Census Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get Philadelphia census tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |===================                                                   |  28%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |=====================                                                 |  31%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |============================                                          |  41%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |=============================================================         |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================|  99%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n:::\n\n\n### 4.2 Map Philadelphia Context\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Map median income\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Context for understanding bike share demand patterns\"\n  ) +\n  # Stations \n  geom_point(\n    data = indego_q3,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.25, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/map_philly-1.png){width=672}\n:::\n:::\n\n\n### 4.3 Join Census Data to Stations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create sf object for stations\nstations_sf_q3 <- panel_q3_base %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\nstations_sf_q1 <- panel_q1_base %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to get census tract for each station\nstations_census_q3 <- st_join(stations_sf_q3, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\nstations_census_q1 <- st_join(stations_sf_q1, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\n# Look at the result - investigate whether all of the stations joined to census data -- according to the map above there are stations in non-residential tracts.\n\nstations_for_map <- panel_q3_base %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census_q3 %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Add back to trip data\nindego_census_q3 <- panel_q3_base %>%\n  left_join(\n    stations_census_q3 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\nindego_census_q1 <- panel_q1_base %>%\n  left_join(\n    stations_census_q1 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n# Prepare data for visualization\nstations_for_map <- indego_q3 %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census_q3 %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Create the map showing problem stations\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  # Stations with census data (small grey dots)\n  geom_point(\n    data = stations_for_map %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  # Stations WITHOUT census data (red X marks the spot)\n  geom_point(\n    data = stations_for_map %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Indego stations shown (RED = no census data match)\",\n    caption = \"Red X marks indicate stations that didn't join to census tracts\"\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/join_census_to_stations-1.png){width=672}\n:::\n:::\n\n\n### 4.4Dealing with missing data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identify which stations to keep\nvalid_stations_q3 <- stations_census_q3 %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\nvalid_stations_q1 <- stations_census_q1 %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data to valid stations only\nindego_census_q3 <- panel_q3_base %>%\n  filter(start_station %in% valid_stations_q3) %>%\n  left_join(\n    stations_census_q3 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\nindego_census_q1 <- panel_q1_base %>%\n  filter(start_station %in% valid_stations_q1) %>%\n  left_join(\n    stations_census_q1 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n:::\n\n\n## 5. Get Weather Data\n\n### 5.1 Load Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get weather from Philadelphia International Airport (KPHL)\n# This covers Q3 2024: July 1 - September 30\nweather_data_q3 <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2024-07-01\",\n  date_end = \"2024-09-30\"\n)\n\n# Process weather data - FIXED: Aggregating to hourly to prevent duplicate rows\nweather_processed_q3 <- weather_data_q3 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  # FIX: Use summarize instead of distinct to handle multiple readings per hour\n  group_by(interval60) %>%\n  summarize(\n    Temperature = mean(Temperature, na.rm = TRUE),\n    Precipitation = sum(Precipitation, na.rm = TRUE),\n    Wind_Speed = mean(Wind_Speed, na.rm = TRUE)\n  ) %>%\n  ungroup()\n\n# Check for missing hours and interpolate if needed\nweather_complete_q3 <- weather_processed_q3 %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_complete_q3 %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Temperature    Precipitation        Wind_Speed    \n Min.   :55.00   Min.   :0.000000   Min.   : 0.000  \n 1st Qu.:70.00   1st Qu.:0.000000   1st Qu.: 4.000  \n Median :76.00   Median :0.000000   Median : 6.667  \n Mean   :75.96   Mean   :0.009819   Mean   : 6.670  \n 3rd Qu.:81.00   3rd Qu.:0.000000   3rd Qu.: 9.000  \n Max.   :98.00   Max.   :2.750100   Max.   :24.000  \n```\n\n\n:::\n\n```{.r .cell-code}\n# This covers Q1 2025: Jan 1 - Mar 31\nweather_data_q1 <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2025-01-01\",\n  date_end = \"2025-03-31\"\n)\n\n# Process weather data - FIXED: Aggregating to hourly to prevent duplicate rows\nweather_processed_q1 <- weather_data_q1 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  # FIX: Use summarize instead of distinct to handle multiple readings per hour\n  group_by(interval60) %>%\n  summarize(\n    Temperature = mean(Temperature, na.rm = TRUE),\n    Precipitation = sum(Precipitation, na.rm = TRUE),\n    Wind_Speed = mean(Wind_Speed, na.rm = TRUE)\n  ) %>%\n  ungroup()\n\n# Check for missing hours and interpolate if needed\nweather_complete_q1 <- weather_processed_q1 %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_complete_q1 %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Temperature    Precipitation        Wind_Speed    \n Min.   :10.00   Min.   :0.000000   Min.   : 0.000  \n 1st Qu.:30.00   1st Qu.:0.000000   1st Qu.: 5.625  \n Median :37.00   Median :0.000000   Median : 8.000  \n Mean   :38.35   Mean   :0.006774   Mean   : 9.329  \n 3rd Qu.:46.00   3rd Qu.:0.000000   3rd Qu.:13.000  \n Max.   :78.00   Max.   :1.240100   Max.   :30.000  \n```\n\n\n:::\n:::\n\n\n### 5.2 Visualize Weather Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_q3_plot <- ggplot(weather_complete_q3, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - 2024 Q3\",\n    subtitle = \"Summer to early autumn transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n\nweather_q1_plot <- ggplot(weather_complete_q1, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - 2025 Q1\",\n    subtitle = \"Winter to early spring transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n\nweather_q3_plot / weather_q1_plot\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/visualize_weather-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## 6. Create Complete Space-Time Panel\n\n### 6.1 **2024 Q3 Complete Panel**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1.Aggregate Trips to Station-Hour Level\n# Count trips by station-hour\ntrips_panel_q3 <- indego_census_q3 %>%\n  group_by(interval60, start_station, start_lat, start_lon) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2. Create Complete Panel Structure\n# Calculate expected panel size\n# Note: Q3 2024 (July, Aug, Sept) has 92 days. 92 * 24 = 2208 hours.\nn_stations <- length(unique(trips_panel_q3$start_station))\n\n# Manual set Q3 time range to ensure we capture ALL hours, even if no trips happened\nq3_start <- ymd_hms(\"2024-07-01 00:00:00\")\nq3_end   <- ymd_hms(\"2024-09-30 23:00:00\")\nfull_time_seq <- seq(from = q3_start, to = q3_end, by = \"1 hour\")\n\nn_hours <- length(full_time_seq)\nexpected_rows_q3 <- n_stations * n_hours\n\ncat(\"Expected panel rows:\", format(expected_rows_q3, big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExpected panel rows: 532,128 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Current rows in trips_panel:\", format(nrow(trips_panel_q3), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCurrent rows in trips_panel: 193,072 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create complete panel\nstudy_panel_q3 <- expand.grid(\n  interval60 = full_time_seq,               # Use the full explicit time sequence\n  start_station = unique(trips_panel_q3$start_station)\n) %>%\n  # Join trip counts (this will generate NAs for hours with no trips)\n  left_join(trips_panel_q3, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0 (Crucial step!)\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Join attributes back to the main expanded panel\n# Note: We select specific columns from study_panel_q3 to avoid duplicate attribute columns before joining\nstudy_panel_q3 <- study_panel_q3 %>%\n  left_join(\n    stations_census_q3 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n# Verify we have complete panel\ncat(\"Complete panel rows Q3:\", format(nrow(study_panel_q3), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nComplete panel rows Q3: 532,128 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 3. Add Time Features\nstudy_panel_q3 <- study_panel_q3 %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 4. Join Weather Data\nstudy_panel_q3 <- study_panel_q3 %>%\n  left_join(weather_complete_q3, by = \"interval60\")\n\n# Check for missing values\nsummary(study_panel_q3 %>% select(Trip_Count, Temperature, Precipitation))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Trip_Count      Temperature    Precipitation   \n Min.   : 0.000   Min.   :55.00   Min.   :0.0000  \n 1st Qu.: 0.000   1st Qu.:70.00   1st Qu.:0.0000  \n Median : 0.000   Median :76.00   Median :0.0000  \n Mean   : 0.722   Mean   :75.96   Mean   :0.0098  \n 3rd Qu.: 1.000   3rd Qu.:81.00   3rd Qu.:0.0000  \n Max.   :24.000   Max.   :98.00   Max.   :2.7501  \n                  NA's   :5784    NA's   :5784    \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 5. Create Temporal Lag Variables\n# Sort by station and time\nstudy_panel_q3 <- study_panel_q3 %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel_q3 <- study_panel_q3 %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete_q3 <- study_panel_q3 %>%\n  filter(!is.na(lag1day))\n\ncat(\"Final 2024 Q3 Panel:\", format(nrow(study_panel_complete_q3), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFinal 2024 Q3 Panel: 526,344 \n```\n\n\n:::\n:::\n\n\n### 6.2 **2025 Q1 Complete Panel**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1.Aggregate Trips to Station-Hour Level\n# Count trips by station-hour\ntrips_panel_q1 <- indego_census_q1 %>%\n  group_by(interval60, start_station, start_lat, start_lon) %>%\n  summarize(Trip_Count = n(), .groups = \"drop\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2. Create Complete Panel Structure\n# Calculate expected panel size\nn_stations <- length(unique(trips_panel_q1$start_station))\n\n# Manual set Q1 2025 time range to ensure we capture ALL hours\n# Q1 is Jan 1 to Mar 31\nq1_start <- ymd_hms(\"2025-01-01 00:00:00\")\nq1_end   <- ymd_hms(\"2025-03-31 23:00:00\")\n\n# Force generate a complete hourly sequence\nfull_time_seq_q1 <- seq(from = q1_start, to = q1_end, by = \"1 hour\")\n\nn_hours <- length(full_time_seq_q1)\nexpected_rows_q1 <- n_stations * n_hours\n\ncat(\"Expected panel rows Q1:\", format(expected_rows_q1, big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExpected panel rows Q1: 529,200 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Current rows in trips_panel:\", format(nrow(trips_panel_q1), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCurrent rows in trips_panel: 116,718 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create complete panel\nstudy_panel_q1 <- expand.grid(\n  interval60 = full_time_seq_q1,            # Use the full explicit time sequence\n  start_station = unique(trips_panel_q1$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_panel_q1, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0 (Crucial step!)\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Join attributes back to the main expanded panel\n# Use select to ensure we don't duplicate columns\nstudy_panel_q1 <- study_panel_q1 %>%\n  left_join(\n    stations_census_q1 %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n# Verify we have complete panel\ncat(\"Complete panel rows Q1:\", format(nrow(study_panel_q1), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nComplete panel rows Q1: 529,200 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 3. Add Time Features\nstudy_panel_q1 <- study_panel_q1 %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 4. Join Weather Data\nstudy_panel_q1 <- study_panel_q1 %>%\n  left_join(weather_complete_q1, by = \"interval60\")\n\n# Check for missing values\nsummary(study_panel_q1 %>% select(Trip_Count, Temperature, Precipitation))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Trip_Count       Temperature    Precipitation   \n Min.   : 0.0000   Min.   :10.00   Min.   :0.0000  \n 1st Qu.: 0.0000   1st Qu.:30.00   1st Qu.:0.0000  \n Median : 0.0000   Median :37.00   Median :0.0000  \n Mean   : 0.3569   Mean   :38.35   Mean   :0.0068  \n 3rd Qu.: 0.0000   3rd Qu.:46.00   3rd Qu.:0.0000  \n Max.   :26.0000   Max.   :78.00   Max.   :1.2401  \n                   NA's   :5880    NA's   :5880    \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 5. Create Temporal Lag Variables\n# Sort by station and time\nstudy_panel_q1 <- study_panel_q1 %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel_q1 <- study_panel_q1 %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete_q1 <- study_panel_q1 %>%\n  filter(!is.na(lag1day))\n\ncat(\"Final 2025 Q1 Panel:\", format(nrow(study_panel_complete_q1), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFinal 2025 Q1 Panel: 523,320 \n```\n\n\n:::\n:::\n\n\n## 7. Visualize Temporal Patterns\n\n### 7.1 Lag Correlations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample one station to visualize\nexample_station <- study_panel_complete_q3 %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)  # One week\n\n# Plot actual vs lagged demand\nggplot(example_station, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\" = \"#08519c\",\n    \"1 Hour Ago\" = \"#3182bd\",\n    \"24 Hours Ago\" = \"#6baed6\"\n  )) +\n  labs(\n    title = \"Temporal Lag Patterns at One Station\",\n    subtitle = \"Past demand predicts future demand\",\n    x = \"Date-Time\",\n    y = \"Trip Count\",\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/lag_correlations-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## 8. Temporal Train/Test Split\n\n### 8.1 2024 Q3\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Q3 has weeks 27-40 (Jul-Sep)\n# Train on weeks 27-35 (Jul 1 - early September)\n# Test on weeks 36-40 (rest of September)\nunique(study_panel_complete_q3$week)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 27 28 29 30 31 32 33 34 35 36 37 38 39 40\n```\n\n\n:::\n\n```{.r .cell-code}\n# Which stations have trips in BOTH early and late periods?\nearly_stations_q3 <- study_panel_complete_q3 %>%\n  filter(week < 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations_q3 <- study_panel_complete_q3 %>%\n  filter(week >= 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations_q3 <- intersect(early_stations_q3, late_stations_q3)\n\n# Filter panel to only common stations\nstudy_panel_complete_q3 <- study_panel_complete_q3 %>%\n  filter(start_station %in% common_stations_q3)\n\n# NOW create train/test split\ntrain_q3 <- study_panel_complete_q3 %>%\n  filter(week < 36)\n\ntest_q3 <- study_panel_complete_q3 %>%\n  filter(week >= 36)\n\ncat(\"Training observations Q3:\", format(nrow(train_q3), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining observations Q3: 349,680 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing observations Q3:\", format(nrow(test_q3), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting observations Q3: 163,560 \n```\n\n\n:::\n:::\n\n\n### 8.2 2025 Q1\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train on weeks 1-9 (Jan 1 - early March)\n# Test on weeks 10-13 (rest of March)\nunique(study_panel_complete_q1$week)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13\n```\n\n\n:::\n\n```{.r .cell-code}\n# Which stations have trips in BOTH early and late periods?\nearly_stations_q1 <- study_panel_complete_q1 %>%\n  filter(week < 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations_q1 <- study_panel_complete_q1 %>%\n  filter(week >= 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations_q1 <- intersect(early_stations_q1, late_stations_q1)\n\n# Filter panel to only common stations\nstudy_panel_complete_q1 <- study_panel_complete_q1 %>%\n  filter(start_station %in% common_stations_q1)\n\n# NOW create train/test split\ntrain_q1 <- study_panel_complete_q1 %>%\n  filter(week < 10)\n\ntest_q1 <- study_panel_complete_q1 %>%\n  filter(week >= 10)\n\ncat(\"Training observations Q1:\", format(nrow(train_q1), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining observations Q1: 354,144 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing observations Q1:\", format(nrow(test_q1), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting observations Q1: 154,224 \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## 9. Build Predictive Models\n\n### 9.1 2024 Q3 Models\n\n#### Model 1: Baseline (Time + Weather)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntrain_q3 <- train_q3 %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train_q3$dotw_simple) <- contr.treatment(7)\n\n# Now run the model\nmodel1_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train_q3\n)\nsummary(model1_q3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation, data = train_q3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7222 -0.7872 -0.1954  0.1871 23.4121 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)        0.3940977  0.0335506  11.746 < 0.0000000000000002 ***\nas.factor(hour)1  -0.0977139  0.0144193  -6.777      0.0000000000123 ***\nas.factor(hour)2  -0.1340615  0.0144109  -9.303 < 0.0000000000000002 ***\nas.factor(hour)3  -0.1867155  0.0144452 -12.926 < 0.0000000000000002 ***\nas.factor(hour)4  -0.1748870  0.0144752 -12.082 < 0.0000000000000002 ***\nas.factor(hour)5  -0.0481245  0.0145117  -3.316             0.000912 ***\nas.factor(hour)6   0.2138134  0.0145495  14.696 < 0.0000000000000002 ***\nas.factor(hour)7   0.4927407  0.0145725  33.813 < 0.0000000000000002 ***\nas.factor(hour)8   0.8922681  0.0146149  61.052 < 0.0000000000000002 ***\nas.factor(hour)9   0.6469687  0.0146375  44.199 < 0.0000000000000002 ***\nas.factor(hour)10  0.5327485  0.0145974  36.496 < 0.0000000000000002 ***\nas.factor(hour)11  0.5624303  0.0145101  38.761 < 0.0000000000000002 ***\nas.factor(hour)12  0.6732015  0.0144185  46.690 < 0.0000000000000002 ***\nas.factor(hour)13  0.6935212  0.0143758  48.242 < 0.0000000000000002 ***\nas.factor(hour)14  0.7445912  0.0143807  51.777 < 0.0000000000000002 ***\nas.factor(hour)15  0.8279830  0.0144296  57.381 < 0.0000000000000002 ***\nas.factor(hour)16  1.0219626  0.0144734  70.610 < 0.0000000000000002 ***\nas.factor(hour)17  1.3858030  0.0145355  95.339 < 0.0000000000000002 ***\nas.factor(hour)18  1.1083174  0.0145778  76.028 < 0.0000000000000002 ***\nas.factor(hour)19  0.8919309  0.0145886  61.139 < 0.0000000000000002 ***\nas.factor(hour)20  0.6268454  0.0145857  42.977 < 0.0000000000000002 ***\nas.factor(hour)21  0.4128159  0.0145127  28.445 < 0.0000000000000002 ***\nas.factor(hour)22  0.3157927  0.0144556  21.846 < 0.0000000000000002 ***\nas.factor(hour)23  0.1548512  0.0143958  10.757 < 0.0000000000000002 ***\ndotw_simple2       0.0735856  0.0079434   9.264 < 0.0000000000000002 ***\ndotw_simple3       0.0751295  0.0079782   9.417 < 0.0000000000000002 ***\ndotw_simple4       0.0468697  0.0079654   5.884      0.0000000040045 ***\ndotw_simple5      -0.0473784  0.0079563  -5.955      0.0000000026056 ***\ndotw_simple6      -0.0653380  0.0079484  -8.220 < 0.0000000000000002 ***\ndotw_simple7      -0.1227242  0.0079501 -15.437 < 0.0000000000000002 ***\nTemperature       -0.0018760  0.0003914  -4.793      0.0000016451977 ***\nPrecipitation     -0.0535064  0.0174455  -3.067             0.002162 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.227 on 349648 degrees of freedom\nMultiple R-squared:  0.1116,\tAdjusted R-squared:  0.1115 \nF-statistic:  1417 on 31 and 349648 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n#### Model 2: Add Temporal Lags\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train_q3\n)\n\nsummary(model2_q3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day, data = train_q3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.2148 -0.5344 -0.1526  0.2223 21.4940 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)        0.1160760  0.0296289   3.918  0.00008943093627735 ***\nas.factor(hour)1  -0.0274986  0.0127286  -2.160             0.030744 *  \nas.factor(hour)2  -0.0081186  0.0127275  -0.638             0.523554    \nas.factor(hour)3  -0.0206389  0.0127662  -1.617             0.105947    \nas.factor(hour)4   0.0099397  0.0128002   0.777             0.437438    \nas.factor(hour)5   0.1009008  0.0128356   7.861  0.00000000000000382 ***\nas.factor(hour)6   0.2677691  0.0128830  20.785 < 0.0000000000000002 ***\nas.factor(hour)7   0.4049385  0.0129270  31.325 < 0.0000000000000002 ***\nas.factor(hour)8   0.6122588  0.0130130  47.050 < 0.0000000000000002 ***\nas.factor(hour)9   0.3103126  0.0130032  23.864 < 0.0000000000000002 ***\nas.factor(hour)10  0.2548051  0.0129193  19.723 < 0.0000000000000002 ***\nas.factor(hour)11  0.2592292  0.0128474  20.178 < 0.0000000000000002 ***\nas.factor(hour)12  0.3607666  0.0127686  28.254 < 0.0000000000000002 ***\nas.factor(hour)13  0.3604016  0.0127400  28.289 < 0.0000000000000002 ***\nas.factor(hour)14  0.3901808  0.0127504  30.601 < 0.0000000000000002 ***\nas.factor(hour)15  0.4246068  0.0128060  33.157 < 0.0000000000000002 ***\nas.factor(hour)16  0.5440485  0.0128779  42.247 < 0.0000000000000002 ***\nas.factor(hour)17  0.7549667  0.0130153  58.006 < 0.0000000000000002 ***\nas.factor(hour)18  0.4587761  0.0130465  35.165 < 0.0000000000000002 ***\nas.factor(hour)19  0.3460763  0.0129926  26.636 < 0.0000000000000002 ***\nas.factor(hour)20  0.1607276  0.0129834  12.379 < 0.0000000000000002 ***\nas.factor(hour)21  0.1050185  0.0128607   8.166  0.00000000000000032 ***\nas.factor(hour)22  0.1110356  0.0127829   8.686 < 0.0000000000000002 ***\nas.factor(hour)23  0.0497331  0.0127111   3.913  0.00009134129697410 ***\ndotw_simple2       0.0119189  0.0070139   1.699             0.089260 .  \ndotw_simple3      -0.0048842  0.0070478  -0.693             0.488309    \ndotw_simple4      -0.0256755  0.0070366  -3.649             0.000263 ***\ndotw_simple5      -0.0795199  0.0070293 -11.313 < 0.0000000000000002 ***\ndotw_simple6      -0.0651468  0.0070181  -9.283 < 0.0000000000000002 ***\ndotw_simple7      -0.1012308  0.0070217 -14.417 < 0.0000000000000002 ***\nTemperature       -0.0008822  0.0003455  -2.553             0.010674 *  \nPrecipitation      0.0419172  0.0154082   2.720             0.006520 ** \nlag1Hour           0.2395396  0.0016301 146.948 < 0.0000000000000002 ***\nlag3Hours          0.1140298  0.0015873  71.839 < 0.0000000000000002 ***\nlag1day            0.2736878  0.0016027 170.763 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.083 on 349645 degrees of freedom\nMultiple R-squared:  0.308,\tAdjusted R-squared:  0.3079 \nF-statistic:  4576 on 34 and 349645 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n**Question:** Did adding lags improve R²? Why or why not?\n\n#### Model 3: Add Demographics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White,\n  data = train_q3\n)\n\n# Summary too long with all station dummies, just show key metrics\ncat(\"Model 3 R-squared:\", summary(model3_q3)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3 R-squared: 0.3142151 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 3 Adj R-squared:\", summary(model3_q3)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3 Adj R-squared: 0.3141425 \n```\n\n\n:::\n:::\n\n\n#### Model 4: Add Station Fixed Effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station),\n  data = train_q3\n)\n\n# Summary too long with all station dummies, just show key metrics\ncat(\"Model 4 R-squared:\", summary(model4_q3)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 R-squared: 0.3434496 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 4 Adj R-squared:\", summary(model4_q3)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 Adj R-squared: 0.342946 \n```\n\n\n:::\n:::\n\n\n**What do station fixed effects capture?** Baseline differences in\ndemand across stations (some are just busier than others!).\n\n#### Model 5: Add Rush Hour Interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train_q3\n)\n\ncat(\"Model 5 R-squared:\", summary(model5_q3)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 R-squared: 0.3479645 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 5 Adj R-squared:\", summary(model5_q3)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 Adj R-squared: 0.3474588 \n```\n\n\n:::\n:::\n\n\n#### Model performance summary (training set)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_rsq_q3 <- data.frame(\n  Model = paste0(\"Model \", 1:5),\n  Description = c(\"Time + Weather\", \"+ Temporal Lags\", \"+ Demographics\", \n                  \"+ Station Fixed Effects\", \"+ Rush Hour Interaction\"),\n  R_squared = c(\n    summary(model1_q3)$r.squared,\n    summary(model2_q3)$r.squared,\n    summary(model3_q3)$r.squared,\n    summary(model4_q3)$r.squared,\n    summary(model5_q3)$r.squared\n  )\n)\n\nkable(model_rsq_q3,\n      caption = \"2024 Q3 Model Performance\",\n      col.names = c(\"Model\", \"Description\", \"R²\"),\n      digits = 3) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>2024 Q3 Model Performance</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:left;\"> Description </th>\n   <th style=\"text-align:right;\"> R² </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Model 1 </td>\n   <td style=\"text-align:left;\"> Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.112 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 2 </td>\n   <td style=\"text-align:left;\"> + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.308 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 3 </td>\n   <td style=\"text-align:left;\"> + Demographics </td>\n   <td style=\"text-align:right;\"> 0.314 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 4 </td>\n   <td style=\"text-align:left;\"> + Station Fixed Effects </td>\n   <td style=\"text-align:right;\"> 0.343 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 5 </td>\n   <td style=\"text-align:left;\"> + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.348 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n#### Model Evaluation Summary (test set)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntest_q3 <- test_q3 %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test_q3$dotw_simple) <- contr.treatment(7)\n\ntest_q3 <- test_q3 %>%\n  mutate(\n    pred1 = predict(model1_q3, newdata = test_q3),\n    pred2 = predict(model2_q3, newdata = test_q3),\n    pred3 = predict(model3_q3, newdata = test_q3),\n    pred4 = predict(model4_q3, newdata = test_q3),\n    pred5 = predict(model5_q3, newdata = test_q3)\n  )\n\n# Calculate MAE for each model\nmae_results_q3 <- data.frame(\n  Model = paste0(\"Model \", 1:5),\n  Description = c(\"Time + Weather\", \"+ Temporal Lags\", \"+ Demographics\", \n                  \"+ Station Fixed Effects\", \"+ Rush Hour Interaction\"),\n  MAE_q3 = c(\n    mean(abs(test_q3$Trip_Count - test_q3$pred1), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred2), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred3), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred4), na.rm = TRUE),\n    mean(abs(test_q3$Trip_Count - test_q3$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results_q3, \n      digits = 2,\n      caption = \"2024 Q3 Model Evaluation\",\n      col.names = c(\"Model\",\"Description\", \"MAE\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>2024 Q3 Model Evaluation</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:left;\"> Description </th>\n   <th style=\"text-align:right;\"> MAE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Model 1 </td>\n   <td style=\"text-align:left;\"> Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 2 </td>\n   <td style=\"text-align:left;\"> + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.71 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 3 </td>\n   <td style=\"text-align:left;\"> + Demographics </td>\n   <td style=\"text-align:right;\"> 0.72 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 4 </td>\n   <td style=\"text-align:left;\"> + Station Fixed Effects </td>\n   <td style=\"text-align:right;\"> 0.71 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 5 </td>\n   <td style=\"text-align:left;\"> + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.71 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### 9.2 2025 Q1 Models\n\n#### Model 1: Baseline (Time + Weather)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntrain_q1 <- train_q1 %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train_q1$dotw_simple) <- contr.treatment(7)\n\n# Now run the model\nmodel1_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train_q1\n)\nsummary(model1_q1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation, data = train_q1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.9571 -0.3981 -0.1761  0.0246 18.5345 \n\nCoefficients:\n                   Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.186083   0.008656 -21.497 < 0.0000000000000002 ***\nas.factor(hour)1  -0.022170   0.008662  -2.560              0.01048 *  \nas.factor(hour)2  -0.038425   0.008665  -4.435 0.000009223337243493 ***\nas.factor(hour)3  -0.051750   0.008669  -5.969 0.000000002382143655 ***\nas.factor(hour)4  -0.040250   0.008675  -4.640 0.000003491064079342 ***\nas.factor(hour)5   0.022443   0.008680   2.586              0.00972 ** \nas.factor(hour)6   0.173092   0.008688  19.924 < 0.0000000000000002 ***\nas.factor(hour)7   0.323218   0.008691  37.190 < 0.0000000000000002 ***\nas.factor(hour)8   0.549242   0.008694  63.175 < 0.0000000000000002 ***\nas.factor(hour)9   0.388029   0.008696  44.622 < 0.0000000000000002 ***\nas.factor(hour)10  0.279833   0.008700  32.164 < 0.0000000000000002 ***\nas.factor(hour)11  0.297059   0.008703  34.134 < 0.0000000000000002 ***\nas.factor(hour)12  0.367753   0.008691  42.314 < 0.0000000000000002 ***\nas.factor(hour)13  0.347729   0.008672  40.100 < 0.0000000000000002 ***\nas.factor(hour)14  0.351219   0.008662  40.548 < 0.0000000000000002 ***\nas.factor(hour)15  0.406504   0.008664  46.917 < 0.0000000000000002 ***\nas.factor(hour)16  0.488703   0.008668  56.379 < 0.0000000000000002 ***\nas.factor(hour)17  0.620476   0.008676  71.520 < 0.0000000000000002 ***\nas.factor(hour)18  0.423784   0.008687  48.786 < 0.0000000000000002 ***\nas.factor(hour)19  0.270369   0.008693  31.104 < 0.0000000000000002 ***\nas.factor(hour)20  0.153548   0.008685  17.679 < 0.0000000000000002 ***\nas.factor(hour)21  0.090346   0.008678  10.411 < 0.0000000000000002 ***\nas.factor(hour)22  0.069686   0.008668   8.039 0.000000000000000905 ***\nas.factor(hour)23  0.045265   0.008661   5.227 0.000000172769575176 ***\ndotw_simple2       0.053398   0.004640  11.509 < 0.0000000000000002 ***\ndotw_simple3       0.059407   0.004803  12.370 < 0.0000000000000002 ***\ndotw_simple4       0.033142   0.004647   7.131 0.000000000000995308 ***\ndotw_simple5       0.044776   0.004642   9.646 < 0.0000000000000002 ***\ndotw_simple6      -0.063711   0.004641 -13.728 < 0.0000000000000002 ***\ndotw_simple7      -0.059444   0.004669 -12.731 < 0.0000000000000002 ***\nTemperature        0.007989   0.000153  52.200 < 0.0000000000000002 ***\nPrecipitation     -1.125949   0.058754 -19.164 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7438 on 354112 degrees of freedom\nMultiple R-squared:  0.0801,\tAdjusted R-squared:  0.08002 \nF-statistic: 994.6 on 31 and 354112 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n#### Model 2: Add Temporal Lags\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train_q1\n)\n\nsummary(model2_q1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day, data = train_q1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.9320 -0.2812 -0.0997  0.0182 17.8035 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.0962851  0.0079137 -12.167 < 0.0000000000000002 ***\nas.factor(hour)1  -0.0062075  0.0079108  -0.785              0.43264    \nas.factor(hour)2  -0.0076621  0.0079144  -0.968              0.33299    \nas.factor(hour)3  -0.0102415  0.0079194  -1.293              0.19594    \nas.factor(hour)4   0.0051558  0.0079260   0.650              0.51538    \nas.factor(hour)5   0.0524781  0.0079312   6.617      0.0000000000368 ***\nas.factor(hour)6   0.1554233  0.0079441  19.565 < 0.0000000000000002 ***\nas.factor(hour)7   0.2350093  0.0079592  29.527 < 0.0000000000000002 ***\nas.factor(hour)8   0.3679467  0.0079919  46.040 < 0.0000000000000002 ***\nas.factor(hour)9   0.1779574  0.0079899  22.273 < 0.0000000000000002 ***\nas.factor(hour)10  0.1162892  0.0079704  14.590 < 0.0000000000000002 ***\nas.factor(hour)11  0.1318394  0.0079848  16.511 < 0.0000000000000002 ***\nas.factor(hour)12  0.2001697  0.0079651  25.131 < 0.0000000000000002 ***\nas.factor(hour)13  0.1834693  0.0079446  23.094 < 0.0000000000000002 ***\nas.factor(hour)14  0.1894740  0.0079350  23.878 < 0.0000000000000002 ***\nas.factor(hour)15  0.2256510  0.0079437  28.406 < 0.0000000000000002 ***\nas.factor(hour)16  0.2748485  0.0079597  34.530 < 0.0000000000000002 ***\nas.factor(hour)17  0.3568287  0.0079903  44.658 < 0.0000000000000002 ***\nas.factor(hour)18  0.1712821  0.0079927  21.430 < 0.0000000000000002 ***\nas.factor(hour)19  0.0884182  0.0079724  11.091 < 0.0000000000000002 ***\nas.factor(hour)20  0.0183403  0.0079699   2.301              0.02138 *  \nas.factor(hour)21  0.0144891  0.0079401   1.825              0.06803 .  \nas.factor(hour)22  0.0252975  0.0079210   3.194              0.00140 ** \nas.factor(hour)23  0.0216694  0.0079105   2.739              0.00616 ** \ndotw_simple2       0.0204023  0.0042393   4.813      0.0000014898921 ***\ndotw_simple3       0.0109642  0.0043909   2.497              0.01252 *  \ndotw_simple4      -0.0017846  0.0042478  -0.420              0.67440    \ndotw_simple5       0.0119251  0.0042419   2.811              0.00494 ** \ndotw_simple6      -0.0718362  0.0042473 -16.914 < 0.0000000000000002 ***\ndotw_simple7      -0.0412702  0.0042671  -9.672 < 0.0000000000000002 ***\nTemperature        0.0036650  0.0001409  26.019 < 0.0000000000000002 ***\nPrecipitation     -0.6138873  0.0537180 -11.428 < 0.0000000000000002 ***\nlag1Hour           0.2278355  0.0016252 140.191 < 0.0000000000000002 ***\nlag3Hours          0.0968586  0.0015982  60.606 < 0.0000000000000002 ***\nlag1day            0.2413146  0.0016078 150.093 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6793 on 354109 degrees of freedom\nMultiple R-squared:  0.2327,\tAdjusted R-squared:  0.2326 \nF-statistic:  3159 on 34 and 354109 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n**Question:** Did adding lags improve R²? Why or why not?\n\n#### Model 3: Add Demographics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White,\n  data = train_q1\n)\n\n# Summary too long with all station dummies, just show key metrics\ncat(\"Model 3 R-squared:\", summary(model3_q1)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3 R-squared: 0.2371779 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 3 Adj R-squared:\", summary(model3_q1)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3 Adj R-squared: 0.2370982 \n```\n\n\n:::\n:::\n\n\n#### Model 4: Add Station Fixed Effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station),\n  data = train_q1\n)\n\n# Summary too long with all station dummies, just show key metrics\ncat(\"Model 4 R-squared:\", summary(model4_q1)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 R-squared: 0.2647377 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 4 Adj R-squared:\", summary(model4_q1)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 Adj R-squared: 0.2641746 \n```\n\n\n:::\n:::\n\n\n**What do station fixed effects capture?** Baseline differences in\ndemand across stations (some are just busier than others!).\n\n#### Model 5: Add Rush Hour Interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5_q1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train_q1\n)\n\ncat(\"Model 5 R-squared:\", summary(model5_q1)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 R-squared: 0.2694846 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 5 Adj R-squared:\", summary(model5_q1)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 Adj R-squared: 0.268919 \n```\n\n\n:::\n:::\n\n\n#### Model performance summary (training set)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_rsq_q1 <- data.frame(\n  Model = paste0(\"Model \", 1:5),\n  Description = c(\"Time + Weather\", \"+ Temporal Lags\", \"+ Demographics\", \n                  \"+ Station Fixed Effects\", \"+ Rush Hour Interaction\"),\n  R_squared = c(\n    summary(model1_q1)$r.squared,\n    summary(model2_q1)$r.squared,\n    summary(model3_q1)$r.squared,\n    summary(model4_q1)$r.squared,\n    summary(model5_q1)$r.squared\n  )\n)\n\nkable(model_rsq_q1,\n      caption = \"2025 Q1 Model Performance\",\n      col.names = c(\"Model\", \"Description\", \"R²\"),\n      digits = 3) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>2025 Q1 Model Performance</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:left;\"> Description </th>\n   <th style=\"text-align:right;\"> R² </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Model 1 </td>\n   <td style=\"text-align:left;\"> Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.080 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 2 </td>\n   <td style=\"text-align:left;\"> + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.233 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 3 </td>\n   <td style=\"text-align:left;\"> + Demographics </td>\n   <td style=\"text-align:right;\"> 0.237 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 4 </td>\n   <td style=\"text-align:left;\"> + Station Fixed Effects </td>\n   <td style=\"text-align:right;\"> 0.265 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 5 </td>\n   <td style=\"text-align:left;\"> + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.269 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n#### Model Evaluation Summary (test set)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntest_q1 <- test_q1 %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test_q1$dotw_simple) <- contr.treatment(7)\n\ntest_q1 <- test_q1 %>%\n  mutate(\n    pred1 = predict(model1_q1, newdata = test_q1),\n    pred2 = predict(model2_q1, newdata = test_q1),\n    pred3 = predict(model3_q1, newdata = test_q1),\n    pred4 = predict(model4_q1, newdata = test_q1),\n    pred5 = predict(model5_q1, newdata = test_q1)\n  )\n\n# Calculate MAE for each model\nmae_results_q1 <- data.frame(\n  Model = paste0(\"Model \", 1:5),\n  Description = c(\"Time + Weather\", \"+ Temporal Lags\", \"+ Demographics\", \n                  \"+ Station Fixed Effects\", \"+ Rush Hour Interaction\"),\n  MAE_q1 = c(\n    mean(abs(test_q1$Trip_Count - test_q1$pred1), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred2), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred3), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred4), na.rm = TRUE),\n    mean(abs(test_q1$Trip_Count - test_q1$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results_q1, \n      digits = 2,\n      caption = \"2025 Q1 Model Evaluation\",\n      col.names = c(\"Model\", \"Description\", \"MAE\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>2025 Q1 Model Evaluation</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:left;\"> Description </th>\n   <th style=\"text-align:right;\"> MAE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Model 1 </td>\n   <td style=\"text-align:left;\"> Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 2 </td>\n   <td style=\"text-align:left;\"> + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.54 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 3 </td>\n   <td style=\"text-align:left;\"> + Demographics </td>\n   <td style=\"text-align:right;\"> 0.53 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 4 </td>\n   <td style=\"text-align:left;\"> + Station Fixed Effects </td>\n   <td style=\"text-align:right;\"> 0.53 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Model 5 </td>\n   <td style=\"text-align:left;\"> + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.53 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### 9.3 Model Performance Comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr2_q3_vec <- c(\n  summary(model1_q3)$r.squared,\n  summary(model2_q3)$r.squared,\n  summary(model3_q3)$r.squared,\n  summary(model4_q3)$r.squared,\n  summary(model5_q3)$r.squared\n)\n\nmae_q3_vec <- c(\n  mean(abs(test_q3$Trip_Count - test_q3$pred1), na.rm = TRUE),\n  mean(abs(test_q3$Trip_Count - test_q3$pred2), na.rm = TRUE),\n  mean(abs(test_q3$Trip_Count - test_q3$pred3), na.rm = TRUE),\n  mean(abs(test_q3$Trip_Count - test_q3$pred4), na.rm = TRUE),\n  mean(abs(test_q3$Trip_Count - test_q3$pred5), na.rm = TRUE)\n)\n\nr2_q1_vec <- c(\n  summary(model1_q1)$r.squared,\n  summary(model2_q1)$r.squared,\n  summary(model3_q1)$r.squared,\n  summary(model4_q1)$r.squared,\n  summary(model5_q1)$r.squared\n)\n\nmae_q1_vec <- c(\n  mean(abs(test_q1$Trip_Count - test_q1$pred1), na.rm = TRUE),\n  mean(abs(test_q1$Trip_Count - test_q1$pred2), na.rm = TRUE),\n  mean(abs(test_q1$Trip_Count - test_q1$pred3), na.rm = TRUE),\n  mean(abs(test_q1$Trip_Count - test_q1$pred4), na.rm = TRUE),\n  mean(abs(test_q1$Trip_Count - test_q1$pred5), na.rm = TRUE)\n)\n\ncomparison_matrix <- data.frame(\n  Model = c(\"1. Time + Weather\", \"2. + Temporal Lags\", \"3. + Demographics\", \"4. + Station FE\", \"5. + Rush Hour\"),\n  R2_Q3_2024 = r2_q3_vec,\n  R2_Q1_2025 = r2_q1_vec,\n  MAE_Q3_2024 = mae_q3_vec,\n  MAE_Q1_2025 = mae_q1_vec\n)\n\nkable(comparison_matrix, \n      digits = 3, \n      caption = \"Model Performance Comparison: Summer (Q3 2024) vs Winter (Q1 2025)\",\n      col.names = c(\"Model Description\", \"Q3 (Summer)\", \"Q1 (Winter)\", \"Q3 (Summer)\", \"Q1 (Winter)\")) %>%\n  \n  add_header_above(c(\" \" = 1, \"R-Squared (Training Fit)\" = 2, \"MAE (Testing Error)\" = 2)) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = F) %>%\n  \n  row_spec(4, bold = T, color = \"black\", background = \"#e6f3ff\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Model Performance Comparison: Summer (Q3 2024) vs Winter (Q1 2025)</caption>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">R-Squared (Training Fit)</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">MAE (Testing Error)</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> Model Description </th>\n   <th style=\"text-align:right;\"> Q3 (Summer) </th>\n   <th style=\"text-align:right;\"> Q1 (Winter) </th>\n   <th style=\"text-align:right;\"> Q3 (Summer) </th>\n   <th style=\"text-align:right;\"> Q1 (Winter) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.112 </td>\n   <td style=\"text-align:right;\"> 0.080 </td>\n   <td style=\"text-align:right;\"> 0.830 </td>\n   <td style=\"text-align:right;\"> 0.625 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.308 </td>\n   <td style=\"text-align:right;\"> 0.233 </td>\n   <td style=\"text-align:right;\"> 0.714 </td>\n   <td style=\"text-align:right;\"> 0.535 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.314 </td>\n   <td style=\"text-align:right;\"> 0.237 </td>\n   <td style=\"text-align:right;\"> 0.717 </td>\n   <td style=\"text-align:right;\"> 0.533 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;color: black !important;background-color: rgba(230, 243, 255, 255) !important;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: rgba(230, 243, 255, 255) !important;\"> 0.343 </td>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: rgba(230, 243, 255, 255) !important;\"> 0.265 </td>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: rgba(230, 243, 255, 255) !important;\"> 0.713 </td>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: rgba(230, 243, 255, 255) !important;\"> 0.527 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour </td>\n   <td style=\"text-align:right;\"> 0.348 </td>\n   <td style=\"text-align:right;\"> 0.269 </td>\n   <td style=\"text-align:right;\"> 0.714 </td>\n   <td style=\"text-align:right;\"> 0.530 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### 9.4 Visualize Model Comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mae_results_q3, aes(x = reorder(Model, -MAE_q3), y = MAE_q3)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE_q3, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/compare_models-1.png){width=672}\n:::\n:::\n\n\n**Question:** Which features gave us the biggest improvement?\n\n------------------------------------------------------------------------\n\n# PART 2: Error Analysis\n\n## 1. Spatial Error Patterns\n\nAre prediction errors clustered in certain parts of Philadelphia?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate station errors\nstation_errors <- test_q3 %>%\n  filter(!is.na(pred4)) %>%\n  group_by(start_station, start_lat, start_lon) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred4), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat), !is.na(start_lon))\n\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon, y = start_lat, color = MAE),\n    size = 1.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE\\n(trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),  # Fewer, cleaner breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\",\n       subtitle = \"Higher in Center City\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand\np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon, y = start_lat, color = avg_demand),\n    size = 1.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg\\nDemand\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),  # Clear breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\",\n       subtitle = \"Trips per station-hour\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Combine\ngrid.arrange(\n  p1, p2,\n  ncol = 2\n  )\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/spatial_errors-1.png){width=672}\n:::\n:::\n\n\n**Question:** Do you see spatial clustering of errors? What\nneighborhoods have high errors?\n\n## 2. Temporal Error Patterns\n\nWhen are we most wrong?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_q3 <- test_q3 %>%\n  mutate(\n    error = Trip_Count - pred4,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test_q3, aes(x = Trip_Count, y = pred4)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 4 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/obs_vs_pred-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MAE by time of day and day type\ntemporal_errors <- test_q3 %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period\",\n    subtitle = \"2024 Q3\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/temporal_errors-1.png){width=672}\n:::\n:::\n\n\n## 3. Demographics Error Patterns\n\nAre prediction errors related to neighborhood characteristics?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join demographic data to station errors\nstation_errors_demo <- station_errors %>%\n  left_join(\n  stations_census_q3 %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1, p2, p3, ncol = 3)\n```\n\n::: {.cell-output-display}\n![](Indego_SpaceTime_Prediction-1-_files/figure-html/errors_demographics-1.png){width=672}\n:::\n:::\n\n\n**Critical Question:** Are prediction errors systematically higher in\ncertain demographic groups? What are the equity implications?\n\n------------------------------------------------------------------------\n\n# PART 3: Feature Engineering & model improvement\n\nBased on your error analysis, add 2-3 NEW features to improve the model:\n\n## 3.1 Temporal features: School calendar\n\n### 3.1.1 Add School Feature\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel_complete_q3 <- study_panel_complete_q3 %>%\n  mutate(\n    # Penn Session Logic\n    is_penn_session = case_when(\n      date >= \"2024-07-01\" & date <= \"2024-07-03\" ~ 1,\n      date >= \"2024-07-05\" & date <= \"2024-08-09\" ~ 1,\n      date >= \"2024-08-21\" & date <= \"2024-09-03\" ~ 1,\n      date >= \"2024-09-05\" & date <= \"2024-09-30\" ~ 1,\n      TRUE ~ 0 # All other dates (holidays/breaks) are 0\n    ),\n    \n    # Drexel Session Logic\n    is_drexel_session = case_when(\n      date >= \"2024-07-01\" & date <= \"2024-07-03\" ~ 1,\n      date >= \"2024-07-06\" & date <= \"2024-07-27\" ~ 1,\n      date >= \"2024-07-29\" & date <= \"2024-08-31\" ~ 1,\n      date >= \"2024-09-03\" & date <= \"2024-09-20\" ~ 1,\n      TRUE ~ 0 # All other dates (holidays/breaks) are 0\n    )\n  )\n```\n:::\n\n\n### 3.1.2 Refresh the Split\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Re-apply the split using the same week logic as Part 8.1\ntrain_q3 <- study_panel_complete_q3 %>% filter(week < 36)\ntest_q3 <- study_panel_complete_q3 %>% filter(week >= 36)\n```\n:::\n\n\n### 3.1.3 Build Model 6 (+School features)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_q3 <- train_q3 %>% \n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"))) \ncontrasts(train_q3$dotw_simple) <- contr.treatment(7)\n\nmodel6_q3 <- lm( Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation + lag1Hour + lag3Hours + lag1day + Med_Inc + Percent_Taking_Transit + Percent_White + as.factor(start_station) + is_penn_session +  is_drexel_session,\n                data = train_q3 )\n\ncat(\"Model 6 R-squared:\", summary(model6_q3)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 6 R-squared: 0.3434728 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 6 Adj R-squared:\", summary(model6_q3)$adj.r.squared, \"\\n\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 6 Adj R-squared: 0.3429655 \n```\n\n\n:::\n:::\n\n\n### 3.1.4 Evaluate Model 6 (+School features)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare Test Set Factors\ntest_q3 <- test_q3 %>% \n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\ncontrasts(test_q3$dotw_simple) <- contr.treatment(7)\n\n# Predict\ntest_q3$pred_school <- predict(model6_q3, newdata = test_q3)\n\n# Calculate MAE\nmae_school <- mean(abs(test_q3$Trip_Count - test_q3$pred_school), na.rm = TRUE)\n\ncat(\"New Feature MAE:\", round(mae_school, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNew Feature MAE: 0.711 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Did the school calendar improve the model?\", ifelse(mae_school < 0.713, \"YES\", \"NO\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDid the school calendar improve the model? YES \n```\n\n\n:::\n:::\n\n## 3.2 Weather features: Weekend + nice weather interaction\n\n### 3.2.1 Add Weather Interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Define \"Nice Weather\"\n# Criteria: Temperature between 60°F and 75°F, and NO rain (Precipitation == 0)\n# We create a binary flag for this.\nstudy_panel_complete_q3 <- study_panel_complete_q3 %>%\n  mutate(\n    nice_weather = ifelse(Temperature >= 60 & Temperature <= 75 & Precipitation == 0, 1, 0),\n    \n# 2. Create the Interaction Term\n# This specifically targets \"Nice Weekends\" (Weekend == 1 AND Nice Weather == 1)\n    weekend_nice = weekend * nice_weather\n  )\n```\n:::\n\n\n### 3.2.2 Refresh the Split\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train on weeks < 36, Test on weeks >= 36\ntrain_q3 <- study_panel_complete_q3 %>% filter(week < 36)\ntest_q3 <- study_panel_complete_q3 %>% filter(week >= 36)\n```\n:::\n\n\n### 3.2.3 Build Model 7(+ Weather Interaction)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ensure factors are set up (standard prep)\ntrain_q3 <- train_q3 %>% \n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\ncontrasts(train_q3$dotw_simple) <- contr.treatment(7)\n\n# Model 7: Model 4 + Schools + Weather Interaction\nmodel7_q3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station) + \n    is_penn_session +    # Keep School Feature\n    is_drexel_session +  # Keep School Feature\n    weekend_nice,        # <--- NEW INTERACTION FEATURE\n  data = train_q3\n)\n\n# Output Model Summary\ncat(\"Model 7 Adj R-squared:\", summary(model7_q3)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 7 Adj R-squared: 0.3434627 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 7 Adj R-squared:\", summary(model7_q3)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 7 Adj R-squared: 0.3429554 \n```\n\n\n:::\n:::\n\n\n### 3.2.4 Evaluate Model 7\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare Test Set\ntest_q3 <- test_q3 %>% \n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\ncontrasts(test_q3$dotw_simple) <- contr.treatment(7)\n\n# Predict\ntest_q3$pred_weather <- predict(model7_q3, newdata = test_q3)\n\n# Calculate MAE\nmae_weather <- mean(abs(test_q3$Trip_Count - test_q3$pred_weather), na.rm = TRUE)\n\ncat(\"MAE (Schools + Weather):\", round(mae_weather, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMAE (Schools + Weather): 0.71 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Did the Weekend + nice weather interaction improve the model?\", ifelse(mae_weather < 0.711, \"YES\", \"NO\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDid the Weekend + nice weather interaction improve the model? YES \n```\n\n\n:::\n:::\n\n# 删掉了温度\n\n## 3.3 Attempt for Poisson Model\n\n### 3.3.1 Build Model 8 (Poisson)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Poisson Model using the best features from Model 7\n# Note: family = \"poisson\" is the key change here\nmodel8_q3 <- glm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc + Percent_Taking_Transit + Percent_White +\n    as.factor(start_station) + \n    is_penn_session +\n    is_drexel_session +  \n    weekend_nice,        \n  family = \"poisson\",\n  data = train_q3\n)\n\n# Output Model Summary\ncat(\"Model 8 Adj R-squared:\", summary(model8_q3)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 8 Adj R-squared: \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 8 Adj R-squared:\", summary(model8_q3)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 8 Adj R-squared: \n```\n\n\n:::\n:::\n\n\n### 3.3.2 Evaluate Model 8\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Predict on Test Data\n# type = \"response\" is crucial for GLM to get the actual count (not log-count)\ntest_q3$pred_poisson <- predict(model8_q3, newdata = test_q3, type = \"response\")\n\n# 2. Calculate MAE for Poisson\nmae_m8 <- mean(abs(test_q3$Trip_Count - test_q3$pred_poisson), na.rm = TRUE)\n\n# 3. Compare with Best OLS Model (Model 7)\ncat(\"Model 7 (OLS) MAE:\", round(mae_weather, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 7 (OLS) MAE: 0.71 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Poisson Model MAE:\", round(mae_m8, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPoisson Model MAE: 0.666 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Did Poisson improve performance?\", ifelse(mae_m8 < mae_weather, \"YES\", \"NO\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDid Poisson improve performance? YES \n```\n\n\n:::\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_q3 <- study_panel_complete_q3 %>% filter(week >= 36)\n\ntest_q3 <- test_q3 %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\ncontrasts(test_q3$dotw_simple) <- contr.treatment(7)\n\n# Recalculate the predicted values of all models\npreds <- list(\nm1 = predict(model1_q3, newdata = test_q3),\n  m2 = predict(model2_q3, newdata = test_q3),\n  m3 = predict(model3_q3, newdata = test_q3),\n  m4 = predict(model4_q3, newdata = test_q3),\n  m5 = predict(model5_q3, newdata = test_q3),\n  m6 = predict(model6_q3, newdata = test_q3),\n  m7 = predict(model7_q3, newdata = test_q3),\n  pois = predict(model8_q3, newdata = test_q3, type = \"response\") \n)\n\nmae_values <- sapply(preds, function(p) mean(abs(test_q3$Trip_Count - p), na.rm = TRUE))\n\n# create a table\nall_models_df <- data.frame(\n  Model = c(\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\", \"Model 5\", \"Model 6\", \"Model 7\", \"Model 8\"),\n  Description = c(\n    \"Time + Weather (Baseline)\",\n    \"+ Temporal Lags\",\n    \"+ Demographics\",\n    \"+ Station Fixed Effects\",\n    \"+ Rush Hour Interaction\",\n    \"+ School Calendars\",\n    \"+ Weather Interaction\",\n    \"Poisson Regression (Full)\"\n  ),\n  MAE = mae_values\n)\n\n# Setup baseline(Model 1)\nbaseline_mae <- all_models_df$MAE[1]\nall_models_df$Improvement_vs_M1 <- (baseline_mae - all_models_df$MAE) / baseline_mae\n\n# Setup baseline2(Model2)\nlag_mae <- all_models_df$MAE[2]\nall_models_df$Improvement_vs_M2 <- (lag_mae - all_models_df$MAE) / lag_mae\n\nall_models_df %>%\n  mutate(\n    MAE = round(MAE, 3),\n    `% Better than M1` = scales::percent(Improvement_vs_M1, accuracy = 0.1),\n    `% Better than M2` = scales::percent(Improvement_vs_M2, accuracy = 0.1)\n  ) %>%\n  select(Model, Description, MAE, `% Better than M1`, `% Better than M2`) %>%\n  kable(\n    caption = \"Part 3: All Models Performance Summary - Q3 2024\",\n    align = c(\"l\", \"l\", \"c\", \"c\", \"c\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"), full_width = F) %>%\n  row_spec(which.min(all_models_df$MAE), bold = T, color = \"white\", background = \"#3182bd\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Part 3: All Models Performance Summary - Q3 2024</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:left;\"> Description </th>\n   <th style=\"text-align:center;\"> MAE </th>\n   <th style=\"text-align:center;\"> % Better than M1 </th>\n   <th style=\"text-align:center;\"> % Better than M2 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> m1 </td>\n   <td style=\"text-align:left;\"> Model 1 </td>\n   <td style=\"text-align:left;\"> Time + Weather (Baseline) </td>\n   <td style=\"text-align:center;\"> 0.830 </td>\n   <td style=\"text-align:center;\"> 0.0% </td>\n   <td style=\"text-align:center;\"> -16.3% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> m2 </td>\n   <td style=\"text-align:left;\"> Model 2 </td>\n   <td style=\"text-align:left;\"> + Temporal Lags </td>\n   <td style=\"text-align:center;\"> 0.714 </td>\n   <td style=\"text-align:center;\"> 14.0% </td>\n   <td style=\"text-align:center;\"> 0.0% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> m3 </td>\n   <td style=\"text-align:left;\"> Model 3 </td>\n   <td style=\"text-align:left;\"> + Demographics </td>\n   <td style=\"text-align:center;\"> 0.717 </td>\n   <td style=\"text-align:center;\"> 13.7% </td>\n   <td style=\"text-align:center;\"> -0.3% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> m4 </td>\n   <td style=\"text-align:left;\"> Model 4 </td>\n   <td style=\"text-align:left;\"> + Station Fixed Effects </td>\n   <td style=\"text-align:center;\"> 0.713 </td>\n   <td style=\"text-align:center;\"> 14.1% </td>\n   <td style=\"text-align:center;\"> 0.1% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> m5 </td>\n   <td style=\"text-align:left;\"> Model 5 </td>\n   <td style=\"text-align:left;\"> + Rush Hour Interaction </td>\n   <td style=\"text-align:center;\"> 0.714 </td>\n   <td style=\"text-align:center;\"> 14.0% </td>\n   <td style=\"text-align:center;\"> 0.0% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> m6 </td>\n   <td style=\"text-align:left;\"> Model 6 </td>\n   <td style=\"text-align:left;\"> + School Calendars </td>\n   <td style=\"text-align:center;\"> 0.711 </td>\n   <td style=\"text-align:center;\"> 14.3% </td>\n   <td style=\"text-align:center;\"> 0.4% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> m7 </td>\n   <td style=\"text-align:left;\"> Model 7 </td>\n   <td style=\"text-align:left;\"> + Weather Interaction </td>\n   <td style=\"text-align:center;\"> 0.710 </td>\n   <td style=\"text-align:center;\"> 14.5% </td>\n   <td style=\"text-align:center;\"> 0.6% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;color: white !important;background-color: rgba(49, 130, 189, 255) !important;\"> pois </td>\n   <td style=\"text-align:left;font-weight: bold;color: white !important;background-color: rgba(49, 130, 189, 255) !important;\"> Model 8 </td>\n   <td style=\"text-align:left;font-weight: bold;color: white !important;background-color: rgba(49, 130, 189, 255) !important;\"> Poisson Regression (Full) </td>\n   <td style=\"text-align:center;font-weight: bold;color: white !important;background-color: rgba(49, 130, 189, 255) !important;\"> 0.666 </td>\n   <td style=\"text-align:center;font-weight: bold;color: white !important;background-color: rgba(49, 130, 189, 255) !important;\"> 19.8% </td>\n   <td style=\"text-align:center;font-weight: bold;color: white !important;background-color: rgba(49, 130, 189, 255) !important;\"> 6.8% </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Implementation:**\n\n-   Add your features to the best model\n-   Compare MAE before and after\n-   Explain *why* you chose these features\n-   Did they improve predictions? Where?\n\n**Try a poisson model for count data**\n\n-   Does this improve model fit?\n\n# PART 4: Critical Reflection\n\n## **1. Operational implications:**\n\n-   Is your final MAE \"good enough\" for Indego to use?\n-   When do prediction errors cause problems for rebalancing?\n-   Would you recommend deploying this system? Under what conditions?\n\n## **2. Equity considerations:**\n\n-   Do prediction errors disproportionately affect certain\n    neighborhoods?\n-   Could this system worsen existing disparities in bike access?\n-   What safeguards would you recommend?\n\n## **3. Model limitations:**\n\n-   What patterns is your model missing?\n-   What assumptions might not hold in real deployment?\n-   How would you improve this with more time/data?\n\n------------------------------------------------------------------------\n\n1.  **Brief report** summarizing (with supporting data & visualization):\n\n    -   Your quarter and why you chose it\n    -   Model comparison results\n    -   Error analysis insights\n    -   New features you added and why\n    -   Critical reflection on deployment\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}