{
  "hash": "54ca1f1c53af095386358bbfb0cd8ed5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Predictive Policing - Technical Implementation\"\nsubtitle: \"MUSA 5080 - Fall 2025\"\nauthor: \"Your Name\"\ndate: today\nformat:\n  html:\n    code-fold: show\n    code-tools: true\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\neditor: visual\nexecute:\n  warning: false\n  message: false\n---\n\n## Assignment Overview\n\nIn this lab, you will apply the spatial predictive modeling techniques demonstrated in the class exercise to a 311 service request type of your choice. You will build a complete spatial predictive model, document your process, and interpret your results.\n\n### Timeline & Deliverables\n\n**Due Date:** November 17, 2025, 10:00AM\n\n**Deliverable:** One rendered document, posted to your portfolio website.\n\n### Learning Goals\n\nBy completing this assignment, you will demonstrate your ability to:\n\n-   Adapt example code to analyze a new dataset\n-   Build spatial features for predictive modeling\n-   Apply count regression techniques to spatial data\n-   Implement spatial cross-validation\n-   Interpret and communicate model results\n-   Critically evaluate model performance\n\n------------------------------------------------------------------------\n\n# Step 0: Set Up\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\nlibrary(here)\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_default <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_default())\n\ncat(\"✓ All packages loaded successfully!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ All packages loaded successfully!\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"✓ Working directory:\", getwd(), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Working directory: D:/PersonalFiles/MUSA/PPA/portfolio/portfolio-setup-demiyang12/assignments/assignment_4 \n```\n\n\n:::\n:::\n\n\n# Step 1: Getting the Data\n\n## 1.1 Load Chicago Spatial Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(District = dist_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 25 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.94011 ymin: 41.64455 xmax: -87.52414 ymax: 42.02303\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(Beat = beat_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 277 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.94011 ymin: 41.64455 xmax: -87.52414 ymax: 42.02303\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\") %>%\n  st_transform('ESRI:102271')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `chicagoBoundary' from data source \n  `https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -87.8367 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"✓ Loaded spatial boundaries\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded spatial boundaries\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police districts: 25 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police beats: 277 \n```\n\n\n:::\n:::\n\n\n## 1.2 Load 311 Rodent Baiting Data\n\n::: {.cell}\n\n```{.r .cell-code}\nrb <- read_csv(\"data/311_Service_Requests_-_Rodent_Baiting_-_Historical_20251114.csv\")\nhead(rb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 20\n  `Creation Date` Status `Completion Date` `Service Request Number`\n  <chr>           <chr>  <chr>             <chr>                   \n1 12/18/2018      Open   <NA>              18-03388744             \n2 12/18/2018      Open   <NA>              18-03388270             \n3 12/18/2018      Open   <NA>              18-03388081             \n4 12/18/2018      Open   <NA>              18-03388796             \n5 12/18/2018      Open   <NA>              18-03386545             \n6 12/18/2018      Open   <NA>              18-03388445             \n# ℹ 16 more variables: `Type of Service Request` <chr>,\n#   `Number of Premises Baited` <dbl>, `Number of Premises with Garbage` <dbl>,\n#   `Number of Premises with Rats` <dbl>, `Current Activity` <chr>,\n#   `Most Recent Action` <chr>, `Street Address` <chr>, `ZIP Code` <dbl>,\n#   `X Coordinate` <dbl>, `Y Coordinate` <dbl>, Ward <dbl>,\n#   `Police District` <dbl>, `Community Area` <dbl>, Latitude <dbl>,\n#   Longitude <dbl>, Location <chr>\n```\n\n\n:::\n\n```{.r .cell-code}\nrb_sf <- rb %>%\n  filter(!is.na(Latitude), !is.na(Longitude)) %>% \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>% \n  st_transform(\"ESRI:102271\")  \n\nrb_sf <- rb_sf %>% \n  filter(st_within(., chicagoBoundary, sparse = FALSE))\n```\n:::\n\n\n## 1.3 Visualize Point Data\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple point map for Rodent Baiting\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = rb_sf, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Rodent Baiting 311 Service Requests\",\n    subtitle = paste0(\"Chicago, n = \", nrow(rb_sf))\n  )\n\n# Density surface using 311 Rodent Baiting data\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = data.frame(st_coordinates(rb_sf)),\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"\n  ) +\n  labs(\n    title = \"Density Surface\",\n    subtitle = \"Kernel density estimation of Rodent Baiting Requests\"\n  )\n\n# Combine plots using patchwork\np1 + p2 + \n  plot_annotation(\n    title = \"Spatial Distribution of Rodent Baiting 311 Requests in Chicago\",\n    tag_levels = \"A\"\n  )\n```\n\n::: {.cell-output-display}\n![](Assignment4_Instructions_files/figure-html/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n- The maps above show the spatial distribution of Rodent Baiting 311 requests across Chicago.  \n- The point map on the left illustrates the raw locations of all reported rodent issues. The large number of points makes the overall pattern dense, but we can still see clear clusters in the northern and western parts of the city.  \n- The density map on the right provides a smoother view of these patterns. Several strong hotspots emerge, especially in the Northwest Side and Near North areas. In contrast, the southern and far southwestern parts of Chicago show much lower intensity.\n\n# Step 2: Fishnet Grid Creation\n\n## 2.1 Create Fishnet Grid\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Created fishnet grid\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of cells: 2458 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell size: 500 x 500 meters\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell area: 250000 square meters\n```\n\n\n:::\n:::\n\n\n## 2.2 Aggregate Rodent Baiting to Grid\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spatial join: which cell contains each rodent baiting request?\nrodent_fishnet <- st_join(rb_sf, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countRodent = n())\n\n# Join back to fishnet (cells with 0 requests will be NA)\nfishnet <- fishnet %>%\n  left_join(rodent_fishnet, by = \"uniqueID\") %>%\n  mutate(countRodent = replace_na(countRodent, 0))\n\n# Summary statistics\ncat(\"\\nRodent baiting request count distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRodent baiting request count distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$countRodent)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0    14.0    75.0   129.6   188.8  1122.0 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nCells with zero requests:\", \n    sum(fishnet$countRodent == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countRodent == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCells with zero requests: 334 / 2458 ( 13.6 %)\n```\n\n\n:::\n:::\n\n## 2.3 Visualize Rodent Baiting with fishnet\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize aggregated rodent baiting counts\nggplot() +\n  geom_sf(data = fishnet, aes(fill = countRodent), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"Rodent Baiting Requests\",\n    option = \"plasma\",\n    trans = \"sqrt\",  # Square root helps with skewed count data\n    breaks = c(0, 1, 5, 10, 20, 40)\n  ) +\n  labs(\n    title = \"Rodent Baiting 311 Requests by Grid Cell\",\n    subtitle = \"500m x 500m cells, Chicago\"\n  ) +\n  theme_default()\n```\n\n::: {.cell-output-display}\n![](Assignment4_Instructions_files/figure-html/unnamed-chunk-7-1.png){width=768}\n:::\n:::\n\n\n\n#### Part 2: Fishnet Grid Creation\n\n-   Create a 500m x 500m fishnet grid\n-   Aggregate your violations to grid cells\n-   Visualize the count distribution\n\n#### Part 3: Spatial Features\n\n-   Calculate k-nearest neighbor features\n-   Perform Local Moran's I analysis\n-   Identify hot spots and cold spots\n-   Create distance-to-hotspot measures\n-   Join any additional contextual data if you are looking for more to do and really get into this (e.g., demographics, land use)\n\n#### Part 4: Count Regression Models\n\n-   Fit Poisson regression\n-   Fit Negative Binomial regression\n-   Compare model fit (AIC)\n\n#### Part 5: Spatial Cross-Validation (2017)\n\n-   Implement Leave-One-Group-Out cross-validation on 2017 data\n-   Calculate and report error metrics (MAE, RMSE)\n\n#### Part 6: Model Evaluation\n\n-   Generate final predictions for both years\n-   Compare to KDE baseline\n-   Map prediction errors for 2018\n-   Assess model performance across time\n\n#### CHALLENGE TASK: Temporal Validation (2018) *not mandatory, only if you want very strong spatial analytics muscles*\n\n-   Download 2018 crimes https://data.cityofchicago.org/Public-Safety/Crimes-2018/3i3m-jwuy/about_data\n-   Be sure to filter for BURGLARIES (FORCED ENTRY only to match the 2017 data)\n-   Aggregate 2018 violations to the same fishnet grid\n-   Use your 2017 model to predict 2018 counts\n-   Calculate temporal validation metrics\n-   Compare spatial vs. temporal validation performance\n\n------------------------------------------------------------------------\n\n## Step 3: Write Your Analysis\n\n### Critical Requirement: Explain Each Step\n\n**For each major section, you must explain in your own words:**\n\n-   **What** you are doing in that step\n-   **Why** this step is important for the analysis\n-   **What** you found or learned from the results\n\nDo not simply copy text from the example or from your AI friend. Think about the purpose of each technique and articulate it in your own words.\n\n------------------------------------------------------------------------\n\n## Step 4: Format Your Document\n\n### Formatting Requirements\n\nYour knitted HTML document should be **professional and easy to read**:\n\n#### ✓ Clean Code\n\n-   Remove unnecessary code, comments, or debugging lines\n-   Keep only essential code chunks\n-   Use `code-fold: show` in your YAML header\n\n#### ✓ Clear Structure\n\n-   Use headers to organize sections\n-   Include a table of contents\n-   Add your name and date\n\n#### ✓ Readable Text\n\n-   Ensure all text renders properly (no broken markdown)\n-   Check that headers appear as headers (not plain text)\n-   Use proper markdown formatting\n\n#### ✓ Quality Visualizations\n\n-   All plots should have titles and labels\n-   Maps should be readable\n-   Use consistent color schemes\n\n#### ✓ Professional Presentation\n\n-   Proofread for typos\n-   Remove any \"Your answer here\" placeholders\n-   Make sure all code runs without errors\n-   Make IT NEAT. WE GOTTA LOOK GOOD HERE.\n\n------------------------------------------------------------------------\n\n## Submission Checklist\n\nBefore you submit, verify that your document includes:\n\n### Required Components\n\n-   [ ] **Introduction**: Brief description of your chosen 311 violation type and why you selected it\n-   [ ] **Data Exploration**: Maps and summary statistics of your violation data\n-   [ ] **Fishnet Grid**: Successfully created and visualized grid with aggregated counts\n-   [ ] **Spatial Features**: At least 2-3 spatial features calculated (k-NN, distance measures, etc.)\n-   [ ] **Local Moran's I**: Spatial autocorrelation analysis with interpretation\n-   [ ] **Count Regression**: Both Poisson and Negative Binomial models with comparison\n-   [ ] **Spatial Cross-Validation**: LOGO CV implemented on 2017 data with reported metrics\n-   [ ] **Temporal Validation**: 2018 data aggregated and tested with 2017 model(OPTIONAL.)\n-   [ ] **Validation Comparison**: Comparison of spatial vs. temporal validation performance\n-   [ ] **Model Comparison**: Your model vs. KDE baseline for 2018 predictions\n-   [ ] **Error Analysis**: Maps and discussion of where model performs well/poorly\n-   [ ] **Written Explanations**: Your own words explaining each step\n\n### Technical Requirements\n\n-   [ ] Document knits to HTML without errors\n-   [ ] Code is clean and well-organized\n-   [ ] All visualizations display properly\n-   [ ] Headers and formatting render correctly\n-   [ ] File is named successfully posted to your website\n\n------------------------------------------------------------------------\n",
    "supporting": [
      "Assignment4_Instructions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}