{
  "hash": "3dbc8a45d95c42845f846c10776f58d8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Safe Passage: Modeling Crime Risk around SEPTA Bus Stops\"\nauthor: \"Xinyuan Cui, Yuqing Yang, Jinyang Xu\"\nformat: \n  html:\n    code-fold: show\n    toc: true\n    toc-location: left\n    theme: cosmo\nexecute:\n  warning: false\n  message: false\n---\n\n预测“**客流带来的社会影响 (公共安全)**”，“**帮助警察部门救命**”。Shark Tank 的评委（通常是政府官员）会对“安全”话题极其敏感。\n\n核心问题： 客流大到底是带来了“街道眼 (Eyes on the Street)”从而抑制了犯罪，还是带来了更多的“潜在受害者 (Targets)”从而吸引了扒窃？\n\n政策目标： 帮助 SEPTA 警察部门 (Transit Police) 预测哪些站点周边是犯罪高风险区，从而优化巡逻警力部署。\n\n选题：做 **“Bus Ridership -\\> Crime”** 模型\n\n**因变量** (预测目标): 站点周边 400米内的犯罪数量 (Crime Incidents Count)\n\n**自变量**: Regional Rail Ridership: 使用你的 Regional_Rail_Station_Summary.csv。\n\n其他自变量: 人口统计 (Census): 贫困率、年轻男性比例。建成环境 (Built Env): 路灯密度 (Street Light Locations)、空置地块 (Vacant Land)。时间特征: 如果你做面板数据，可以加入周末/工作日。“诱发因子” ：**酒类销售点 (Alcohol Outlets):***数据源:* OpenDataPhilly (Liquor Licenses).+**商业密度 (Commercial Density):***数据源:* Land Use (Zoning) 或 OSM。**房屋空置率 (Vacancy Rate) / 311 投诉:***数据源:* OpenDataPhilly。**距离最近警局的距离 (Dist to Police Station):** *数据源:* OpenDataPhilly (Police Stations)。\n\n模型方法: Negative Binomial Regression (负二项回归): 犯罪数据也是计数数据，且离散度极高（很多地方没犯罪，少数地方特别多）。\n\nLocal Spatial Regression (GWR): 探索客流对犯罪的影响在不同社区是否不同？\n\nShark Tank Pitch: \"SEPTA 的首要任务是安全。我们的模型不预测有多少人坐车，而是预测哪里最需要警察。我们利用客流数据作为核心指标，识别出那些‘高客流但高犯罪’的异常站点，建议在此增加监控和巡逻。\"\n\n# Phase 1: Data Preparation\n\nThe primary dataset we use is 2025summer Septa bus ridership data.The\nvalidity of any predictive model rests on the quality of its underlying\ndata. In this initial phase, we focus strictly on data preparation and\nexploratory visualization. We load and clean the raw ridership, crime\ndataset and other datasets to handle missing values and outliers.\nThrough initial descriptive analytics and visualization, we assess the\nstatistical properties of our datasets.\n\n## 1.0 Complete data cleaning code\n\n***Load necessary libraries***\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tidycensus)\nlibrary(tigris)\noptions(tigris_use_cache = TRUE, tigris_class = \"sf\")\nlibrary(MASS)\nlibrary(spdep)\nlibrary(dplyr)\nlibrary(scales)\nlibrary(ggplot2)\nlibrary(caret)\nlibrary(nngeo)\nlibrary(car)\nlibrary(knitr)\nlibrary(readr)\nlibrary(patchwork)\nlibrary(kableExtra)\nlibrary(lubridate)\n\noptions(tigris_use_cache = TRUE)\noptions(tigris_progress = FALSE)  \n```\n:::\n\n\n***Define themes***\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n:::\n\n\n## **1.1 Load and clean bus stop ridership data:**\n\n### 1.1.1 Load bus stop ridership data\n\n[2025 summer SEPTA bus ridership data](https://opendataphilly.org/datasets/septa-ridership-statistics/)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Load Bus Data\nbus_raw <- read_csv(\"data/Summer_2025_Stop_Summary_(Bus).csv\")\n```\n:::\n\n\n### 1.1.2 Clean\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2. Get Philadelphia Boundary\nphilly_boundary <- counties(state = \"PA\", cb = TRUE, class = \"sf\") %>%\n  filter(NAME == \"Philadelphia\") %>%\n  st_transform(2272)\n```\n:::\n\n\nIn preparing the ridership data, we performed two critical structural\ntransformations to align with our research goals.   \nFirst, we **aggregated bidirectional stops** sharing the same location (including opposite sides of a street) into single spatial units. This prevents spatial autocorrelation and ensures our 400m buffers capture a unique street environment.  \nSecond, we **restructured the dataset into a ‘long format’ (panel data)**, distinguishing between Weekday and Weekend ridership. This temporal split is vital, as it allows our model to capture the distinct behavioral patterns of both commuters and potential offenders during different times of the week.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 3. Process Ridership: Create Long Format (Aggregated + Weekday vs Weekend)\nbus_long <- bus_raw %>%\n  # A. 基础清洗\n  filter(!is.na(Lat) & !is.na(Lon)) %>%\n  \n  # B. 预计算每个物理站牌的客流 (Pre-calculate per stop_code)\n  mutate(\n    Raw_Weekday = Weekdays_O + Weekdays_1,\n    # Weekend average = (Sat total + Sun total) / 2\n    Raw_Weekend = (Saturdays_ + Saturdays1 + Sundays_On + Sundays_Of) / 2\n  ) %>%\n  \n  # C. [新增步骤] 聚合双向站点 (Aggregation by Stop Name)\n  # 这一步把同名的站点（比如 \"Broad St & Walnut St\" 的双向）合二为一\n  group_by(Stop) %>% \n  summarise(\n    # 两个方向的客流相加\n    Ridership_Weekday = sum(Raw_Weekday, na.rm = TRUE),\n    Ridership_Weekend = sum(Raw_Weekend, na.rm = TRUE),\n    # 坐标取平均值\n    Lat = mean(Lat, na.rm = TRUE),\n    Lon = mean(Lon, na.rm = TRUE),\n    # 保留一个 Stop_Code 作为 ID\n    Stop_Code = first(Stop_Code),\n    .groups = \"drop\"\n  ) %>%\n  \n  # D. Pivot to Long Format (把宽数据变长数据)\n  # 现在每个站点会变成两行：一行 Weekday，一行 Weekend\n  pivot_longer(\n    cols = c(Ridership_Weekday, Ridership_Weekend),\n    names_to = \"Time_Type\",\n    values_to = \"Ridership\"\n  ) %>%\n  \n  # E. Create Dummy Variable & Clean up\n  mutate(\n    is_weekend = if_else(Time_Type == \"Ridership_Weekend\", 1, 0),\n    Time_Category = if_else(is_weekend == 1, \"Weekend\", \"Weekday\")\n  ) %>%\n  \n  # F. Convert to SF & Clip\n  st_as_sf(coords = c(\"Lon\", \"Lat\"), crs = 4326) %>%\n  st_transform(2272) %>%\n  st_intersection(philly_boundary) %>%\n  dplyr::select(Stop_Code, Stop, Ridership, is_weekend, Time_Category, geometry)\n\n# Check results\ncat(\"Total Aggregated Stops (Unique Locations):\", nrow(bus_long) / 2, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal Aggregated Stops (Unique Locations): 5884 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Total Observation Rows (Panel Data):\", nrow(bus_long), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal Observation Rows (Panel Data): 11768 \n```\n\n\n:::\n:::\n\n\n### 1.1.3 Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Prepare Base Map (Philly Boundary)\n# 确保之前已经加载了 tigris 包并获取了边界\n# philly_boundary <- counties(state = \"PA\", cb = TRUE, class = \"sf\") %>%\n#   filter(NAME == \"Philadelphia\") %>%\n#   st_transform(2272)\n\n# 2. Plot the Map\nggplot() +\n  # A. Base Layer: Philadelphia County Background\n  geom_sf(data = philly_boundary, \n          fill = \"grey98\", \n          color = \"grey50\", \n          size = 0.5) +\n  \n  # B. Station Layer: Simple Points\n  # [修改点] 只筛选 Weekday 的行来画图，避免每个点画两次导致重叠\n  geom_sf(data = bus_long %>% filter(is_weekend == 0), \n          color = \"#3182bd\",  # SEPTA Blue\n          size = 0.1,         # Small dots to avoid clutter\n          alpha = 0.6) +      # Slight transparency\n  \n  # C. Styling\n  labs(\n    title = \"Spatial Coverage of SEPTA Bus Network\",\n    # [修改点] 修正 nrow 除法的语法\n    subtitle = paste0(\"Total Aggregated Stops: \", nrow(bus_long) / 2),\n    caption = \"Source: SEPTA Summer 2025 Stop Summary\"\n  ) +\n  theme_void() + # Clean look\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 10, color = \"grey40\", hjust = 0.5),\n    plot.margin = margin(1, 1, 1, 1, \"cm\")\n  )\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/map_stations-1.png){width=672}\n:::\n:::\n\n\nThe figure illustrates the extensive spatial coverage of the SEPTA bus network within Philadelphia. After aggregating bidirectional stops, our study includes **5,884 unique locations**.  \nThe distribution reveals **a high density in the Center City** and **a grid-like arterial pattern extending into residential neighborhoods**. This\ncomprehensive coverage ensures that our analysis captures a diverse range of built environments, from dense commercial districts to suburban residential areas.\n\n## **1.2 Load and clean secondary dataset:**\n\n### 1.2.1 Crime data:\n\n[Crime Incidents from 2024](https://opendataphilly.org/datasets/crime-incidents/)\n\nWe excluded domestic disputes or indoor financial crimes because SEPTA Transit Police cannot police inside people's homes. Instead, we selected these specific crime types because they occur in the public right-of-way and directly impact a rider's decision to use public transit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### 1.2.1 Crime data:\n\n# 定义“街头犯罪”列表 (排除室内/家庭纠纷/非蓄意犯罪)\n# target_crime_types <- c(\n#   \"Robbery Firearm\",\n#   \"Robbery No Firearm\",\n#   \"Aggravated Assault Firearm\",\n#   \"Aggravated Assault No Firearm\",\n#   \"Homicide - Criminal\",\n#   \"Rape\",\n#   \"Other Sex Offenses (Not Commercialized)\",\n#   \"Weapon Violations\",\n#   \"Narcotic / Drug Law Violations\",\n#   \"Vandalism/Criminal Mischief\",\n#   \"Prostitution and Commercialized Vice\",\n#   \"Public Drunkenness\"\n# )\n\ncrime_raw <- read_csv(\"data/crime2024.csv\")\n\n# Filter & Transform\ncrime_raw <- crime_raw %>%\n  filter(!is.na(lat) & !is.na(lng))\n\n# 2. 单独保存 1–3 月的数据\ncrime_q1 <- crime_raw %>%\n  filter(lubridate::month(dispatch_date) %in% 1:3) %>%\n  mutate(\n    crime_date = as.Date(dispatch_date), \n    day_of_week = wday(crime_date), # 1 is Sunday, 7 is Saturday\n    is_crime_weekend = if_else(day_of_week %in% c(1, 7), 1, 0)\n  ) %>%\n    \n  st_as_sf(coords = c(\"lng\", \"lat\"), crs = 4326) %>%\n  st_transform(2272)  \n\n # 1. 筛选 4–6 月\ncrime_sf <- crime_raw %>%\n  filter(lubridate::month(dispatch_date) %in% 4:6)%>%\n\n  # 1. 筛选：只保留列表中的犯罪类型\n  #filter(text_general_code %in% target_crime_types) %>%\n  \n  # 2. 时间特征处理\n  mutate(\n    crime_date = as.Date(dispatch_date), \n    day_of_week = wday(crime_date), # 1 is Sunday, 7 is Saturday\n    is_crime_weekend = if_else(day_of_week %in% c(1, 7), 1, 0)\n  ) %>%\n  \n  st_as_sf(coords = c(\"lng\", \"lat\"), crs = 4326) %>%\n  st_transform(2272)\n\n# 打印检查\ncat(\"Total Selected Crimes (Count):\", nrow(crime_sf), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal Selected Crimes (Count): 24184 \n```\n\n\n:::\n:::\n\n\n### 1.2.2 Census data (tidycensus):\n\nTo isolate the true impact of transit ridership on crime, we must first account for the socio-economic context of the neighborhood. A bus stop in a distressed area faces different risks than one in a wealthy suburb.  \nBy integrating 2023 ACS Census data, we control for structural disadvantages—such as poverty rates, unemployment, and housing vacancy.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_api_key(\"42bf8a20a3df1def380f330cf7edad0dd5842ce6\", overwrite = TRUE, install = TRUE)\n```\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load Census data for Philadelphia tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    total_pop = \"B01003_001\",\n    poverty_pop = \"B17001_002\",\n    med_income = \"B19013_001\",\n    ba_degree = \"B15003_022\",\n    total_edu = \"B15003_001\",\n    labor_force = \"B23025_003\",\n    unemployed = \"B23025_005\",\n    total_housing = \"B25002_001\",\n    vacant_housing = \"B25002_003\"\n  ),\n  year = 2023, \n  state = \"PA\",\n  county = \"Philadelphia\",\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  st_transform(2272) %>%\n  mutate(\n    # 注意：所有变量名后面都要加 \"E\"\n    Poverty_Rate = poverty_popE / total_popE,\n    Med_Income = med_incomeE,\n    \n    # 修正部分：加上 E\n    ba_rate = 100 * ba_degreeE / total_eduE,\n    unemployment_rate = 100 * unemployedE / labor_forceE,\n    vacancy_rate = 100 * vacant_housingE / total_housingE\n  ) %>%\n  dplyr::select(GEOID, Poverty_Rate, Med_Income, ba_rate, unemployment_rate, vacancy_rate)\n```\n:::\n\n\n### 1.2.3 Spatial amenities\n\nWe ingest data from OpenDataPhilly to capture the built environment's impact on safety. This includes `Alcohol Outlets` (potential crime generators), `Street Lights` (natural surveillance/visibility) and `Police Stations` (formal guardianship/deterrence).  \n\n- [Alcohol Outlets](https://github.com/mafichman/cpln_6890/blob/main/plcb_licenses/PHL_PLCB_geocoded.csv)\n\n- [Street Poles](https://opendataphilly.org/datasets/street-poles/)\n\n- [Police Stations](https://opendataphilly.org/datasets/police-stations/)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A. Alcohol Outlets (Crime Generators)\nalcohol_sf <- read_csv(\"data/PHL_PLCB_geocoded.csv\") %>%\n  filter(!is.na(lon) & !is.na(lat)) %>%\n  st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326) %>%\n  st_transform(2272)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# B. Street Lights (Guardianship)\nlights_sf <- read_csv(\"data/Street_Poles.csv\") %>%\n  filter(!is.na(X) & !is.na(Y)) %>%\n  # 修正：原始坐标是 EPSG:3857 (Web Mercator)\n  st_as_sf(coords = c(\"X\", \"Y\"), crs = 3857) %>%\n  # 然后再转为费城投影\n  st_transform(2272)\n```\n:::\n\nProximity to police stations acts as a proxy for formal guardianship. We load these coordinates to later calculate the distance-based deterrence effect.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# C. Police Stations (Guardianship) \n# 直接读取包含坐标的 GeoJSON 文件\npolice_sf <- st_read(\"data/Police_Stations.geojson\", quiet = TRUE) %>%\n  st_transform(2272) # 统一转为 PA State Plane\n\ncat(\"Total Police Stations:\", nrow(police_sf))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal Police Stations: 20\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Phase 2: Feature Engineering\n\nPhase 2 transforms our raw spatial data into analytical features. A bus stop is not just a point on a map; it is the center of a dynamic micro-environment. To capture this, we employ a **400-meter buffer** approach—roughly equivalent to a **5-minute walk**, defining the 'catchment area' for each station.  \n\nAfter that, we shift our focus to investigating the aggregate relationships between our independent variables (e.g., ridership, built environment) and the dependent variable (crime counts). This exploratory analysis allows us to observe baseline correlations and structural patterns, providing the necessary empirical support for our subsequent **Negative Binomial modeling**.\n\n## **2.1 Buffer creation:**\n\n### 2.1.1 公交站400m buffer\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create Buffer(400m)\nbus_buffer <- st_buffer(bus_long, 1312)\n```\n:::\n\n\n### 2.1.2 Crime numbers\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### 2.1.2 Crime numbers (Corrected with Normalization)\n\n# 1. 计算数据集中包含的“总天数” (Exposure)\n# 这一步会自动计算你的 crime_sf 数据里涵盖了多少个工作日，多少个周末\nday_counts <- crime_sf %>%\n  st_drop_geometry() %>%\n  group_by(is_crime_weekend) %>%\n  summarise(n_days = n_distinct(crime_date)) # 统计有多少个不重复的日期\n\n# 打印天数检查 (你会发现 Weekday 天数大约是 Weekend 的 2.5 倍)\nprint(day_counts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  is_crime_weekend n_days\n             <dbl>  <int>\n1                0     65\n2                1     26\n```\n\n\n:::\n\n```{.r .cell-code}\n# 2. 关联并计算日均犯罪 (Rate)\ncrime_agg <- st_join(bus_buffer, crime_sf, join = st_intersects) %>%\n  filter(is_weekend == is_crime_weekend) %>%\n  group_by(Stop_Code, is_weekend) %>%\n  summarise(\n    Crime_Total_Count = n() # 原始总数 (用于模型)\n  ) %>%\n  st_drop_geometry() %>%\n  # 把天数信息 join 进来\n  left_join(day_counts, by = c(\"is_weekend\" = \"is_crime_weekend\")) %>%\n  mutate(\n    # 关键修正：计算日均犯罪量\n    Crime_Daily_Rate = Crime_Total_Count / n_days,\n    \n    # 同时也保留 n_days，因为负二项回归模型需要它作为 offset\n    Exposure_Days = n_days\n  )\n\n# 检查结果\nhead(crime_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n# Groups:   Stop_Code [3]\n  Stop_Code is_weekend Crime_Total_Count n_days Crime_Daily_Rate Exposure_Days\n      <dbl>      <dbl>             <int>  <int>            <dbl>         <int>\n1         2          0                11     65           0.169             65\n2         2          1                 2     26           0.0769            26\n3         4          0                70     65           1.08              65\n4         4          1                26     26           1                 26\n5         5          0               102     65           1.57              65\n6         5          1                34     26           1.31              26\n```\n\n\n:::\n:::\n\n### 2.1.3 Spatial Feature\n\nWe know that a dangerous corner doesn't become safe overnight. To make our model fair, we must acknowledge that some stops have a history of trouble.  \n\nWe calculated the crime counts for each stop **from the previous season (Q1)**. We try to explain: 'Given how dangerous this spot usually is, does adding more bus riders make it safer or worse?'\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### 2.1.2 Lag Crime numbers (Corrected with Normalization)\n\n# 1. 计算 Q1 数据集中包含的“总天数” (Exposure)\nday_counts_q1 <- crime_q1 %>%\n  st_drop_geometry() %>%\n  group_by(is_crime_weekend) %>%\n  summarise(n_days_lag = n_distinct(crime_date)) \n\n# 打印天数检查\nprint(day_counts_q1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  is_crime_weekend n_days_lag\n             <dbl>      <int>\n1                0         65\n2                1         26\n```\n\n\n:::\n\n```{.r .cell-code}\n# 2. 关联并计算日均犯罪 (Rate) —— 完全复制你的 Q2 逻辑\ncrime_lag_q1 <- st_join(bus_buffer, crime_q1, join = st_intersects) %>%\n  filter(is_weekend == is_crime_weekend) %>%\n  group_by(Stop_Code, is_weekend) %>%\n  summarise(\n    Crime_Total_Count_lag = n()   # lag 原始总数\n  ) %>%\n  st_drop_geometry() %>%\n  left_join(day_counts_q1, by = c(\"is_weekend\" = \"is_crime_weekend\")) %>%\n  mutate(\n    Crime_Daily_Rate_lag = Crime_Total_Count_lag / n_days_lag,\n    Exposure_Days_lag    = n_days_lag\n  )\n\n# 检查结果\nhead(crime_lag_q1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n# Groups:   Stop_Code [3]\n  Stop_Code is_weekend Crime_Total_Count_lag n_days_lag Crime_Daily_Rate_lag\n      <dbl>      <dbl>                 <int>      <int>                <dbl>\n1         2          0                     5         65               0.0769\n2         2          1                     2         26               0.0769\n3         4          0                    63         65               0.969 \n4         4          1                    26         26               1     \n5         5          0                    52         65               0.8   \n6         5          1                    27         26               1.04  \n# ℹ 1 more variable: Exposure_Days_lag <int>\n```\n\n\n:::\n:::\n\n\n\n### 2.1.3 POI Numbers（酒类销售点）\n\nAlcohol outlets are established 'crime generators.' We load their locations to model areas with higher potential for intoxication-related conflicts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2. Count Alcohol Outlets\nalcohol_agg <- st_join(bus_buffer, alcohol_sf, join = st_intersects) %>%\n  # 按 Stop 和 时间类型分组，这样每一行都会得到计数\n  group_by(Stop_Code, is_weekend) %>%\n  summarise(Alcohol_Count = n() - 1) %>% # Subtract 1 because st_join is left join (self-intersection NA check)\n  st_drop_geometry()\n```\n:::\n\n\n### 2.1.4 Infrastructure Numbers（路灯密度）\n\nStreet lighting is a key component of CPTED (Crime Prevention Through Environmental Design). We process the location of street poles to estimate visibility and natural surveillance levels.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 3. Count Street Lights\nlight_agg <- st_join(bus_buffer, lights_sf, join = st_intersects) %>%\n  group_by(Stop_Code, is_weekend) %>%\n  summarise(Light_Count = n() - 1) %>%\n  st_drop_geometry()\n```\n:::\n\n\n### 2.1.5 Census Demographics\n\nTo control for neighborhood context, we calculated the average:  \n- `Avg_Poverty`: Rate of economic deprivation.  \n- `Avg_Income`: Proxy for local wealth and resources.  \n- `Avg_BA`: Educational attainment.  \n- `Avg_Unemployment`: Measure of labor market instability.  \n- `Avg_Vacancy`: Indicator of physical disorder.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 4. Average Census Demographics\ncensus_agg <- st_join(bus_buffer, philly_census, join = st_intersects) %>%\n  group_by(Stop_Code, is_weekend) %>%\n  summarise(\n    Avg_Poverty = mean(Poverty_Rate, na.rm = TRUE),\n    Avg_Income = mean(Med_Income, na.rm = TRUE),\n    Avg_BA = mean(ba_rate, na.rm = TRUE),\n    Avg_Unemployment = mean(unemployment_rate, na.rm = TRUE),\n    Avg_Vacancy = mean(vacancy_rate, na.rm = TRUE)\n  ) %>%\n  st_drop_geometry()\n```\n:::\n\n\n## **2.2 k-Nearest Neighbor features:**\n\n### 2.2.1 Police station (KNN-1)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate distance to nearest police station\ndist_matrix <- st_distance(bus_long, police_sf)\n\n# 取每一行的最小值，并换算成英里\nbus_long$Dist_Police <- apply(dist_matrix, 1, min) / 5280\n```\n:::\n\n\n## 2.3 Get Police Service Area (PSA) ID for Fixed Effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. 加载 PSA 边界数据\n# 请确保文件名跟你下载的一致\npsa_sf <- st_read(\"data/Boundaries_PSA.geojson\", quiet = TRUE) %>%\n  st_transform(2272) %>% # 统一坐标系\n  # 费城 PSA 数据中，唯一的 ID 通常叫 \"PSA_NUM\" 或 \"PSA_NAME\"\n  # 我们这里假设它叫 \"PSA_NUM\" (例如 241, 143 等)\n  # 如果你的列名不一样，请运行 names(psa_sf) 检查并修改下面这一行\n  dplyr::select(PSA_ID = PSA_NUM) \n\n# 2. 空间匹配：判断每个公交站属于哪个 PSA\n# 注意：只取 weekday=0 的数据来做空间匹配，避免重复计算\nstop_psa_mapping <- bus_long %>%\n  filter(is_weekend == 0) %>% \n  st_join(psa_sf) %>% # 空间连接：点找面\n  st_drop_geometry() %>%\n  dplyr::select(Stop_Code, PSA_ID) %>%\n  # 以防万一某个点在边界上匹配到了两个区，去重保留第一个\n  distinct(Stop_Code, .keep_all = TRUE)\n\ncat(\"PSA mapping created for\", nrow(stop_psa_mapping), \"stops.\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPSA mapping created for 5884 stops.\n```\n\n\n:::\n\n```{.r .cell-code}\n# 打印一下看看长什么样，确保 ID 是存在的\nhead(stop_psa_mapping)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  Stop_Code PSA_ID\n      <dbl> <chr> \n1       759 033   \n2     16397 251   \n3     17921 351   \n4     16054 352   \n5     16102 221   \n6     16104 221   \n```\n\n\n:::\n:::\n\n\n## 2.4 Merge Features into Master Dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_data <- bus_long %>%\n  # Join all aggregated tables\n  left_join(crime_agg,     by = c(\"Stop_Code\", \"is_weekend\")) %>%\n  left_join(crime_lag_q1,  by = c(\"Stop_Code\", \"is_weekend\")) %>%\n  left_join(alcohol_agg,   by = c(\"Stop_Code\", \"is_weekend\")) %>%\n  left_join(light_agg,     by = c(\"Stop_Code\", \"is_weekend\")) %>%\n  left_join(census_agg,    by = c(\"Stop_Code\", \"is_weekend\")) %>%\n  \n  # --- [修改点] Join PSA ID (原为 GEOID) ---\n  left_join(stop_psa_mapping, by = \"Stop_Code\") %>%\n  \n   mutate(\n    # 1. Handle NAs for Counts\n    Crime_Total_Count = replace_na(Crime_Total_Count, 0),\n    Crime_Daily_Rate  = replace_na(Crime_Daily_Rate, 0),\n\n    # ⭐ 处理 lag crime 的 NA（如果某站点 Q1 没犯罪）\n    Crime_Total_Count_lag = replace_na(Crime_Total_Count_lag, 0),\n    Crime_Daily_Rate_lag  = replace_na(Crime_Daily_Rate_lag, 0),\n\n    Alcohol_Count = replace_na(Alcohol_Count, 0),\n    Light_Count   = replace_na(Light_Count, 0),\n    \n    # 2. Log transform Ridership\n    Log_Ridership = log(Ridership + 1),\n    \n    # 3. Create Factor for Interaction Term\n    is_weekend_factor = factor(is_weekend, levels = c(0, 1), \n                               labels = c(\"Weekday\", \"Weekend\")),\n\n  ) %>%\n  \n  # 5. Clean up\n  # [修改点] 过滤掉没有匹配到 PSA 的站点 (原为 !is.na(GEOID))\n  filter(!is.na(PSA_ID)) %>%\n  na.omit() \n\ncat(\"Final Panel Dataset Rows:\", nrow(final_data))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFinal Panel Dataset Rows: 11066\n```\n\n\n:::\n:::\n\n\n## 2.5 检查PSA数据密度\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. 统计每个 PSA 有多少个样本 (Panel Data Rows)\npsa_counts <- final_data %>%\n  group_by(PSA_ID) %>%\n  summarise(\n    n_observations = n(),              # 总行数 (weekday + weekend)\n    n_stops = n_distinct(Stop_Code)    # 物理站点数\n  ) %>%\n  arrange(n_observations)\n\n# 2. 打印最少样本的 10 个 PSA\nprint(head(psa_counts, 10))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 10 features and 3 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 2669882 ymin: 215531.6 xmax: 2715062 ymax: 279357.4\nProjected CRS: NAD83 / Pennsylvania South (ftUS)\n# A tibble: 10 × 4\n   PSA_ID n_observations n_stops                                        geometry\n   <chr>           <int>   <int>                   <MULTIPOINT [US_survey_foot]>\n 1 122                32      16 ((2670537 223892.4), (2670585 223932.8), (2670…\n 2 124                58      29 ((2671643 232878.2), (2672084 233106.1), (2672…\n 3 053                68      42 ((2670063 279330.9), (2670112 279357.4), (2670…\n 4 012                83      44 ((2685082 218564.9), (2685568 218997.3), (2686…\n 5 224                86      43 ((2686092 246848.8), (2686176 246409.7), (2686…\n 6 393                90      45 ((2688934 252812), (2688968 253070.2), (268922…\n 7 181                96      48 ((2669882 237256), (2669902 237214.7), (266998…\n 8 243                96      49 ((2706035 247307.4), (2706350 248302.6), (2706…\n 9 242                98      49 ((2702265 250424.1), (2702297 250520.3), (2702…\n10 052                99      50 ((2671211 266842), (2671303 266812.6), (267140…\n```\n\n\n:::\n\n```{.r .cell-code}\n# 3. 这里的判断标准：\n# 如果 n_observations 最小的值都 > 5，恭喜你，CV 问题基本解决！\n# 如果还是有 1 或 2，那 CV 依然可能会报错，但概率比 Tract 小多了。\n```\n:::\n\n\n\n------------------------------------------------------------------------\n\n# Phase 3: Exploratory Data Analysis\n\n## 3.1 Distribution of Crime and Bus Stop Ridership (histogram)\n\nDoes ridership follow a normal distribution? No. That's why we need Negative Binomial.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gridExtra)\np1 <- ggplot(final_data, aes(x = Ridership)) +\n  geom_histogram(fill = \"#3182bd\", bins = 50) +\n  labs(title = \"Distribution of Ridership\", x = \"Daily Boardings\") + plotTheme\n\np2 <- ggplot(final_data, aes(x = Crime_Total_Count)) +\n  geom_histogram(fill = \"#de2d26\", bins = 50) +\n  labs(title = \"Distribution of Crime\", x = \"Crime Count (400m)\") + plotTheme\n\ngrid.arrange(p1, p2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nThe histograms reveal that both Ridership (Left) and Crime Counts (Right) follow **a highly right-skewed, 'long-tail' distribution**, rather than a normal bell curve. This extreme skewness mathematically confirm that a standard OLS Linear Regression would be biased.   \n\nThis visual evidence creates a compelling mandate for using **Negative Binomial Regression**, which is specifically designed to handle such skewed count data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 检查均值和方差\nmean_crime <- mean(final_data$Crime_Total_Count, na.rm = TRUE)\nvar_crime <- var(final_data$Crime_Total_Count, na.rm = TRUE)\n\ncat(\"Mean:\", mean_crime, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean: 30.91478 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Variance:\", var_crime, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nVariance: 1190.485 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Ratio (Var/Mean):\", var_crime / mean_crime, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRatio (Var/Mean): 38.50861 \n```\n\n\n:::\n:::\n\n\nWhile many bus stops have zero incidents, a few 'hotspots' have very high counts. This causes **the variance to be much larger than the mean**.\nTo address this overdispersion，which violates the core assumption of Poisson regression， we employed a **Negative Binomial model**. This approach allows us to model the data more accurately without inflating the significance of our findings.\n\n## 3.2 Spatial distribution of crime and Bus Stop Ridership(map)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 需要先加载 patchwork 包，如果前面没加载，这里补充一下\n# library(patchwork) \n\n# --- 1. 准备绘图数据 (Extract Coordinates) ---\n\n# A. 处理公交数据：只取工作日数据以避免重复，并提取坐标\nbus_plot_data <- bus_long %>%\n  filter(is_weekend == 0) %>%   # 仅使用工作日数据代表典型客流\n  mutate(\n    X = st_coordinates(geometry)[,1],\n    Y = st_coordinates(geometry)[,2]\n  ) %>%\n  st_drop_geometry() # 移除几何列，方便 stat_density_2d 使用\n\n# B. 处理犯罪数据：提取坐标\ncrime_plot_data <- crime_sf %>%\n  mutate(\n    X = st_coordinates(geometry)[,1],\n    Y = st_coordinates(geometry)[,2]\n  ) %>%\n  st_drop_geometry()\n\n# --- 2. 绘制图形 (Create Maps) ---\n\n# 左图：客流热力图 (Ridership Density)\n# 注意：aes(weight = Ridership) 是关键，让热力图基于客流量而不是站点数量\np_ridership <- ggplot() +\n  # 底图：费城轮廓\n  geom_sf(data = philly_boundary, fill = \"#f5f5f5\", color = \"grey80\") +\n  # 热力层\n  stat_density_2d(\n    data = bus_plot_data, \n    aes(x = X, y = Y, fill = ..level.., weight = Ridership), \n    geom = \"polygon\", \n    alpha = 0.75\n  ) +\n  # 配色：蓝色系 (代表正常活动)\n  scale_fill_distiller(palette = \"Blues\", direction = 1, guide = \"none\") +\n  labs(\n    title = \"Weekday Ridership Hotspots\", \n    subtitle = \"High Transit Activity Zones\"\n  ) +\n  mapTheme\n\n# 右图：犯罪热力图 (Crime Density)\np_crime_map <- ggplot() +\n  # 底图\n  geom_sf(data = philly_boundary, fill = \"#f5f5f5\", color = \"grey80\") +\n  \n  # 热力层 (修改部分)\n  stat_density_2d(\n    data = crime_plot_data, \n    aes(x = X, y = Y, fill = ..level..), \n    geom = \"polygon\", \n    alpha = 0.4,       # 1. 调低透明度，减少\"硬边\"的感觉\n    bins = 30,         # 2. 增加层数，让过渡更平滑 (原来默认很少)\n    adjust = 0.5       # 3. 调低带宽 (0.5), 让热力点收缩，更聚焦局部热点\n  ) +\n  \n  # 配色\n  scale_fill_distiller(palette = \"Reds\", direction = 1, guide = \"none\") +\n  labs(\n    title = \"Crime Hotspots\", \n    subtitle = \"High Incident Zones\"\n  ) +\n  mapTheme\n\n# --- 3. 组合展示 (Combine Side-by-Side) ---\n\n# 使用 patchwork 进行拼接\ncombined_map <- p_ridership + p_crime_map +\n  plot_annotation(\n    title = \"Spatial Mismatch Analysis: Eyes on the Street vs. Targets?\",\n    subtitle = \"Left: Where people are (Ridership) | Right: Where crimes happen\",\n    theme = theme(\n      plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n      plot.subtitle = element_text(size = 12, color = \"grey40\", hjust = 0.5)\n    )\n  )\n\n# 输出图形\ncombined_map\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nTransit activity is **anchored in Center City** and **radiates outward along the major arterials** (Broad St.and Market St.). However, crime exhibits a **polycentric distribution**. Beyond the city center, we observe significant  high-crime clusters in North and West Philadelphia (Kensington/Allegheny).  \n\nThis spatial mismatch suggests that **ridership volume alone cannot explain crime risk**. While the downtown core attracts crime due to sheer foot traffic ('Targets'), the peripheral hotspots are likely driven by other environmental factors—such as socioeconomic disadvantage or the presence of crime generators (e.g., alcohol outlets)—rather than transit volume alone.\n\n## 3.3 Crime vs. Bus Stop Ridership (scatter plots)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- 1. 准备绘图数据 ---\n# 我们需要计算“日均”数值，以保证公平比较 (因为工作日有5天，周末只有2天，不能比总数)\nbar_plot_data <- final_data %>%\n  st_drop_geometry() %>% # 移除空间属性，加快处理\n  group_by(is_weekend_factor) %>% # 按 Weekday/Weekend 分组\n  summarise(\n    # 计算平均每个站点的日均客流\n    Avg_Ridership = mean(Ridership, na.rm = TRUE), # 如果原数据是 Log，记得还原，或者直接用原始 Ridership 列\n    # 计算平均每个站点的日均犯罪\n    Avg_Crime_count = mean(Crime_Daily_Rate, na.rm = TRUE)\n  ) %>%\n  #以此转换为长数据，方便 ggplot 分面画图\n  pivot_longer(\n    cols = c(Avg_Ridership, Avg_Crime_count),\n    names_to = \"Metric\",\n    values_to = \"Value\"\n  ) %>%\n  mutate(\n    # 修改标签名，让图表更好看\n    Metric_Label = case_when(\n      Metric == \"Avg_Ridership\" ~ \"Average Ridership\",\n      Metric == \"Avg_Crime_count\" ~ \"Average Crime Count\"\n    )\n  )\n\n# --- 2. 绘制图形 ---\nggplot(bar_plot_data, aes(x = is_weekend_factor, y = Value, fill = is_weekend_factor)) +\n  geom_col(width = 0.6, alpha = 0.9) +\n  \n  facet_wrap(~Metric_Label, scales = \"free_y\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#3182bd\", \"Weekend\" = \"#de2d26\")) +\n  \n  # 标签和主题\n  labs(\n    title = \"Volume vs. Risk: Weekday vs. Weekend\",\n    subtitle = \"Comparison of Average  Ridership and Crime per Stop\",\n    x = \"\", \n    y = \"Average Count\",\n    fill = \"Time Period\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 10, color = \"grey40\", hjust = 0.5),\n    strip.text = element_text(size = 12, face = \"bold\"), # 分面标题字体\n    axis.text.x = element_text(size = 11, face = \"bold\"),\n    legend.position = \"none\" # \n  )\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Crime vs. Ridership (Interaction Plot)\n# 这是一个非常关键的图，用于验证你的核心假设：周末的客流影响是否不同？\n\nggplot(final_data, aes(x = Log_Ridership, y = Crime_Daily_Rate, color = is_weekend_factor)) +\n  geom_point(alpha = 0.1, size = 1) +\n  geom_smooth(method = \"glm\", method.args = list(family = \"quasipoisson\"), se = TRUE) +\n  scale_color_manual(values = c(\"Weekday\" = \"#3182bd\", \"Weekend\" = \"#de2d26\")) +\n  labs(\n    title = \"Does Ridership impact Crime differently on Weekends?\",\n    subtitle = \"Interaction Effect (Normalized by Number of Days)\",\n    x = \"Log(Daily Ridership)\",\n    y = \"Average Daily Crime Count (per 400m)\", # 修改 Y 轴标签\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/eda_interaction-1.png){width=672}\n:::\n:::\n\n\n- **Crime Follows the Crowd (Bar Chart):**  \nThe left bar charts show that crime volume drops significantly on weekends, mirroring the drop in ridership shown in the right chart. This confirms that crime is likely driven by opportunity—fewer people on the street simply means fewer targets and fewer conflicts.\n\n- **The Risk \"Conversion Rate\" is Constant (Scatter Plot):**   \nThe interaction plot reveals **a consistent positive correlation** between ridership and crime counts across both weekdays and weekends. While the slopes exhibit only minor differences, the methodological value of this split is significant. By comparing the same bus stops during different time periods (Weekday vs. Weekend), we **inherently control for static environmental factors**, such as poverty rates, street lighting, and proximity to alcohol outlets, which remain constant regardless of the day.  \nConsequently, this acts as a quasi-experimental control: since the physical environment is fixed, the persistent upward trend suggests that **ridership itself is a direct driver of crime risk**. This supports the 'Targets' hypothesis over the 'Eyes on the Street' theory, indicating that higher passenger volumes attract opportunistic crime regardless of the temporal context.\n\n## 3.4 Crime vs. Spatial & Social features (scatter plots)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\nlibrary(scales)\n\n# 为了可视化清晰，我们先创建一个带有 log(crime) 的临时绘图数据\nplot_data <- final_data %>%\n  mutate(\n    log_crime = log(Crime_Daily_Rate + 0.01), # +1 避免 log(0)\n    # 给 Income 取个 log 看看是否更线性，很多经济学变量 log 后效果更好\n    log_income = log(Avg_Income + 1)\n  )\n\n# --- 1. POI & Infrastructure (Built Environment) ---\n\n# A. Alcohol Outlets (线性还是指数增加？)\np1 <- ggplot(plot_data, aes(x = Alcohol_Count, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#6A1B9A\") +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Log(Crime) vs. Alcohol Outlets\",\n       subtitle = \"Check for diminishing returns\",\n       x = \"Count of Alcohol Outlets\", y = \"Log(Crime Count)\") +\n  plotTheme\n\n# B. Street Lights (路灯越多越安全？还是路灯只出现在繁华区？)\np2 <- ggplot(plot_data, aes(x = Light_Count, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#6A1B9A\") +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Log(Crime) vs. Street Lights\",\n       subtitle = \"Is the relationship linear?\",\n       x = \"Count of Street Lights\", y = \"\") +\n  plotTheme\n\n# C. Distance to Police (离警局越远越危险？)\np3 <- ggplot(plot_data, aes(x = Dist_Police, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#6A1B9A\") +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Log(Crime) vs. Dist to Police\",\n       subtitle = \"Check for U-shape or threshold\",\n       x = \"Distance to Station (Miles)\", y = \"\") +\n  plotTheme\n\n# --- 2. Demographics (Census) ---\n\n# D. Poverty Rate (贫困率与犯罪)\np4 <- ggplot(plot_data, aes(x = Avg_Poverty, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#3182bd\") +\n  geom_smooth(method = \"loess\", color = \"orange\", se = FALSE) +\n  scale_x_continuous(labels = scales::percent) +\n  labs(title = \"Log(Crime) vs. Poverty Rate\",\n       x = \"Poverty Rate\", y = \"Log(Crime Count)\") +\n  plotTheme\n\n# E. Median Income (收入与犯罪 - 这是一个典型的可能需要 log 的变量)\np5 <- ggplot(plot_data, aes(x = Avg_Income, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#3182bd\") +\n  geom_smooth(method = \"loess\", color = \"orange\", se = FALSE) +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Log(Crime) vs. Median Income\",\n       subtitle = \"Does wealth shield against crime?\",\n       x = \"Median Household Income\", y = \"\") +\n  plotTheme\n\n# F. Vacancy Rate (空置率/破窗理论)\np6 <- ggplot(plot_data, aes(x = Avg_Vacancy, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#3182bd\") +\n  geom_smooth(method = \"loess\", color = \"orange\", se = FALSE) +\n  scale_x_continuous(labels = scales::percent) +\n  labs(title = \"Log(Crime) vs. Vacancy Rate\",\n       x = \"Housing Vacancy Rate\", y = \"\") +\n  plotTheme\n\n# --- Combine Plots ---\n(p1 | p2 | p3) / (p4 | p5 | p6) +\n  plot_annotation(\n    title = \"Exploratory Analysis: Variable Functional Forms\",\n    subtitle = \"Red Line = Loess Smoother (Non-linear trend)\",\n    theme = theme(plot.title = element_text(size = 16, face = \"bold\"))\n  )\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/3.4_scatter_plots-1.png){width=672}\n:::\n:::\n\n\nBefore finalizing our model, we conducted an extensive exploratory analysis, testing relationships across multiple potential independent variables and their non-linear transformations. \nWhile we only present the variables with the most significant statistical relationships and policy implications here, this rigorous process of trial and error was essential to ensure the robustness of our final model. The charts above represent the distilled 'risk signals' identified from this comprehensive screening.\n\n- `Alcohol Outlets`: The plot shows that crime goes up quickly with the first few alcohol stores. However, as the number of stores gets very high, the line flattens out **(Diminishing marginal returns)**. We will try using a **log transformation** for this feature. This tells the model that the first few stores have a bigger impact than the later ones.  \n\n- `Street Lights`: The red trend line is **not straight**. It goes up as lights increase (usually in busy areas), but then it curves. In later this study, we used a **polynomial (2nd degree) term**. This allows the model to draw a curved line instead of a straight one to fit the data better.  \n\n- `Distance to Police`: The line looks **mostly straight** and goes down slightly, so we kept this variable linear.  \n\n- `Poverty Rate`: As poverty goes up, crime generally goes up. The line is **mostly straight**. We also kept it as a **standard linear variable**.  \n\n- `Median Income`: The line looks a bit like a **\"U\" shape**. Crime is high in low-income areas, drops in middle-income areas, and rises slightly or stays flat in higher-income areas. We added a **squared term (^2)**. This helps the model understand that crime can be high at both low and high income levels, but low in the middle.  \n\n- `Vacancy Rate`: The line looks like an **upside-down \"U\"**. Crime goes up as vacancy increases, but when vacancy gets very high (empty neighborhoods), crime actually drops. We also added a squared term (^2) for this.\n\n## 3.5 Correlation Matrix of Features for all Features\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggcorrplot)\n\n# 1. 选择数值型变量\nnumeric_vars <- final_data %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    Crime_Daily_Rate, \n    Ridership, \n    Alcohol_Count, \n    Light_Count, \n    Dist_Police, \n    Avg_Poverty, \n    Avg_Income, \n    Avg_Unemployment,\n    Avg_Vacancy\n  )\n\n# 2. 计算相关系数矩阵\ncorr_matrix <- cor(numeric_vars, use = \"complete.obs\")\n\n# 3. 绘图\nggcorrplot(\n  corr_matrix, \n  method = \"square\", \n  type = \"lower\", \n  lab = TRUE, \n  lab_size = 3, \n  colors = c(\"#6D9EC1\", \"white\", \"#E46726\"), \n  title = \"Correlation Matrix of Features\",\n  ggtheme = theme_minimal()\n)\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n- The correlation matrix reveals a critical issue of multicollinearity among the socioeconomic predictors. Specifically, Average Poverty Rate (Avg_Poverty) and Median Household Income (Avg_Income) exhibit a strong negative correlation of -0.81. Additionally, Unemployment Rate (Avg_Unemployment) shows a strong negative correlation with Income (-0.70) and a moderately high positive correlation with Poverty (0.66).\n\n- These high coefficients suggest that **Poverty, Income, and Unemployment** are capturing overlapping dimensions of neighborhood socioeconomic status. While this flags a risk of multicollinearity, correlation coefficients alone are insufficient for removing variables. Therefore, we will proceed to calculate the **Variance Inflation Factor (VIF) in the next step** to rigorously quantify the severity of multicollinearity and determine the appropriate strategy for feature selection or transformation.\n\n## 3.6 Crime distribution in weekdays and weekends\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### 3.5 Weekend Effect Boxplot\n\nggplot(final_data, aes(x = is_weekend_factor, y = Crime_Daily_Rate, fill = is_weekend_factor)) +\n  geom_boxplot(alpha = 0.7, outlier.shape = NA) + \n  \n  # 加上均值点\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  \n  # 限制 Y 轴范围 (注意：现在的单位是“每天”，数值会很小，比如 0.05)\n  # 使用 quantile 自动截断极端值\n  coord_cartesian(ylim = c(0, quantile(final_data$Crime_Daily_Rate, 0.95))) +\n  \n  scale_fill_manual(values = c(\"Weekday\" = \"#3182bd\", \"Weekend\" = \"#de2d26\")) +\n  \n  labs(\n    title = \"Daily Crime Risk: Weekday vs. Weekend\",\n    subtitle = \"Comparison of Average Daily Crime Counts per Stop\",\n    x = \"Time Period\",\n    y = \"Average Daily Crime Count (per 400m)\", # 修改标签\n    caption = \"Note: Values represent daily averages to account for fewer weekend days per year.\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n- **Stability of Crime Volume:** The means (indicated by white diamonds) and medians (solid black lines) for both weekdays and weekends are nearly identical, appearing at approximately the same daily average level (~0.6 incidents). This pattern suggests that the aggregate demand for public safety resources at these bus stops does not fluctuate significantly throughout the week.  \n\n- **Justification for Pseudo-Panel Modeling：** While this chart shows crime counts are constant, we know that generally ridership volume typically drops on weekends. If the outcome (crime) remains the same while the input (ridership) decreases, it implies that the risk intensity per rider is likely higher on weekends. Constructing a pseudo-panel allows us to mathematically capture this changing elasticity, rather than averaging it out.  \n\n  - By disaggregating the data into **weekday and weekend observations** for each stop, we create a pseudo-panel structure that acts as a natural control. Since the **physical environment (lighting, poverty, location) remains fixed** for a specific stop, splitting the data allows our model to **isolate ridership as the primary changing variable**, thereby enabling a more robust causal inference about how passenger flows specifically impact crime rates under different density conditions.\n\n------------------------------------------------------------------------\n\n# Phase 4: Model Building(负二项式)\n\n## 4.1 Ridership only:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_1 <- glm.nb(Crime_Total_Count ~ \n                    Log_Ridership + \n                    offset(log(Exposure_Days)), \n                  data = final_data)\nsummary(model_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership + offset(log(Exposure_Days)), \n    data = final_data, init.theta = 1.962937689, link = log)\n\nCoefficients:\n               Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -1.328484   0.018925  -70.20   <2e-16 ***\nLog_Ridership  0.243197   0.004944   49.19   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.9629) family taken to be 1)\n\n    Null deviance: 14335  on 11065  degrees of freedom\nResidual deviance: 11852  on 11064  degrees of freedom\nAIC: 92538\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.9629 \n          Std. Err.:  0.0274 \n\n 2 x log-likelihood:  -92531.6570 \n```\n\n\n:::\n:::\n\n\n- This baseline model establishes the **fundamental relationship** between transit ridership and crime counts without any confounding factors. It serves as a benchmark to test the raw association. specifically, whether higher passenger volume acts as a \"crime generator\" (providing more potential targets) or a deterrent (providing \"eyes on the street\"). The **offset term** ensures we are modeling the rate of crime per day, accounting for differences in exposure periods.\n\n## 4.2 The Interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_2 <- glm.nb(Crime_Total_Count ~ \n                    Log_Ridership * is_weekend_factor + \n                    offset(log(Exposure_Days)), \n                  data = final_data) \nsummary(model_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n    offset(log(Exposure_Days)), data = final_data, init.theta = 1.968491375, \n    link = log)\n\nCoefficients:\n                                        Estimate Std. Error z value Pr(>|z|)\n(Intercept)                            -1.434242   0.027417 -52.311  < 2e-16\nLog_Ridership                           0.263192   0.006798  38.716  < 2e-16\nis_weekend_factorWeekend                0.186359   0.038085   4.893 9.92e-07\nLog_Ridership:is_weekend_factorWeekend -0.034408   0.010040  -3.427  0.00061\n                                          \n(Intercept)                            ***\nLog_Ridership                          ***\nis_weekend_factorWeekend               ***\nLog_Ridership:is_weekend_factorWeekend ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.9685) family taken to be 1)\n\n    Null deviance: 14371  on 11065  degrees of freedom\nResidual deviance: 11849  on 11062  degrees of freedom\nAIC: 92509\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.9685 \n          Std. Err.:  0.0275 \n\n 2 x log-likelihood:  -92498.9340 \n```\n\n\n:::\n:::\n\n\n- In this step, we introduce the **interaction term (Log_Ridership * is_weekend_factor)** to test our core hypothesis: does the impact of ridership on crime change fundamentally during weekends? This specification allows the model to differentiate the \"commuter effect\" from potentially riskier weekend dynamics. It helps us determine if a specific bus stop becomes more dangerous per rider on weekends, even if the total volume of passengers decreases.\n\n## 4.3 Built Environment and Demographics features:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_3 <- glm.nb(Crime_Total_Count ~ \n                    Log_Ridership * is_weekend_factor + \n                    log(Alcohol_Count + 1) +        # 诱发因子\n                    poly(Light_Count, 2) +          # 预防因子\n                    Avg_Poverty +          # 社会结构\n                    Avg_Vacancy + I(Avg_Vacancy^2) +          # 破窗效应\n                    Avg_Income + I(Avg_Income^2)  +\n                    Avg_Unemployment +\n                    Dist_Police +\n                    offset(log(Exposure_Days)), \n                  data = final_data)\nsummary(model_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n    log(Alcohol_Count + 1) + poly(Light_Count, 2) + Avg_Poverty + \n    Avg_Vacancy + I(Avg_Vacancy^2) + Avg_Income + I(Avg_Income^2) + \n    Avg_Unemployment + Dist_Police + offset(log(Exposure_Days)), \n    data = final_data, init.theta = 3.809131636, link = log)\n\nCoefficients:\n                                         Estimate Std. Error z value Pr(>|z|)\n(Intercept)                            -8.603e-01  8.710e-02  -9.877  < 2e-16\nLog_Ridership                           1.102e-01  5.485e-03  20.086  < 2e-16\nis_weekend_factorWeekend                4.330e-02  2.965e-02   1.460  0.14416\nlog(Alcohol_Count + 1)                  2.836e-01  7.490e-03  37.869  < 2e-16\npoly(Light_Count, 2)1                   2.074e+01  9.830e-01  21.094  < 2e-16\npoly(Light_Count, 2)2                  -2.401e+00  6.208e-01  -3.867  0.00011\nAvg_Poverty                             1.310e+00  1.157e-01  11.325  < 2e-16\nAvg_Vacancy                             5.836e-03  3.003e-03   1.943  0.05197\nI(Avg_Vacancy^2)                       -1.034e-04  8.434e-05  -1.226  0.22030\nAvg_Income                             -1.162e-05  1.435e-06  -8.097 5.64e-16\nI(Avg_Income^2)                         5.343e-11  7.797e-12   6.852 7.27e-12\nAvg_Unemployment                       -1.235e-02  1.879e-03  -6.575 4.87e-11\nDist_Police                            -1.986e-01  1.149e-02 -17.278  < 2e-16\nLog_Ridership:is_weekend_factorWeekend -2.319e-02  7.718e-03  -3.004  0.00266\n                                          \n(Intercept)                            ***\nLog_Ridership                          ***\nis_weekend_factorWeekend                  \nlog(Alcohol_Count + 1)                 ***\npoly(Light_Count, 2)1                  ***\npoly(Light_Count, 2)2                  ***\nAvg_Poverty                            ***\nAvg_Vacancy                            .  \nI(Avg_Vacancy^2)                          \nAvg_Income                             ***\nI(Avg_Income^2)                        ***\nAvg_Unemployment                       ***\nDist_Police                            ***\nLog_Ridership:is_weekend_factorWeekend ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(3.8091) family taken to be 1)\n\n    Null deviance: 25397  on 11065  degrees of freedom\nResidual deviance: 11556  on 11052  degrees of freedom\nAIC: 85737\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  3.8091 \n          Std. Err.:  0.0607 \n\n 2 x log-likelihood:  -85706.8380 \n```\n\n\n:::\n:::\n\n\n- We incorporate criminogenic generators (alcohol outlets), potential guardians (street lights), and socioeconomic indicators (income, vacancy, and poverty).  \n- By adjusting for these factors, this model rigorously tests whether ridership has a unique impact on crime, or if high-ridership stops simply happen to be located in disadvantaged or commercially dense neighborhoods. This step is crucial for **isolating the specific effect** of the transit network from broader environmental conditions.\n\n## 4.4 Spatial Fixed Effect\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 加入 'PSA' (Police Service Area) 作为固定效应\n# 这相当于为费城每一个普查区都加了一个“基准拦截”，控制了所有观测不到的社区特征\nmodel_4 <- glm.nb(Crime_Total_Count ~ \n                    Log_Ridership * is_weekend_factor + \n                    log(Alcohol_Count + 1) +        # 诱发因子\n                    poly(Light_Count, 2) +          # 预防因子\n                    Avg_Poverty +          # 社会结构\n                    Avg_Vacancy + I(Avg_Vacancy^2) +          # 破窗效应\n                    Avg_Income + I(Avg_Income^2)  +\n                    Avg_Unemployment +\n                    Dist_Police +          # 政策变量：警力可达性\n                    factor(PSA_ID) +      # <--- 如果模型跑不动(不收敛)，注释掉这一行\n                    offset(log(Exposure_Days)), \n                  data = final_data,\n                  control = glm.control(maxit = 100)) # 增加迭代次数以防不收敛\nsummary(model_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n    log(Alcohol_Count + 1) + poly(Light_Count, 2) + Avg_Poverty + \n    Avg_Vacancy + I(Avg_Vacancy^2) + Avg_Income + I(Avg_Income^2) + \n    Avg_Unemployment + Dist_Police + factor(PSA_ID) + offset(log(Exposure_Days)), \n    data = final_data, control = glm.control(maxit = 100), init.theta = 4.730969316, \n    link = log)\n\nCoefficients:\n                                         Estimate Std. Error z value Pr(>|z|)\n(Intercept)                            -4.058e-01  1.071e-01  -3.789 0.000151\nLog_Ridership                           9.525e-02  5.201e-03  18.314  < 2e-16\nis_weekend_factorWeekend                2.432e-05  2.758e-02   0.001 0.999296\nlog(Alcohol_Count + 1)                  2.423e-01  8.067e-03  30.036  < 2e-16\npoly(Light_Count, 2)1                   2.468e+01  1.203e+00  20.510  < 2e-16\npoly(Light_Count, 2)2                  -5.178e+00  7.333e-01  -7.062 1.64e-12\nAvg_Poverty                             8.036e-01  1.364e-01   5.891 3.83e-09\nAvg_Vacancy                             9.710e-03  4.093e-03   2.372 0.017672\nI(Avg_Vacancy^2)                       -1.480e-04  9.976e-05  -1.484 0.137899\nAvg_Income                             -1.750e-05  1.684e-06 -10.396  < 2e-16\nI(Avg_Income^2)                         8.873e-11  8.819e-12  10.061  < 2e-16\nAvg_Unemployment                       -1.928e-02  2.160e-03  -8.924  < 2e-16\nDist_Police                            -2.755e-01  1.534e-02 -17.954  < 2e-16\nfactor(PSA_ID)012                       3.774e-02  7.062e-02   0.534 0.593118\nfactor(PSA_ID)021                       5.770e-01  5.888e-02   9.800  < 2e-16\nfactor(PSA_ID)022                       4.204e-01  6.138e-02   6.848 7.49e-12\nfactor(PSA_ID)023                       2.167e-01  5.230e-02   4.144 3.42e-05\nfactor(PSA_ID)031                      -2.512e-01  5.587e-02  -4.496 6.92e-06\nfactor(PSA_ID)032                       1.861e-01  5.190e-02   3.586 0.000336\nfactor(PSA_ID)033                      -1.804e-01  4.656e-02  -3.874 0.000107\nfactor(PSA_ID)051                      -1.158e-01  6.476e-02  -1.788 0.073805\nfactor(PSA_ID)052                      -3.001e-01  7.173e-02  -4.184 2.87e-05\nfactor(PSA_ID)053                      -3.824e-01  8.832e-02  -4.330 1.49e-05\nfactor(PSA_ID)071                       3.128e-01  6.760e-02   4.627 3.71e-06\nfactor(PSA_ID)072                      -2.708e-01  6.293e-02  -4.303 1.69e-05\nfactor(PSA_ID)073                      -3.697e-01  6.517e-02  -5.672 1.41e-08\nfactor(PSA_ID)081                       4.798e-01  6.006e-02   7.989 1.36e-15\nfactor(PSA_ID)082                      -1.388e-01  5.780e-02  -2.402 0.016302\nfactor(PSA_ID)083                      -4.606e-03  6.210e-02  -0.074 0.940871\nfactor(PSA_ID)091                       1.973e-01  5.179e-02   3.811 0.000139\nfactor(PSA_ID)092                       1.249e-01  5.629e-02   2.219 0.026498\nfactor(PSA_ID)093                      -2.243e-02  5.251e-02  -0.427 0.669180\nfactor(PSA_ID)094                       4.995e-01  5.413e-02   9.229  < 2e-16\nfactor(PSA_ID)095                      -1.978e-01  5.810e-02  -3.404 0.000663\nfactor(PSA_ID)121                       4.666e-01  6.270e-02   7.443 9.85e-14\nfactor(PSA_ID)122                      -1.427e-01  1.038e-01  -1.375 0.169163\nfactor(PSA_ID)123                       8.914e-02  6.188e-02   1.441 0.149665\nfactor(PSA_ID)124                       2.368e-01  7.720e-02   3.067 0.002159\nfactor(PSA_ID)141                      -3.889e-02  5.571e-02  -0.698 0.485112\nfactor(PSA_ID)142                      -1.625e-01  6.301e-02  -2.579 0.009916\nfactor(PSA_ID)143                       1.960e-01  5.740e-02   3.415 0.000637\nfactor(PSA_ID)144                      -1.241e-02  6.515e-02  -0.190 0.848975\nfactor(PSA_ID)151                       1.524e-01  5.272e-02   2.891 0.003845\nfactor(PSA_ID)152                       4.628e-01  5.253e-02   8.810  < 2e-16\nfactor(PSA_ID)153                       5.232e-01  5.387e-02   9.713  < 2e-16\nfactor(PSA_ID)161                      -3.663e-02  5.725e-02  -0.640 0.522209\nfactor(PSA_ID)162                      -5.668e-02  5.983e-02  -0.947 0.343485\nfactor(PSA_ID)171                      -1.610e-01  5.428e-02  -2.965 0.003022\nfactor(PSA_ID)172                      -5.680e-01  6.898e-02  -8.234  < 2e-16\nfactor(PSA_ID)173                      -3.975e-01  5.909e-02  -6.727 1.73e-11\nfactor(PSA_ID)181                      -1.636e-01  6.676e-02  -2.451 0.014265\nfactor(PSA_ID)182                       3.990e-02  5.880e-02   0.679 0.497423\nfactor(PSA_ID)183                      -1.393e-01  5.350e-02  -2.603 0.009229\nfactor(PSA_ID)191                       1.965e-01  5.347e-02   3.674 0.000238\nfactor(PSA_ID)192                       1.749e-02  5.921e-02   0.295 0.767637\nfactor(PSA_ID)193                       2.983e-01  5.720e-02   5.215 1.84e-07\nfactor(PSA_ID)221                       2.063e-01  5.666e-02   3.642 0.000271\nfactor(PSA_ID)222                      -1.035e-02  6.510e-02  -0.159 0.873735\nfactor(PSA_ID)223                       2.647e-01  5.970e-02   4.434 9.23e-06\nfactor(PSA_ID)224                       1.685e-01  6.918e-02   2.435 0.014876\nfactor(PSA_ID)241                       1.121e-01  6.299e-02   1.780 0.075073\nfactor(PSA_ID)242                       3.243e-01  6.764e-02   4.795 1.63e-06\nfactor(PSA_ID)243                       8.122e-02  6.635e-02   1.224 0.220954\nfactor(PSA_ID)251                       1.819e-01  6.727e-02   2.704 0.006846\nfactor(PSA_ID)252                      -2.377e-01  6.457e-02  -3.682 0.000232\nfactor(PSA_ID)253                      -3.656e-01  6.789e-02  -5.385 7.25e-08\nfactor(PSA_ID)254                      -5.605e-02  6.495e-02  -0.863 0.388107\nfactor(PSA_ID)261                      -1.929e-01  6.498e-02  -2.969 0.002990\nfactor(PSA_ID)262                       1.561e-01  5.853e-02   2.667 0.007655\nfactor(PSA_ID)263                      -9.630e-02  5.027e-02  -1.916 0.055399\nfactor(PSA_ID)351                      -3.793e-02  5.096e-02  -0.744 0.456679\nfactor(PSA_ID)352                       6.887e-02  5.383e-02   1.279 0.200771\nfactor(PSA_ID)353                      -2.201e-02  5.796e-02  -0.380 0.704186\nfactor(PSA_ID)391                       1.119e-02  5.277e-02   0.212 0.832001\nfactor(PSA_ID)392                      -1.532e-01  5.705e-02  -2.686 0.007233\nfactor(PSA_ID)393                       1.888e-01  6.928e-02   2.725 0.006431\nLog_Ridership:is_weekend_factorWeekend -1.720e-02  7.148e-03  -2.406 0.016114\n                                          \n(Intercept)                            ***\nLog_Ridership                          ***\nis_weekend_factorWeekend                  \nlog(Alcohol_Count + 1)                 ***\npoly(Light_Count, 2)1                  ***\npoly(Light_Count, 2)2                  ***\nAvg_Poverty                            ***\nAvg_Vacancy                            *  \nI(Avg_Vacancy^2)                          \nAvg_Income                             ***\nI(Avg_Income^2)                        ***\nAvg_Unemployment                       ***\nDist_Police                            ***\nfactor(PSA_ID)012                         \nfactor(PSA_ID)021                      ***\nfactor(PSA_ID)022                      ***\nfactor(PSA_ID)023                      ***\nfactor(PSA_ID)031                      ***\nfactor(PSA_ID)032                      ***\nfactor(PSA_ID)033                      ***\nfactor(PSA_ID)051                      .  \nfactor(PSA_ID)052                      ***\nfactor(PSA_ID)053                      ***\nfactor(PSA_ID)071                      ***\nfactor(PSA_ID)072                      ***\nfactor(PSA_ID)073                      ***\nfactor(PSA_ID)081                      ***\nfactor(PSA_ID)082                      *  \nfactor(PSA_ID)083                         \nfactor(PSA_ID)091                      ***\nfactor(PSA_ID)092                      *  \nfactor(PSA_ID)093                         \nfactor(PSA_ID)094                      ***\nfactor(PSA_ID)095                      ***\nfactor(PSA_ID)121                      ***\nfactor(PSA_ID)122                         \nfactor(PSA_ID)123                         \nfactor(PSA_ID)124                      ** \nfactor(PSA_ID)141                         \nfactor(PSA_ID)142                      ** \nfactor(PSA_ID)143                      ***\nfactor(PSA_ID)144                         \nfactor(PSA_ID)151                      ** \nfactor(PSA_ID)152                      ***\nfactor(PSA_ID)153                      ***\nfactor(PSA_ID)161                         \nfactor(PSA_ID)162                         \nfactor(PSA_ID)171                      ** \nfactor(PSA_ID)172                      ***\nfactor(PSA_ID)173                      ***\nfactor(PSA_ID)181                      *  \nfactor(PSA_ID)182                         \nfactor(PSA_ID)183                      ** \nfactor(PSA_ID)191                      ***\nfactor(PSA_ID)192                         \nfactor(PSA_ID)193                      ***\nfactor(PSA_ID)221                      ***\nfactor(PSA_ID)222                         \nfactor(PSA_ID)223                      ***\nfactor(PSA_ID)224                      *  \nfactor(PSA_ID)241                      .  \nfactor(PSA_ID)242                      ***\nfactor(PSA_ID)243                         \nfactor(PSA_ID)251                      ** \nfactor(PSA_ID)252                      ***\nfactor(PSA_ID)253                      ***\nfactor(PSA_ID)254                         \nfactor(PSA_ID)261                      ** \nfactor(PSA_ID)262                      ** \nfactor(PSA_ID)263                      .  \nfactor(PSA_ID)351                         \nfactor(PSA_ID)352                         \nfactor(PSA_ID)353                         \nfactor(PSA_ID)391                         \nfactor(PSA_ID)392                      ** \nfactor(PSA_ID)393                      ** \nLog_Ridership:is_weekend_factorWeekend *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(4.731) family taken to be 1)\n\n    Null deviance: 30304  on 11065  degrees of freedom\nResidual deviance: 11532  on 10989  degrees of freedom\nAIC: 83893\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  4.7310 \n          Std. Err.:  0.0792 \n\n 2 x log-likelihood:  -83736.6850 \n```\n\n\n:::\n:::\n\n\n- In this robust specification, we introduce **Police Service Area (PSA)** fixed effects to control for unobserved spatial heterogeneity. Unlike census tracts, PSAs are directly relevant to law enforcement strategy, allowing the model to account for differences in patrolling intensity and reporting practices across different police districts. This approach not only improves model fit but also resolves potential overfitting issues associated with smaller spatial units.\n\n## 4.5 Crime Temporal Lag\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 加入警局距离，并加入 'GEOID' (Census Tract) 作为固定效应\n# 这相当于为费城每一个普查区都加了一个“基准拦截”，控制了所有观测不到的社区特征\nmodel_5 <- glm.nb(Crime_Total_Count ~ \n                    Log_Ridership * is_weekend_factor + \n                    log(Alcohol_Count + 1) +        # 诱发因子\n                    poly(Light_Count, 2) +          # 预防因子\n                    Avg_Poverty +          # 社会结构\n                    Avg_Vacancy + I(Avg_Vacancy^2) +          # 破窗效应\n                    Avg_Income + I(Avg_Income^2)  +\n                    Avg_Unemployment +\n                    Dist_Police +          # 政策变量：警力可达性\n                    factor(PSA_ID) + \n                    log(Crime_Daily_Rate_lag + 0.001) +\n                    offset(log(Exposure_Days)), \n                  data = final_data,\n                  control = glm.control(maxit = 100)) # 增加迭代次数以防不收敛\nsummary(model_5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n    log(Alcohol_Count + 1) + poly(Light_Count, 2) + Avg_Poverty + \n    Avg_Vacancy + I(Avg_Vacancy^2) + Avg_Income + I(Avg_Income^2) + \n    Avg_Unemployment + Dist_Police + factor(PSA_ID) + log(Crime_Daily_Rate_lag + \n    0.001) + offset(log(Exposure_Days)), data = final_data, control = glm.control(maxit = 100), \n    init.theta = 13.48398402, link = log)\n\nCoefficients:\n                                         Estimate Std. Error z value Pr(>|z|)\n(Intercept)                             2.557e-01  7.508e-02   3.405 0.000661\nLog_Ridership                           3.097e-02  3.559e-03   8.701  < 2e-16\nis_weekend_factorWeekend                7.513e-03  1.983e-02   0.379 0.704750\nlog(Alcohol_Count + 1)                  6.111e-02  5.773e-03  10.587  < 2e-16\npoly(Light_Count, 2)1                   3.775e+00  8.603e-01   4.388 1.14e-05\npoly(Light_Count, 2)2                  -8.197e-01  4.967e-01  -1.650 0.098911\nAvg_Poverty                             1.727e-01  9.536e-02   1.811 0.070160\nAvg_Vacancy                            -8.960e-03  2.840e-03  -3.155 0.001604\nI(Avg_Vacancy^2)                        2.615e-04  6.921e-05   3.779 0.000158\nAvg_Income                             -8.633e-06  1.166e-06  -7.405 1.31e-13\nI(Avg_Income^2)                         4.994e-11  6.027e-12   8.286  < 2e-16\nAvg_Unemployment                       -1.039e-02  1.539e-03  -6.750 1.48e-11\nDist_Police                            -9.557e-02  1.108e-02  -8.629  < 2e-16\nfactor(PSA_ID)012                      -1.441e-01  5.067e-02  -2.844 0.004459\nfactor(PSA_ID)021                       1.421e-01  3.993e-02   3.558 0.000373\nfactor(PSA_ID)022                       6.487e-02  4.244e-02   1.529 0.126353\nfactor(PSA_ID)023                       5.092e-02  3.636e-02   1.400 0.161366\nfactor(PSA_ID)031                      -2.420e-02  3.758e-02  -0.644 0.519537\nfactor(PSA_ID)032                       3.348e-02  3.519e-02   0.951 0.341369\nfactor(PSA_ID)033                      -7.734e-02  3.133e-02  -2.469 0.013559\nfactor(PSA_ID)051                       5.406e-02  4.560e-02   1.186 0.235803\nfactor(PSA_ID)052                      -1.807e-01  5.194e-02  -3.479 0.000504\nfactor(PSA_ID)053                      -3.275e-01  6.822e-02  -4.801 1.58e-06\nfactor(PSA_ID)071                       2.336e-01  4.844e-02   4.822 1.42e-06\nfactor(PSA_ID)072                      -2.252e-01  4.649e-02  -4.845 1.27e-06\nfactor(PSA_ID)073                      -1.690e-01  4.871e-02  -3.469 0.000521\nfactor(PSA_ID)081                       1.977e-01  4.246e-02   4.655 3.23e-06\nfactor(PSA_ID)082                      -2.421e-01  4.216e-02  -5.742 9.34e-09\nfactor(PSA_ID)083                      -9.608e-02  4.610e-02  -2.084 0.037172\nfactor(PSA_ID)091                      -1.083e-01  3.486e-02  -3.108 0.001886\nfactor(PSA_ID)092                       8.268e-02  3.771e-02   2.193 0.028343\nfactor(PSA_ID)093                       3.994e-02  3.498e-02   1.142 0.253427\nfactor(PSA_ID)094                       2.249e-01  3.584e-02   6.276 3.47e-10\nfactor(PSA_ID)095                      -1.073e-01  3.890e-02  -2.758 0.005810\nfactor(PSA_ID)121                       4.142e-01  4.334e-02   9.557  < 2e-16\nfactor(PSA_ID)122                      -1.703e-01  7.205e-02  -2.363 0.018121\nfactor(PSA_ID)123                      -1.704e-01  4.189e-02  -4.067 4.75e-05\nfactor(PSA_ID)124                       2.026e-01  5.139e-02   3.943 8.05e-05\nfactor(PSA_ID)141                      -1.294e-01  3.887e-02  -3.330 0.000868\nfactor(PSA_ID)142                      -1.265e-01  4.355e-02  -2.905 0.003670\nfactor(PSA_ID)143                      -1.477e-03  4.006e-02  -0.037 0.970583\nfactor(PSA_ID)144                      -8.455e-02  4.711e-02  -1.795 0.072659\nfactor(PSA_ID)151                       1.626e-02  3.617e-02   0.450 0.652963\nfactor(PSA_ID)152                       1.268e-01  3.589e-02   3.532 0.000412\nfactor(PSA_ID)153                       2.305e-01  3.677e-02   6.269 3.62e-10\nfactor(PSA_ID)161                       1.339e-01  3.881e-02   3.449 0.000562\nfactor(PSA_ID)162                       1.178e-01  4.045e-02   2.913 0.003581\nfactor(PSA_ID)171                      -6.720e-02  3.659e-02  -1.836 0.066302\nfactor(PSA_ID)172                      -4.248e-01  4.869e-02  -8.724  < 2e-16\nfactor(PSA_ID)173                      -2.044e-01  3.989e-02  -5.124 2.99e-07\nfactor(PSA_ID)181                      -1.544e-01  4.483e-02  -3.445 0.000572\nfactor(PSA_ID)182                       1.001e-01  3.898e-02   2.569 0.010197\nfactor(PSA_ID)183                      -8.624e-02  3.617e-02  -2.384 0.017118\nfactor(PSA_ID)191                       2.030e-01  3.696e-02   5.493 3.94e-08\nfactor(PSA_ID)192                       6.114e-02  3.944e-02   1.550 0.121118\nfactor(PSA_ID)193                       2.517e-01  3.986e-02   6.315 2.71e-10\nfactor(PSA_ID)221                       6.874e-02  3.797e-02   1.811 0.070214\nfactor(PSA_ID)222                       7.326e-03  4.428e-02   0.165 0.868600\nfactor(PSA_ID)223                      -6.076e-02  3.978e-02  -1.528 0.126626\nfactor(PSA_ID)224                      -1.448e-01  4.634e-02  -3.124 0.001781\nfactor(PSA_ID)241                      -4.814e-02  4.310e-02  -1.117 0.264063\nfactor(PSA_ID)242                      -7.662e-03  4.520e-02  -0.169 0.865409\nfactor(PSA_ID)243                       1.327e-01  4.562e-02   2.908 0.003640\nfactor(PSA_ID)251                       1.919e-01  4.508e-02   4.256 2.08e-05\nfactor(PSA_ID)252                      -4.972e-02  4.469e-02  -1.113 0.265880\nfactor(PSA_ID)253                      -2.549e-01  4.660e-02  -5.469 4.52e-08\nfactor(PSA_ID)254                       4.112e-02  4.372e-02   0.941 0.346951\nfactor(PSA_ID)261                      -7.614e-02  4.393e-02  -1.733 0.083059\nfactor(PSA_ID)262                       5.008e-02  3.908e-02   1.282 0.199990\nfactor(PSA_ID)263                      -6.978e-02  3.389e-02  -2.059 0.039467\nfactor(PSA_ID)351                      -9.185e-02  3.527e-02  -2.604 0.009201\nfactor(PSA_ID)352                       7.575e-02  3.668e-02   2.065 0.038890\nfactor(PSA_ID)353                      -1.149e-01  3.954e-02  -2.905 0.003667\nfactor(PSA_ID)391                      -8.094e-02  3.676e-02  -2.202 0.027682\nfactor(PSA_ID)392                      -7.300e-02  3.878e-02  -1.883 0.059766\nfactor(PSA_ID)393                       4.386e-02  4.647e-02   0.944 0.345290\nlog(Crime_Daily_Rate_lag + 0.001)       7.084e-01  6.903e-03 102.622  < 2e-16\nLog_Ridership:is_weekend_factorWeekend -8.622e-03  5.060e-03  -1.704 0.088411\n                                          \n(Intercept)                            ***\nLog_Ridership                          ***\nis_weekend_factorWeekend                  \nlog(Alcohol_Count + 1)                 ***\npoly(Light_Count, 2)1                  ***\npoly(Light_Count, 2)2                  .  \nAvg_Poverty                            .  \nAvg_Vacancy                            ** \nI(Avg_Vacancy^2)                       ***\nAvg_Income                             ***\nI(Avg_Income^2)                        ***\nAvg_Unemployment                       ***\nDist_Police                            ***\nfactor(PSA_ID)012                      ** \nfactor(PSA_ID)021                      ***\nfactor(PSA_ID)022                         \nfactor(PSA_ID)023                         \nfactor(PSA_ID)031                         \nfactor(PSA_ID)032                         \nfactor(PSA_ID)033                      *  \nfactor(PSA_ID)051                         \nfactor(PSA_ID)052                      ***\nfactor(PSA_ID)053                      ***\nfactor(PSA_ID)071                      ***\nfactor(PSA_ID)072                      ***\nfactor(PSA_ID)073                      ***\nfactor(PSA_ID)081                      ***\nfactor(PSA_ID)082                      ***\nfactor(PSA_ID)083                      *  \nfactor(PSA_ID)091                      ** \nfactor(PSA_ID)092                      *  \nfactor(PSA_ID)093                         \nfactor(PSA_ID)094                      ***\nfactor(PSA_ID)095                      ** \nfactor(PSA_ID)121                      ***\nfactor(PSA_ID)122                      *  \nfactor(PSA_ID)123                      ***\nfactor(PSA_ID)124                      ***\nfactor(PSA_ID)141                      ***\nfactor(PSA_ID)142                      ** \nfactor(PSA_ID)143                         \nfactor(PSA_ID)144                      .  \nfactor(PSA_ID)151                         \nfactor(PSA_ID)152                      ***\nfactor(PSA_ID)153                      ***\nfactor(PSA_ID)161                      ***\nfactor(PSA_ID)162                      ** \nfactor(PSA_ID)171                      .  \nfactor(PSA_ID)172                      ***\nfactor(PSA_ID)173                      ***\nfactor(PSA_ID)181                      ***\nfactor(PSA_ID)182                      *  \nfactor(PSA_ID)183                      *  \nfactor(PSA_ID)191                      ***\nfactor(PSA_ID)192                         \nfactor(PSA_ID)193                      ***\nfactor(PSA_ID)221                      .  \nfactor(PSA_ID)222                         \nfactor(PSA_ID)223                         \nfactor(PSA_ID)224                      ** \nfactor(PSA_ID)241                         \nfactor(PSA_ID)242                         \nfactor(PSA_ID)243                      ** \nfactor(PSA_ID)251                      ***\nfactor(PSA_ID)252                         \nfactor(PSA_ID)253                      ***\nfactor(PSA_ID)254                         \nfactor(PSA_ID)261                      .  \nfactor(PSA_ID)262                         \nfactor(PSA_ID)263                      *  \nfactor(PSA_ID)351                      ** \nfactor(PSA_ID)352                      *  \nfactor(PSA_ID)353                      ** \nfactor(PSA_ID)391                      *  \nfactor(PSA_ID)392                      .  \nfactor(PSA_ID)393                         \nlog(Crime_Daily_Rate_lag + 0.001)      ***\nLog_Ridership:is_weekend_factorWeekend .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(13.484) family taken to be 1)\n\n    Null deviance: 64740  on 11065  degrees of freedom\nResidual deviance: 11871  on 10988  degrees of freedom\nAIC: 76243\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  13.484 \n          Std. Err.:  0.307 \n\n 2 x log-likelihood:  -76085.254 \n```\n\n\n:::\n:::\n\n\n- The last model incorporates a temporal lag (Log_Crime_Rate_lag), accounting for the historical \"stickiness\" of crime hotspots. By controlling for **past crime** alongside spatial fixed effects, this model offers the most rigorous test, correcting for both spatial dependence and serial correlation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(model_5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                         GVIF Df GVIF^(1/(2*Df))\nLog_Ridership                        2.140750  1        1.463130\nis_weekend_factor                    8.319162  1        2.884296\nlog(Alcohol_Count + 1)               3.845278  1        1.960938\npoly(Light_Count, 2)                11.981538  2        1.860493\nAvg_Poverty                          9.159654  1        3.026492\nAvg_Vacancy                         23.286389  1        4.825597\nI(Avg_Vacancy^2)                    14.466404  1        3.803473\nAvg_Income                          98.553277  1        9.927400\nI(Avg_Income^2)                     63.899807  1        7.993735\nAvg_Unemployment                     3.897398  1        1.974183\nDist_Police                          2.828785  1        1.681899\nfactor(PSA_ID)                    2368.120093 63        1.063606\nlog(Crime_Daily_Rate_lag + 0.001)    2.737960  1        1.654678\nLog_Ridership:is_weekend_factor      8.153167  1        2.855375\n```\n\n\n:::\n:::\n\n\n- A diagnostic check for multicollinearity in Model 5 revealed significant redundancy among the socioeconomic variables. Specifically, Median Income (`Avg_Income`) exhibited an extremely high Generalized VIF score of 9.92, indicating strong collinearity with Poverty Rate (`Avg_Poverty`). Including both variables introduces noise and destabilizes coefficient estimates, as they essentially measure the same underlying concept of economic disadvantage.  \n- Consequently, in the transition to Model 6 (Refined Model), we removed `Avg_Income` and its quadratic term, retaining `Avg_Poverty` as the primary proxy for socioeconomic status due to its stronger theoretical link to crime risk in urban literature. Additionally, we simplified the Street Lights variable from a polynomial to a linear term (`Light_Count`). Given that the model includes robust spatial fixed effects (`PSA_ID`), the complex non-linear variation is already largely absorbed by the spatial controls, making a linear specification for infrastructure more parsimonious and interpretable.\n\n## 4.6 Refine Model 5 and Create Final Model\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_6 <- glm.nb(Crime_Total_Count ~ \n                             Log_Ridership * is_weekend_factor + \n                             log(Alcohol_Count + 1) +\n                             Light_Count +\n                             Avg_Poverty +   \n                             Avg_Vacancy + I(Avg_Vacancy^2) + \n                             Avg_Unemployment +\n                             Dist_Police +\n                             factor(PSA_ID) + \n                             log(Crime_Daily_Rate_lag + 0.001) +\n                             offset(log(Exposure_Days)), \n                           data = final_data,\n                           control = glm.control(maxit = 100))\n\nsummary(model_6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n    log(Alcohol_Count + 1) + Light_Count + Avg_Poverty + Avg_Vacancy + \n    I(Avg_Vacancy^2) + Avg_Unemployment + Dist_Police + factor(PSA_ID) + \n    log(Crime_Daily_Rate_lag + 0.001) + offset(log(Exposure_Days)), \n    data = final_data, control = glm.control(maxit = 100), init.theta = 13.34075513, \n    link = log)\n\nCoefficients:\n                                         Estimate Std. Error z value Pr(>|z|)\n(Intercept)                            -1.939e-01  4.323e-02  -4.485 7.30e-06\nLog_Ridership                           3.134e-02  3.564e-03   8.793  < 2e-16\nis_weekend_factorWeekend                8.872e-03  1.987e-02   0.447 0.655203\nlog(Alcohol_Count + 1)                  6.276e-02  5.758e-03  10.899  < 2e-16\nLight_Count                             1.154e-04  3.655e-05   3.158 0.001590\nAvg_Poverty                             3.399e-01  7.377e-02   4.607 4.08e-06\nAvg_Vacancy                            -6.985e-03  2.840e-03  -2.460 0.013899\nI(Avg_Vacancy^2)                        2.459e-04  6.941e-05   3.543 0.000396\nAvg_Unemployment                       -9.685e-03  1.477e-03  -6.555 5.55e-11\nDist_Police                            -9.825e-02  1.095e-02  -8.971  < 2e-16\nfactor(PSA_ID)012                      -1.422e-01  5.058e-02  -2.811 0.004946\nfactor(PSA_ID)021                       1.509e-01  3.998e-02   3.773 0.000161\nfactor(PSA_ID)022                       1.014e-01  4.228e-02   2.399 0.016438\nfactor(PSA_ID)023                       6.396e-02  3.636e-02   1.759 0.078605\nfactor(PSA_ID)031                       2.073e-02  3.584e-02   0.578 0.563028\nfactor(PSA_ID)032                       5.317e-02  3.469e-02   1.533 0.125309\nfactor(PSA_ID)033                      -8.258e-02  3.112e-02  -2.654 0.007952\nfactor(PSA_ID)051                       6.217e-02  4.519e-02   1.376 0.168953\nfactor(PSA_ID)052                      -1.710e-01  5.178e-02  -3.302 0.000961\nfactor(PSA_ID)053                      -3.309e-01  6.830e-02  -4.845 1.27e-06\nfactor(PSA_ID)071                       2.547e-01  4.842e-02   5.259 1.45e-07\nfactor(PSA_ID)072                      -2.214e-01  4.646e-02  -4.764 1.89e-06\nfactor(PSA_ID)073                      -1.700e-01  4.882e-02  -3.482 0.000498\nfactor(PSA_ID)081                       2.072e-01  4.248e-02   4.877 1.08e-06\nfactor(PSA_ID)082                      -2.493e-01  4.219e-02  -5.909 3.45e-09\nfactor(PSA_ID)083                      -1.196e-01  4.575e-02  -2.615 0.008924\nfactor(PSA_ID)091                      -9.835e-02  3.360e-02  -2.927 0.003423\nfactor(PSA_ID)092                       1.325e-01  3.576e-02   3.705 0.000212\nfactor(PSA_ID)093                       3.605e-02  3.468e-02   1.040 0.298572\nfactor(PSA_ID)094                       2.110e-01  3.357e-02   6.287 3.25e-10\nfactor(PSA_ID)095                      -3.208e-02  3.647e-02  -0.880 0.379119\nfactor(PSA_ID)121                       4.456e-01  4.336e-02  10.275  < 2e-16\nfactor(PSA_ID)122                      -1.271e-01  7.201e-02  -1.765 0.077630\nfactor(PSA_ID)123                      -1.146e-01  4.141e-02  -2.767 0.005659\nfactor(PSA_ID)124                       2.308e-01  5.113e-02   4.515 6.34e-06\nfactor(PSA_ID)141                      -1.059e-01  3.856e-02  -2.747 0.006022\nfactor(PSA_ID)142                      -8.819e-02  4.343e-02  -2.030 0.042325\nfactor(PSA_ID)143                       2.082e-02  4.008e-02   0.519 0.603501\nfactor(PSA_ID)144                      -5.119e-02  4.695e-02  -1.090 0.275505\nfactor(PSA_ID)151                       4.567e-02  3.592e-02   1.271 0.203590\nfactor(PSA_ID)152                       1.576e-01  3.578e-02   4.404 1.06e-05\nfactor(PSA_ID)153                       2.389e-01  3.681e-02   6.490 8.58e-11\nfactor(PSA_ID)161                       1.985e-01  3.806e-02   5.215 1.84e-07\nfactor(PSA_ID)162                       1.781e-01  3.975e-02   4.480 7.48e-06\nfactor(PSA_ID)171                      -4.983e-02  3.509e-02  -1.420 0.155534\nfactor(PSA_ID)172                      -4.390e-01  4.839e-02  -9.073  < 2e-16\nfactor(PSA_ID)173                      -2.201e-01  3.978e-02  -5.533 3.15e-08\nfactor(PSA_ID)181                      -9.756e-02  4.423e-02  -2.206 0.027403\nfactor(PSA_ID)182                       1.344e-01  3.864e-02   3.479 0.000503\nfactor(PSA_ID)183                      -4.389e-02  3.495e-02  -1.256 0.209178\nfactor(PSA_ID)191                       1.931e-01  3.687e-02   5.237 1.63e-07\nfactor(PSA_ID)192                       1.307e-01  3.848e-02   3.396 0.000684\nfactor(PSA_ID)193                       2.633e-01  3.985e-02   6.608 3.88e-11\nfactor(PSA_ID)221                       1.218e-01  3.758e-02   3.242 0.001189\nfactor(PSA_ID)222                       7.118e-02  4.376e-02   1.627 0.103789\nfactor(PSA_ID)223                      -1.989e-02  3.955e-02  -0.503 0.615088\nfactor(PSA_ID)224                      -1.497e-01  4.627e-02  -3.235 0.001215\nfactor(PSA_ID)241                       1.896e-03  4.282e-02   0.044 0.964684\nfactor(PSA_ID)242                       4.314e-02  4.490e-02   0.961 0.336712\nfactor(PSA_ID)243                       1.449e-01  4.519e-02   3.206 0.001345\nfactor(PSA_ID)251                       2.562e-01  4.454e-02   5.752 8.84e-09\nfactor(PSA_ID)252                       8.936e-03  4.432e-02   0.202 0.840212\nfactor(PSA_ID)253                      -1.611e-01  4.549e-02  -3.540 0.000399\nfactor(PSA_ID)254                       1.288e-01  4.258e-02   3.024 0.002497\nfactor(PSA_ID)261                      -2.606e-02  4.353e-02  -0.599 0.549301\nfactor(PSA_ID)262                       6.579e-02  3.819e-02   1.723 0.084969\nfactor(PSA_ID)263                      -4.964e-02  3.330e-02  -1.491 0.135995\nfactor(PSA_ID)351                      -7.299e-02  3.527e-02  -2.070 0.038487\nfactor(PSA_ID)352                       1.256e-01  3.624e-02   3.466 0.000528\nfactor(PSA_ID)353                      -5.349e-02  3.886e-02  -1.377 0.168638\nfactor(PSA_ID)391                      -4.033e-02  3.657e-02  -1.103 0.270083\nfactor(PSA_ID)392                      -1.015e-02  3.821e-02  -0.266 0.790478\nfactor(PSA_ID)393                       1.247e-01  4.552e-02   2.739 0.006163\nlog(Crime_Daily_Rate_lag + 0.001)       7.118e-01  6.898e-03 103.194  < 2e-16\nLog_Ridership:is_weekend_factorWeekend -8.741e-03  5.073e-03  -1.723 0.084891\n                                          \n(Intercept)                            ***\nLog_Ridership                          ***\nis_weekend_factorWeekend                  \nlog(Alcohol_Count + 1)                 ***\nLight_Count                            ** \nAvg_Poverty                            ***\nAvg_Vacancy                            *  \nI(Avg_Vacancy^2)                       ***\nAvg_Unemployment                       ***\nDist_Police                            ***\nfactor(PSA_ID)012                      ** \nfactor(PSA_ID)021                      ***\nfactor(PSA_ID)022                      *  \nfactor(PSA_ID)023                      .  \nfactor(PSA_ID)031                         \nfactor(PSA_ID)032                         \nfactor(PSA_ID)033                      ** \nfactor(PSA_ID)051                         \nfactor(PSA_ID)052                      ***\nfactor(PSA_ID)053                      ***\nfactor(PSA_ID)071                      ***\nfactor(PSA_ID)072                      ***\nfactor(PSA_ID)073                      ***\nfactor(PSA_ID)081                      ***\nfactor(PSA_ID)082                      ***\nfactor(PSA_ID)083                      ** \nfactor(PSA_ID)091                      ** \nfactor(PSA_ID)092                      ***\nfactor(PSA_ID)093                         \nfactor(PSA_ID)094                      ***\nfactor(PSA_ID)095                         \nfactor(PSA_ID)121                      ***\nfactor(PSA_ID)122                      .  \nfactor(PSA_ID)123                      ** \nfactor(PSA_ID)124                      ***\nfactor(PSA_ID)141                      ** \nfactor(PSA_ID)142                      *  \nfactor(PSA_ID)143                         \nfactor(PSA_ID)144                         \nfactor(PSA_ID)151                         \nfactor(PSA_ID)152                      ***\nfactor(PSA_ID)153                      ***\nfactor(PSA_ID)161                      ***\nfactor(PSA_ID)162                      ***\nfactor(PSA_ID)171                         \nfactor(PSA_ID)172                      ***\nfactor(PSA_ID)173                      ***\nfactor(PSA_ID)181                      *  \nfactor(PSA_ID)182                      ***\nfactor(PSA_ID)183                         \nfactor(PSA_ID)191                      ***\nfactor(PSA_ID)192                      ***\nfactor(PSA_ID)193                      ***\nfactor(PSA_ID)221                      ** \nfactor(PSA_ID)222                         \nfactor(PSA_ID)223                         \nfactor(PSA_ID)224                      ** \nfactor(PSA_ID)241                         \nfactor(PSA_ID)242                         \nfactor(PSA_ID)243                      ** \nfactor(PSA_ID)251                      ***\nfactor(PSA_ID)252                         \nfactor(PSA_ID)253                      ***\nfactor(PSA_ID)254                      ** \nfactor(PSA_ID)261                         \nfactor(PSA_ID)262                      .  \nfactor(PSA_ID)263                         \nfactor(PSA_ID)351                      *  \nfactor(PSA_ID)352                      ***\nfactor(PSA_ID)353                         \nfactor(PSA_ID)391                         \nfactor(PSA_ID)392                         \nfactor(PSA_ID)393                      ** \nlog(Crime_Daily_Rate_lag + 0.001)      ***\nLog_Ridership:is_weekend_factorWeekend .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(13.3408) family taken to be 1)\n\n    Null deviance: 64299  on 11065  degrees of freedom\nResidual deviance: 11874  on 10991  degrees of freedom\nAIC: 76310\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  13.341 \n          Std. Err.:  0.303 \n\n 2 x log-likelihood:  -76157.840 \n```\n\n\n:::\n\n```{.r .cell-code}\n# 重新看 VIF\nvif(model_6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                        GVIF Df GVIF^(1/(2*Df))\nLog_Ridership                       2.133246  1        1.460563\nis_weekend_factor                   8.301509  1        2.881234\nlog(Alcohol_Count + 1)              3.798142  1        1.948882\nLight_Count                         5.541211  1        2.353978\nAvg_Poverty                         5.428573  1        2.329930\nAvg_Vacancy                        23.126903  1        4.809044\nI(Avg_Vacancy^2)                   14.459269  1        3.802535\nAvg_Unemployment                    3.561355  1        1.887155\nDist_Police                         2.751623  1        1.658802\nfactor(PSA_ID)                    467.133380 63        1.049992\nlog(Crime_Daily_Rate_lag + 0.001)   2.717994  1        1.648634\nLog_Ridership:is_weekend_factor     8.139565  1        2.852992\n```\n\n\n:::\n:::\n\n\n- After removing the conflicting income variables, Model 6 is now statistically healthy. Most importantly, our core variable, `Log_Ridership`, has a very low GVIF score of 2.13. This is well below the concern threshold (usually 5 or 10), which proves that our main finding that ridership drives crime, is reliable and not distorted by other factors.  \n- High scores for Vacancy and the Interaction term are mathematically expected when we use squared terms (like Vacancy^2) or interactions. They do not negatively affect the model's ability to predict crime.\n\n## 4.7 Model Comparison Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# --- Phase 4.5: Model Comparison Plot (Corrected) ---\n\nlibrary(modelsummary)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# 1. 修正 Coef Map (增加反向交互项以防万一)\ncoef_map_refined <- c(\n  # --- 核心交互项 ---\n  \"Log_Ridership\" = \"Ridership (Log)\",\n  \"is_weekend_factorWeekend\" = \"Weekend Effect\",\n  \n  # R 有时候会把交互项写反，为了保险，把两种可能都写上\n  \"Log_Ridership:is_weekend_factorWeekend\" = \"Interaction: Ridership × Weekend\",\n  \"is_weekend_factorWeekend:Log_Ridership\" = \"Interaction: Ridership × Weekend\", \n  \n  # --- 最终选定的控制变量 ---\n  \"log(Alcohol_Count + 1)\" = \"Alcohol Outlets\", \n  \"Light_Count\" = \"Street Lights (Linear)\",   \n  \"Avg_Poverty\" = \"Poverty Rate\",             \n  \"Avg_Vacancy\" = \"Vacancy Rate\",\n  \"I(Avg_Vacancy^2)\" = \"Vacancy Rate (Sq)\",\n  \"Avg_Unemployment\" = \"Unemployment Rate\",\n  \"Dist_Police\" = \"Dist to Police Station\",\n  \"log(Crime_Daily_Rate_lag + 0.001)\" = \"Temporal Lag (Prev. Q)\"\n)\n\n# 2. 绘图\np_comparison <- modelplot(\n  list(\n    \"M1: Ridership\" = model_1, \n    \"M2: +Interact\" = model_2,\n    \"M3: +Env/Demo\" = model_3,\n    \"M4: +PSA Fixed\" = model_4, \n    \"M5: +Lag\" = model_5,\n    \"M6: Final\" = model_6 \n  ),\n  coef_map = coef_map_refined, \n  \n  # ⭐⭐⭐ 核心修改在这里 ⭐⭐⭐\n  # 原来的写法: \"Intercept|factor|PSA_ID\" -> 误杀了 is_weekend_factor\n  # 现在的写法: 只过滤 Intercept。\n  # 原理解释: modelplot 使用 coef_map 时，会自动隐藏所有\"不在 map 里\"的变量。\n  # 所以你根本不需要写 factor 或 PSA_ID，只要 map 里没写它们，它们自动就不显示。\n  # 我们只保留 Intercept 过滤以防万一。\n  coef_omit = \"Intercept\", \n  \n  conf_level = 0.95,\n  size = 0.8 \n) +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Model Evolution: Stability of Key Drivers\",\n    subtitle = \"Comparing coefficients across model iterations (M1-M6)\",\n    x = \"Effect Size (Coefficient Estimate)\",\n    y = \"\",\n    caption = \"Note: To facilitate direct comparison, this plot displays only the variables selected for the Final Refined Model (M6).\"\n  ) +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Dark2\") + \n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\", size = 14),\n    axis.text.y = element_text(size = 10, face = \"bold\", color = \"black\"),\n    panel.grid.minor = element_blank()\n  )\n\n# 输出图形\np_comparison\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n- This plot visualizes our journey from a naive baseline to a robust final model. When reading this chart:  \n  - **Distance from Red Line:** The further the dot is to the right, the stronger the positive impact on crime.  \n  - **Length of the Line:** This represents the Confidence Interval. A longer line means higher uncertainty, often caused by multicollinearity.\n\n- **Model 1(Ridership Only):** Without controlling for any other factors, ridership appears to be a massive driver of crime. However, this estimate is likely **inflated (biased)** because high-ridership stops are often located in dense, low-income areas. The model is mistakenly attributing the neighborhood effect solely to ridership. \n\n- **Model 2(+Interaction):** We introduce the Weekend Effect and the interaction term. The main Ridership coefficient increases slightly. This confirms that the relationship isn't identical across the week. By separating weekends, we begin to see that the \"baseline risk\" shifts, validating the need for a pseudo-panel approach, though the core finding (ridership = risk) remains consistent due to its positive coefficient.  \n\n- **Model 3(+Env & Demo):** A dramatic shift occurs. The **Poverty Rate coefficient** appears and is extremely high (purple dot far to the right), while the **Ridership coefficient drops significantly** (moving left). This is the \"Reality Check.\" Once we account for poverty, we realize that socioeconomic status is the primary driver of crime, not just the bus stop itself. Ridership is still a significant risk factor (the coefficient is still positive), but its impact is much smaller than Model 1 suggested.  \n\n- **Model 4(+PSA Fixed Effects):** The Poverty Rate coefficient shrinks (moves left, pink dot) compared to Model 3. By adding PSA (Police Service Area) fixed effects, we control for unobserved neighborhood characteristics (like local culture or police presence). The model **no longer relies solely on \"Poverty\"** to explain crime clusters, making the estimates for specific variables like Alcohol Outlets and Ridership more precise and trustworthy.  \n\n- **Model 5(+Lag):** The Temporal Lag variable appears at the top with a very high positive coefficient. The strongest predictor of future crime is past crime. Adding this variable absorbs a huge amount of variance, creating a very strict test for our other variables.\n\n- **Model 6(Final Refined):** `Ridership` remains positive and significant (approx 0.1), proving that even after controlling for everything (poverty, history, location), more passengers still equal more targets. `Alcohol` shows a stable positive link. `Dist to Police` shows a negative coefficient (meaning crime is higher closer to stations),  but this is probably because there are bias in original dataset where crimes nearby the police stations are more likely to be recorded.\n\n# Phase 5: Model Validation\n\n## 5.1 Compare all 5 models:\n\n### 5.1.1 Create predicted vs. actual plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. 重新定义五个模型的公式 (确保与 Phase 4 一致)\n\nf1 <- Crime_Total_Count ~ Log_Ridership + offset(log(Exposure_Days))\nf2 <- Crime_Total_Count ~ Log_Ridership * is_weekend_factor + offset(log(Exposure_Days))\nf3 <- Crime_Total_Count ~ Log_Ridership * is_weekend_factor + log(Alcohol_Count + 1) + poly(Light_Count, 2) + Avg_Poverty + Avg_Vacancy + I(Avg_Vacancy^2) + Avg_Income + I(Avg_Income^2) + Avg_Unemployment + Dist_Police + offset(log(Exposure_Days))\n\nf4 <- Crime_Total_Count ~ Log_Ridership * is_weekend_factor + log(Alcohol_Count + 1) + poly(Light_Count, 2) + Avg_Poverty + Avg_Vacancy + I(Avg_Vacancy^2) + Avg_Income + I(Avg_Income^2) + Avg_Unemployment + Dist_Police + factor(PSA_ID) + offset(log(Exposure_Days)) \n\nf5 <- Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n      log(Alcohol_Count + 1) + poly(Light_Count, 2) + \n      Avg_Poverty + Avg_Vacancy + I(Avg_Vacancy^2) + \n      Avg_Income + I(Avg_Income^2) + Avg_Unemployment + \n      Dist_Police + factor(PSA_ID) + \n      log(Crime_Daily_Rate_lag + 0.001) + \n      offset(log(Exposure_Days))\n\nf6 <- Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n      log(Alcohol_Count + 1) + \n      Light_Count +              # 线性项\n      Avg_Poverty +              # 仅保留贫困\n      Avg_Vacancy + I(Avg_Vacancy^2) + \n      Avg_Unemployment + \n      Dist_Police + \n      factor(PSA_ID) +           # PSA 固定效应\n      log(Crime_Daily_Rate_lag + 0.001) + \n      offset(log(Exposure_Days))\n\n# 2. 训练五个模型\nm1 <- glm.nb(f1, data = final_data)\nm2 <- glm.nb(f2, data = final_data)\nm3 <- glm.nb(f3, data = final_data)\nm4 <- glm.nb(f4, data = final_data)\nm5 <- glm.nb(f5, data = final_data)\nm6 <- glm.nb(f6, data = final_data)\n\n# 3. 生成预测数据 (Gather Predictions)\n# type = \"response\" 会直接返回预测的犯罪数量 (Count)，不需要再 exp\nplot_data <- final_data %>%\n  dplyr::select(Crime_Total_Count) %>%\n  mutate(\n    Model_1_Pred = predict(m1, type = \"response\"),\n    Model_2_Pred = predict(m2, type = \"response\"),\n    Model_3_Pred = predict(m3, type = \"response\"),\n    Model_4_Pred = predict(m4, type = \"response\"),\n    Model_5_Pred = predict(m5, type = \"response\"),\n    Model_6_Pred = predict(m6, type = \"response\"),\n  ) %>%\n  pivot_longer(\n    cols = starts_with(\"Model\"), \n    names_to = \"Model\", \n    values_to = \"Predicted_Count\"\n  )\n\n# 4. 绘图：Facet Wrap 对比6个模型\n# 因为犯罪是计数数据，点会重叠，我们使用 alpha 和 45度线\nggplot(plot_data, aes(x = Predicted_Count, y = Crime_Total_Count)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\", size = 0.8) +\n  \n  # 添加完美预测线 (y=x)\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  \n  facet_wrap(~Model, ncol = 3) +\n  \n  labs(\n    title = \"Predicted vs. Actual Crime Counts\",\n    subtitle = \"Comparing Model Fit: Final Model (M6) shows robust predictions\",\n    x = \"Predicted Crime Count\",\n    y = \"Actual Crime Count\"\n  ) +\n  theme_bw() +\n  # 限制坐标轴范围以便看清核心区域 (去掉极值干扰)\n  coord_cartesian(xlim = c(0, 50), ylim = c(0, 50))\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n- This plot also visualizes our journey from a naive baseline to a robust final model.\n\n- Overall, as more contextual and more spatial information are added, the predicted values align **more closely with the 45° reference line**, indicating improved model fit.\n\n- Models 1–2 rely mainly on ridership and weekend interaction, resulting in wide dispersion and systematic under-prediction at higher crime levels.\n\n- Models 3–4 incorporate environmental (alcohol outlets, lighting) and demographic features, producing a noticeably tighter prediction band and capturing more variation across stops.\n\n- Model 5 adds temporal information (lagged crime rate), which further stabilizes predictions and reduces bias.\n\n- Compared with Model 5, Model 6 trims several weak or redundant predictors while keeping the key effects. This parsimonious specification makes the model more stable and interpretable and helps reduce potential multicollinearity among highly correlated socioeconomic variables.\n\n### 5.1.2 Report and Compare RMSE, MAE, R²\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\n# 1. 设置 5-Fold Cross Validation\nset.seed(999)\nfolds <- createFolds(final_data$Crime_Total_Count, k = 5, list = TRUE)\n\n# 定义一个辅助函数：跑 CV 并计算指标\nrun_cv <- function(formula, data, folds) {\n  mae_list <- c()\n  rmse_list <- c()\n  \n  for (i in 1:length(folds)) {\n    # Split Data\n    test_idx <- folds[[i]]\n    train_set <- data[-test_idx, ]\n    test_set  <- data[test_idx, ]\n    \n    # Train Model (tryCatch 防止不收敛报错)\n    model <- tryCatch({\n      glm.nb(formula, data = train_set)\n    }, error = function(e) return(NULL))\n    \n    if(!is.null(model)) {\n      # Predict (type = \"response\" 返回预测的数量)\n      preds <- predict(model, newdata = test_set, type = \"response\")\n      \n      # Calculate Errors\n      actuals <- test_set$Crime_Total_Count\n      mae_list <- c(mae_list, mean(abs(actuals - preds)))\n      rmse_list <- c(rmse_list, sqrt(mean((actuals - preds)^2)))\n    }\n  }\n  return(c(mean(mae_list), mean(rmse_list)))\n}\n\n# 2. 对五个模型分别跑 CV\n# 这里的公式需要跟上面定义的一致\nresults_m1 <- run_cv(f1, final_data, folds)\nresults_m2 <- run_cv(f2, final_data, folds)\nresults_m3 <- run_cv(f3, final_data, folds)\nresults_m4 <- run_cv(f4, final_data, folds)\nresults_m5 <- run_cv(f5, final_data, folds)\nresults_m6 <- run_cv(f6, final_data, folds)\n\n# 3. 汇总表格\nvalidation_summary <- data.frame(\n  Model = c(\"1. Ridership Only\", \"2. +Interaction\", \"3. +Env & Demo\", \"4. +Policy & Dist\", \"5. +Temporal lag\", \"6. Refined\"),\n  MAE  = c(results_m1[1], results_m2[1], results_m3[1], results_m4[1], results_m5[1], results_m6[1]),\n  RMSE = c(results_m1[2], results_m2[2], results_m3[2], results_m4[2], results_m5[2], results_m6[2])\n) %>%\n  mutate(\n    # 计算相对于 Model 1 的提升百分比\n    Improvement_MAE = (MAE[1] - MAE) / MAE[1]\n  )\n\n# 4. 展示漂亮的表格\nkable(validation_summary, digits = 3, caption = \"5-Fold Cross-Validation Metrics\") %>%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE) %>%\n  column_spec(4, color = \"green\", bold = TRUE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>5-Fold Cross-Validation Metrics</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE </th>\n   <th style=\"text-align:right;\"> RMSE </th>\n   <th style=\"text-align:right;\"> Improvement_MAE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Ridership Only </td>\n   <td style=\"text-align:right;\"> 17.268 </td>\n   <td style=\"text-align:right;\"> 28.877 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. +Interaction </td>\n   <td style=\"text-align:right;\"> 17.209 </td>\n   <td style=\"text-align:right;\"> 28.868 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. +Env &amp; Demo </td>\n   <td style=\"text-align:right;\"> 12.777 </td>\n   <td style=\"text-align:right;\"> 21.039 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.260 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. +Policy &amp; Dist </td>\n   <td style=\"text-align:right;\"> 11.409 </td>\n   <td style=\"text-align:right;\"> 18.343 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.339 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. +Temporal lag </td>\n   <td style=\"text-align:right;\"> 7.453 </td>\n   <td style=\"text-align:right;\"> 11.629 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.568 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6. Refined </td>\n   <td style=\"text-align:right;\"> 7.475 </td>\n   <td style=\"text-align:right;\"> 11.662 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.567 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThese findings are validated through 5-fold cross-validation, which evaluates each model on unseen data rather than relying solely on in-sample fit. The consistent reduction in MAE and RMSE across folds confirms that the improvements are not artifacts of overfitting but reflect real gains in out-of-sample predictive performance.\n\n1. Baseline: Mobility Activity (Model 1)\n\nThe model using only ridership intensity establishes a basic relationship between human activity levels and crime, but its predictive capacity is limited. Ridership alone captures general exposure but cannot explain spatial heterogeneity across stops.\n\n2. Temporal Structure of Activity (Model 2)\n\nAdding the weekday–weekend interaction improves the model slightly.\n\n3. Built Environment & Demographic features (Model 3)\n\nAlcohol outlet density, Lighting conditions poverty, income, vacancy, and unemployment: these variables substantially reduce prediction error, indicating that crime near transit stops is strongly shaped by both environmental risk factors and neighborhood disadvantage.\n\n4. Spatial Fixed Effect (Model 4)\n\nIntroducing police station distance and especially PSA fixed effects further improves performance.\nThis suggests that:Crime patterns are partly structured by local policing jurisdictions and there are unobserved spatial factors (culture, enforcement style, land use patterns) that are constant within each PSA.PSA fixed effects absorb these stable spatial characteristics, making the model more robust.\n\n5. Temporal Dependence in Crime (Model 5)\n\nIncluding lagged crime rate (previous quarter) yields the largest single improvement.\nLagged crime captures temporal persistence—areas that experienced more crime in the past tend to remain active in the present.This is a very strong and stable predictor, dramatically improving accuracy.\n\n6. Model Refinement & Parsimony (Model 6)\n\nModel 6 streamlines the specification by removing weaker or collinear variables.Despite using fewer predictors, its accuracy remains nearly identical to Model 5.\nThis indicates that a refined, parsimonious model with reduced multicollinearity can maintain strong predictive performance while improving interpretability and stability.\n\n# Phase 6: Model Diagnostics\n\n### Check assumptions for best model:\n\n## **6.1 Spatial Autocorrelation of Residuals (Moran's I)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. 明确指定 Model 5 为最佳模型\nbest_model <- model_6\n\n# 2. 提取残差\n# Pearson 残差用于统计检验（因为它是标准化的）\n# Deviance 残差用于绘图（因为视觉上更能反映拟合优度）\nfinal_data$resid_pearson  <- residuals(best_model, type = \"pearson\")\nfinal_data$resid_deviance <- residuals(best_model, type = \"deviance\")\n\n# 3. 构建空间权重矩阵 (Spatial Weights Matrix)\n# 由于公交站点是离散点，使用 k-Nearest Neighbors (KNN) 比距离阈值更稳健\n# 这里选取 k=8，意味着每个站点对比它最近的 8 个邻居\ncoords <- st_coordinates(final_data)\nneighbor_nb <- knn2nb(knearneigh(coords, k = 8))\nspatial_weights <- nb2listw(neighbor_nb, style = \"W\")\n\n# 4. 运行 Moran's I 检验\nmoran_result <- moran.test(final_data$resid_pearson, spatial_weights)\n\n# 打印结果\nprint(moran_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  final_data$resid_pearson  \nweights: spatial_weights    \n\nMoran I statistic standard deviate = 100.73, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     4.518144e-01     -9.037506e-05      2.012726e-05 \n```\n\n\n:::\n\n```{.r .cell-code}\n# 解释逻辑：\n# 如果 p-value > 0.05: 恭喜！残差是随机分布的，模型非常完美，没有遗漏空间变量。\n# 如果 p-value < 0.05 但 Moran's I 很小 (如 < 0.1): 模型还可以，只有轻微的空间依赖。\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spatial Distribution of Residuals\n# 1. 将残差添加回空间数据\n# type = \"deviance\" residuals are often better for mapping goodness-of-fit\nfinal_data$spatial_resid <- residuals(best_model, type = \"deviance\")\n\n# 2. 绘制地图\nggplot() +\n  # 底图\n  geom_sf(data = philly_boundary, fill = \"grey95\", color = NA) +\n  \n  # 站点残差图\n  geom_sf(data = final_data, \n          aes(color = spatial_resid), \n          size = 0.8, alpha = 0.7) +\n  \n  # 颜色比例尺\n  scale_color_gradient2(\n    low = \"blue\", mid = \"grey90\", high = \"red\",\n    midpoint = 0,\n    name = \"Deviance\\nResidual\",\n    # 限制范围，防止极个别离群值破坏颜色分布\n    limits = c(-3, 3), \n    oob = scales::squish \n  ) +\n  \n  labs(\n    title = \"Map of Model Residuals\",\n    subtitle = \"Red = Unexpectedly High Crime (Under-predicted)\\nBlue = Unexpectedly Low Crime (Over-predicted)\"\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n**Interpretation**:\n\n-   Interpretation:\n\nRed Spots (Positive Residuals): These are \"Anomalies\". The model (based on income, lighting, ridership) predicted low crime, but actual crime was high. These are targets for specific police intervention or CPTED audits.\n\nBlue Spots (Negative Residuals): These areas are safer than their environment suggests. What are they doing right?\n\nmorans I还是很高，但是空间负二项式回归很难做，我们只能保留这个高Morans i作为limitation：\nC. 数学上的噩梦：“非线性链接” (The Link Function Problem)这是最硬核的技术原因。线性模型 (OLS): $Y = X\\beta + \\text{Spatial Effects} + \\epsilon$。加法运算，很容易解。广义线性模型 (GLM/NegBin): $\\ln(Y) = X\\beta$。如果你想把空间效应加进去，模型就变成了 $\\ln(Y) = \\rho W Y + X\\beta$。问题来了： $Y$ 在左边取了对数，在右边又是原始值。这导致似然函数（Likelihood Function）变得极其复杂，无法像普通回归那样求出解析解，必须用非常复杂的马尔可夫链蒙特卡洛（MCMC/Bayesian）方法去“猜”参数。\n\n可以说：我们使用负二项模型，因为标准空间模型无法处理离散的计数数据。但为了修正空间自相关，我们引入了固定效应/空间滤波。这是一种“两全其美”的策略：既尊重了数据的计数属性，又控制了空间聚集风险。\n\n## **6.1 Residual plot:（找实际犯罪\\>预测）**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_model <- model_6\n\n# 1. 提取拟合值和残差\n# 注意：对于 glm.nb，必须指定 type = \"pearson\" 来标准化残差\nmodel_data <- data.frame(\n  Fitted = fitted(best_model),\n  Residuals = residuals(best_model, type = \"pearson\")\n)\n\n# 2. 绘制残差 vs. 拟合值图\np_resid_fitted <- ggplot(model_data, aes(x = log(Fitted), y = Residuals)) +\n  geom_point(alpha = 0.3, color = \"#6A1B9A\", size = 1.5) + \n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"loess\", color = \"black\", se = FALSE, linewidth = 0.8) +\n  labs(\n    title = \"Residuals vs Fitted Values\",\n    subtitle = \"Checking for systematic bias in the Count Model\",\n    x = \"Log(Fitted Values) - Predicted Crime Count\",\n    y = \"Pearson Residuals\"\n  ) +\n  plotTheme\n\np_resid_fitted\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\nInterpretation:\n\nIdeal Plot: The points should be scattered randomly around the horizontal red line (0).\n\nCurvature? If the black line curves significantly, it suggests we might be missing a non-linear variable (like a squared term).\n\nFan Shape? Ideally, the spread should be roughly constant. Since we used Negative Binomial (which handles overdispersion), we hope to see a relatively even spread compared to a Poisson model.\n\n\"The Integer Effect\" (整数效应) 或 \"Discreteness\" (离散性)\n\n不要惊慌，这些线条不是模型错误的标志，反而证明了你使用 负二项回归 (Count Model) 来处理犯罪数据是正确的选择。\n\n没看懂啥原理，对就完了\n\n## **6.2 Q-Q plot:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_qq <- ggplot(model_data, aes(sample = Residuals)) +\n  stat_qq(color = \"#6A1B9A\", size = 1.5, alpha = 0.5) +\n  stat_qq_line(color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(\n    title = \"Q-Q Plot of Pearson Residuals\",\n    subtitle = \"Checking for extreme outliers in count data\",\n    x = \"Theoretical Quantiles\",\n    y = \"Sample Quantiles\"\n  ) +\n  plotTheme\n\np_qq\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n**Interpretation**:\n\n-   Deviation at tails: It is common for count data models to deviate at the extreme ends.\n\nInterpretation: If the points mostly follow the line in the middle range, the model is acceptable. If there is a massive curve, the Negative Binomial assumption might still be struggling with extreme overdispersion.\n\n\n## **6.3** Top 50 风险站点地图**:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. 提取预测值 (Predicted Counts)\nfinal_data <- final_data %>%\n  mutate(Predicted_Crime = predict(best_model, type = \"response\"))\n\n# 2. 筛选前 50 个高风险站点\ntop_50_risky <- final_data %>%\n  arrange(desc(Predicted_Crime)) %>%\n  slice(1:50)\n\n# 3. 绘制行动地图\nggplot() +\n  # 背景底图\n  geom_sf(data = philly_boundary, fill = \"grey95\", color = \"white\") +\n  \n  # 所有站点 (灰色背景)\n  geom_sf(data = final_data, color = \"grey80\", size = 0.5, alpha = 0.3) +\n  \n  # 高风险站点 (红色醒目)\n  geom_sf(data = top_50_risky, color = \"red\", size = 2, alpha = 0.9) +\n  \n  # (可选) 加上文字标签\n  # geom_sf_text(data = head(top_50_risky, 5), aes(label = Stop), dy = 100, size = 3) +\n\n  labs(\n    title = \"Top 50 High-Risk Bus Stops\",\n    subtitle = \"Priority Zones for Police Patrol Deployment (Based on Model Prediction)\",\n    caption = \"Red dots represent the stops with the highest predicted crime counts.\"\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 6.3 Top 50 异常风险站点地图 (Residuals)\n\n# 1. 计算残差 (Actual - Predicted)\n# 我们使用 \"Raw Residuals\" (原始残差)，因为它的业务含义最直观：\n# \"实际发生的犯罪比模型预测的多出了多少起？\"\nfinal_data <- final_data %>%\n  mutate(\n    Predicted_Crime = predict(best_model, type = \"response\"),\n    \n    # 计算差异：实际 - 预测\n    # 正值 (Positive) = 实际犯罪 > 预期 (危险异常)\n    # 负值 (Negative) = 实际犯罪 < 预期 (安全异常)\n    Resid_Raw = Crime_Total_Count - Predicted_Crime\n  )\n\n# 2. 筛选前 50 个风险高（人多），但实际没什么事的站点\ntop_50_anomalies <- final_data %>%\n  # 按残差从大到小排序 (只看正值最大的)\n  arrange(desc(Resid_Raw)) %>%\n  slice(1:50)\n\n# 3. 绘制地图\nggplot() +\n  # A. 背景底图 (费城)\n  geom_sf(data = philly_boundary, fill = \"grey95\", color = \"white\") +\n  \n  # B. 所有站点 (作为背景参考，浅灰色)\n  geom_sf(data = final_data, color = \"grey80\", size = 0.5, alpha = 0.3) +\n  \n  # C. 异常站点 (红色醒目)\n  geom_sf(data = top_50_anomalies, \n          aes(size = Resid_Raw), # 让残差越大的点越大\n          color = \"steelblue\", \n          alpha = 0.8) +\n\n  # E. 设置图例和标题\n  scale_size_continuous(name = \"Excess Crimes\\n(Actual - Predicted)\") +\n  \n  labs(\n    title = \"Top 50 Under-policed Stops\",\n    subtitle = \"Locations where actual crime significantly exceeds model predictions.\",\n    caption = \"Blue dots represent stops performing worse than their environment, suggesting there are more police in need.\"\n  ) +\n  mapTheme +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 6.3 Top 50 异常风险站点地图 (Residuals)\n\n# 1. 计算残差 (Actual - Predicted)\n# 我们使用 \"Raw Residuals\" (原始残差)，因为它的业务含义最直观：\n# \"实际发生的犯罪比模型预测的多出了多少起？\"\nfinal_data <- final_data %>%\n  mutate(\n    Predicted_Crime = predict(best_model, type = \"response\"),\n    \n    # 计算差异：实际 - 预测\n    # 正值 (Positive) = 实际犯罪 > 预期 (危险异常)\n    # 负值 (Negative) = 实际犯罪 < 预期 (安全异常)\n    Resid_Raw =  Predicted_Crime - Crime_Total_Count\n  )\n\n# 2. 筛选前 50 个风险高（人多），但实际没什么事的站点\ntop_50_anomalies <- final_data %>%\n  # 按残差从大到小排序 (只看正值最大的)\n  arrange(desc(Resid_Raw)) %>%\n  slice(1:50)\n\n# 3. 绘制地图\nggplot() +\n  # A. 背景底图 (费城)\n  geom_sf(data = philly_boundary, fill = \"grey95\", color = \"white\") +\n  \n  # B. 所有站点 (作为背景参考，浅灰色)\n  geom_sf(data = final_data, color = \"grey80\", size = 0.5, alpha = 0.3) +\n  \n  # C. 异常站点 (红色醒目)\n  geom_sf(data = top_50_anomalies, \n          aes(size = Resid_Raw), # 让残差越大的点越大\n          color = \"#d73027\", \n          alpha = 0.8) +\n\n  # E. 设置图例和标题\n  scale_size_continuous(name = \"Excess Crimes\\n(Predicted - Actual)\") +\n  \n  labs(\n    title = \"Top 50 'Over-policed' Stops\",\n    subtitle = \"Locations where actual crime significantly under model predictions.\",\n    caption = \"Red dots represent stations which are statistically risky, but the actual crime counts are actually small. \"\n  ) +\n  mapTheme +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 6.4 Top 10 High-Risk Anomaly Table\n\nlibrary(kableExtra)\n\n# 1. 准备数据\ntop_10_table <- final_data %>%\n  mutate(\n    Predicted = predict(best_model, type = \"response\"),\n    Residual = Crime_Total_Count - Predicted\n  ) %>%\n  # 按残差排序：找出\"实际犯罪\"比\"预测\"高得最多的点\n  arrange(desc(Residual)) %>%\n  slice(1:10) %>%\n  # 选择并重命名列，使其适合展示\n  dplyr::select(\n    \"Bus Stop Name\" = Stop,\n    \"Police District (PSA)\" = PSA_ID,\n    \"Actual Crime\" = Crime_Total_Count,\n    \"Model Predicted\" = Predicted,\n    \"Unexplained Excess\" = Residual\n  )\n\n# 2. 输出美化的表格\nkbl(top_10_table, digits = 1, caption = \"The 'Hit List': Top 10 Stops with Highest Unexplained Crime Risk\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = F) %>%\n  # 高亮最后一列，强调这是我们需要解决的问题\n  column_spec(5, bold = TRUE, color = \"white\", background = \"#d73027\") %>%\n  # 加一个脚注解释\n  footnote(general = \" 'Unexplained Excess' = Actual Crime minus Predicted Crime based on local environment. Positive values indicate specific local security failures.\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n<caption>The 'Hit List': Top 10 Stops with Highest Unexplained Crime Risk</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Bus Stop Name </th>\n   <th style=\"text-align:left;\"> Police District (PSA) </th>\n   <th style=\"text-align:right;\"> Actual Crime </th>\n   <th style=\"text-align:right;\"> Model Predicted </th>\n   <th style=\"text-align:right;\"> Unexplained Excess </th>\n   <th style=\"text-align:left;\"> geometry </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Locust St &amp; 17th St </td>\n   <td style=\"text-align:left;\"> 093 </td>\n   <td style=\"text-align:right;\"> 295 </td>\n   <td style=\"text-align:right;\"> 198.2 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 96.8 </td>\n   <td style=\"text-align:left;\"> POINT (2691904 234766) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Whitby Av &amp; 53rd St </td>\n   <td style=\"text-align:left;\"> 124 </td>\n   <td style=\"text-align:right;\"> 138 </td>\n   <td style=\"text-align:right;\"> 52.3 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 85.7 </td>\n   <td style=\"text-align:left;\"> POINT (2675321 233206.7) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 17th St &amp; Locust St </td>\n   <td style=\"text-align:left;\"> 093 </td>\n   <td style=\"text-align:right;\"> 276 </td>\n   <td style=\"text-align:right;\"> 190.9 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 85.1 </td>\n   <td style=\"text-align:left;\"> POINT (2691903 234716.1) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 54th St &amp; Willows Av </td>\n   <td style=\"text-align:left;\"> 124 </td>\n   <td style=\"text-align:right;\"> 142 </td>\n   <td style=\"text-align:right;\"> 58.2 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 83.8 </td>\n   <td style=\"text-align:left;\"> POINT (2675499 232607.7) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 52nd St &amp; Jefferson St </td>\n   <td style=\"text-align:left;\"> 193 </td>\n   <td style=\"text-align:right;\"> 176 </td>\n   <td style=\"text-align:right;\"> 94.5 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 81.5 </td>\n   <td style=\"text-align:left;\"> POINT (2675925 245535.5) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 54th St &amp; Whitby Av - FS </td>\n   <td style=\"text-align:left;\"> 124 </td>\n   <td style=\"text-align:right;\"> 136 </td>\n   <td style=\"text-align:right;\"> 55.4 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 80.6 </td>\n   <td style=\"text-align:left;\"> POINT (2675117 232954.9) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 54th St &amp; Whitby Av </td>\n   <td style=\"text-align:left;\"> 124 </td>\n   <td style=\"text-align:right;\"> 137 </td>\n   <td style=\"text-align:right;\"> 57.2 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 79.8 </td>\n   <td style=\"text-align:left;\"> POINT (2675141 233000) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Whitby Av &amp; 53rd St - FS </td>\n   <td style=\"text-align:left;\"> 124 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n   <td style=\"text-align:right;\"> 53.5 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 79.5 </td>\n   <td style=\"text-align:left;\"> POINT (2675326 233279) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Jefferson St &amp; 52nd St - FS </td>\n   <td style=\"text-align:left;\"> 193 </td>\n   <td style=\"text-align:right;\"> 176 </td>\n   <td style=\"text-align:right;\"> 98.9 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 77.1 </td>\n   <td style=\"text-align:left;\"> POINT (2675866 245528.4) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 52nd St &amp; Heston St </td>\n   <td style=\"text-align:left;\"> 193 </td>\n   <td style=\"text-align:right;\"> 176 </td>\n   <td style=\"text-align:right;\"> 98.9 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 77.1 </td>\n   <td style=\"text-align:left;\"> POINT (2675998 245602.9) </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup>  'Unexplained Excess' = Actual Crime minus Predicted Crime based on local environment. Positive values indicate specific local security failures.</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n**Interpretation**:\n\n-   **Overall**These 50 stops represent the \"Hotspots\" identified by our algorithm.\n\nActionable Insight: \"We recommend SEPTA Police allocate dedicated patrol units to these specific locations during peak hours. By focusing resources on these top 1% of stops, we can potentially address a significant portion of the total crime risk.\"\n\n这很好，加了geoid之后，除了市中心还有另一坨红色\n\n------------------------------------------------------------------------\n\n# Phase 7: Conclusions\n\n## 7.1 Results:\n\n**系数解读:**\n\n-   如果客流系数是 **负**的 -\\> **支持“街道眼”理论**（人多反而安全）。\n\n-   如果客流系数是 **正**的 -\\> **支持“潜在受害者”理论**（人多扒窃多）。\n\n## 7.2 The Action Plan:\n\n-   **警力部署:** 根据预测的风险值，生成“每日巡逻热点图”。\n\n-   **环境设计 (CPTED):** 对于那些高犯罪站点，如果是路灯不够，装灯；如果是空置房太多，清理社区。\n\n## **7.3 Equity concerns**\n\n-   **Which neighborhoods are hardest to predict?**\n\n-   **Any data bias?**\n",
    "supporting": [
      "Final_appendix_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}