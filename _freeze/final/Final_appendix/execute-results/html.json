{
  "hash": "16167884e8ddb1add7477f015f9bd2ce",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Safe Passage: Modeling Crime Risk around SEPTA Bus Stops\"\nauthor: \"Xinyuan Cui, Yuqing Yang, Jinyang Xu\"\nformat: \n  html:\n    code-fold: show\n    toc: true\n    toc-location: left\n    theme: cosmo\nexecute:\n  warning: false\n  message: false\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n# Phase 1: Data Preparation\n\nThe primary dataset we use is 2025summer Septa bus ridership data.The\nvalidity of any predictive model rests on the quality of its underlying\ndata. In this initial phase, we focus strictly on data preparation and\nexploratory visualization. We load and clean the raw ridership, crime\ndataset and other datasets to handle missing values and outliers.\nThrough initial descriptive analytics and visualization, we assess the\nstatistical properties of our datasets.\n\n## 1.0 Complete data cleaning code\n\n***Load necessary libraries***\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tidycensus)\nlibrary(tigris)\noptions(tigris_use_cache = TRUE, tigris_class = \"sf\")\nlibrary(MASS)\nlibrary(spdep)\nlibrary(dplyr)\nlibrary(scales)\nlibrary(ggplot2)\nlibrary(caret)\nlibrary(nngeo)\nlibrary(car)\nlibrary(knitr)\nlibrary(readr)\nlibrary(patchwork)\nlibrary(kableExtra)\nlibrary(lubridate)\n\noptions(tigris_use_cache = TRUE)\noptions(tigris_progress = FALSE)  \n```\n:::\n\n\n***Define themes***\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n:::\n\n\n## 1.1 Load and clean bus stop ridership data:\n\n### 1.1.1 Load bus stop ridership data\n\n[2025 summer SEPTA bus ridership\ndata](https://opendataphilly.org/datasets/septa-ridership-statistics/)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Load Bus Data\nbus_raw <- read_csv(\"data/Summer_2025_Stop_Summary_(Bus).csv\")\n```\n:::\n\n\n### 1.1.2 Clean\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2. Get Philadelphia Boundary\nphilly_boundary <- counties(state = \"PA\", cb = TRUE, class = \"sf\") %>%\n  filter(NAME == \"Philadelphia\") %>%\n  st_transform(2272)\n```\n:::\n\n\nIn preparing the ridership data, we performed two critical structural\ntransformations to align with our research goals.\\\nFirst, we **aggregated bidirectional stops** sharing the same location\n(including opposite sides of a street) into single spatial units. This\nprevents spatial autocorrelation and ensures our 400m buffers capture a\nunique street environment.\\\nSecond, we **restructured the dataset into a ‘long format’ (panel\ndata)**, distinguishing between Weekday and Weekend ridership. This\ntemporal split is vital, as it allows our model to capture the distinct\nbehavioral patterns of both commuters and potential offenders during\ndifferent times of the week.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 3. Process Ridership: Create Long Format (Aggregated + Weekday vs Weekend)\nbus_long <- bus_raw %>%\n  filter(!is.na(Lat) & !is.na(Lon)) %>%\n  mutate(\n    Raw_Weekday = Weekdays_O + Weekdays_1,\n    # A. Weekend average = (Sat total + Sun total) / 2\n    Raw_Weekend = (Saturdays_ + Saturdays1 + Sundays_On + Sundays_Of) / 2\n  ) %>%\n  \n  # B. Aggregation by Stop Name\n  group_by(Stop) %>% \n  summarise(\n    # C. Add two direction ridership\n    Ridership_Weekday = sum(Raw_Weekday, na.rm = TRUE),\n    Ridership_Weekend = sum(Raw_Weekend, na.rm = TRUE),\n    Lat = mean(Lat, na.rm = TRUE),\n    Lon = mean(Lon, na.rm = TRUE),\n    # Keep one Stop_Code as unique ID\n    Stop_Code = first(Stop_Code),\n    .groups = \"drop\"\n  ) %>%\n  \n  # D. Pivot to Long Format\n  pivot_longer(\n    cols = c(Ridership_Weekday, Ridership_Weekend),\n    names_to = \"Time_Type\",\n    values_to = \"Ridership\"\n  ) %>%\n  \n  # E. Create Dummy Variable & Clean up\n  mutate(\n    is_weekend = if_else(Time_Type == \"Ridership_Weekend\", 1, 0),\n    Time_Category = if_else(is_weekend == 1, \"Weekend\", \"Weekday\")\n  ) %>%\n  \n  # F. Convert to SF & Clip\n  st_as_sf(coords = c(\"Lon\", \"Lat\"), crs = 4326) %>%\n  st_transform(2272) %>%\n  st_intersection(philly_boundary) %>%\n  dplyr::select(Stop_Code, Stop, Ridership, is_weekend, Time_Category, geometry)\n\n# Check results\ncat(\"Total Aggregated Stops (Unique Locations):\", nrow(bus_long) / 2, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal Aggregated Stops (Unique Locations): 5884 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Total Observation Rows (Panel Data):\", nrow(bus_long), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal Observation Rows (Panel Data): 11768 \n```\n\n\n:::\n:::\n\n\n### 1.1.3 Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  # A. Base Layer: Philadelphia County Background\n  geom_sf(data = philly_boundary, \n          fill = \"grey98\", \n          color = \"grey50\", \n          size = 0.5) +\n  \n  # B. Station Layer: Simple Points\n  geom_sf(data = bus_long %>% filter(is_weekend == 0), \n          color = \"#3182bd\",  # SEPTA Blue\n          size = 0.1,         # Small dots to avoid clutter\n          alpha = 0.6) +      # Slight transparency\n  \n  # C. Styling\n  labs(\n    title = \"Spatial Coverage of SEPTA Bus Network\",\n    subtitle = paste0(\"Total Aggregated Stops: \", nrow(bus_long) / 2),\n    caption = \"Source: SEPTA Summer 2025 Stop Summary\"\n  ) +\n  theme_void() + # Clean look\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 10, color = \"grey40\", hjust = 0.5),\n    plot.margin = margin(1, 1, 1, 1, \"cm\")\n  )\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/map_stations-1.png){width=672}\n:::\n:::\n\n\nThe figure illustrates the extensive spatial coverage of the SEPTA bus\nnetwork within Philadelphia. After aggregating bidirectional stops, our\nstudy includes **5,884 unique locations**.\\\nThe distribution reveals **a high density in the Center City** and **a\ngrid-like arterial pattern extending into residential neighborhoods**.\nThis comprehensive coverage ensures that our analysis captures a diverse\nrange of built environments, from dense commercial districts to suburban\nresidential areas.\n\n## 1.2 Load and clean secondary dataset:\n\n### 1.2.1 Crime data:\n\n[Crime Incidents from\n2024](https://opendataphilly.org/datasets/crime-incidents/)\n\nWe excluded domestic disputes or indoor financial crimes because SEPTA\nTransit Police cannot police inside people's homes. Instead, we selected\nthese specific crime types because they occur in the public right-of-way\nand directly impact a rider's decision to use public transit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### 1.2.1 Crime data:\n\n# Define Street-Crime List\n# target_crime_types <- c(\n#   \"Robbery Firearm\",\n#   \"Robbery No Firearm\",\n#   \"Aggravated Assault Firearm\",\n#   \"Aggravated Assault No Firearm\",\n#   \"Homicide - Criminal\",\n#   \"Rape\",\n#   \"Other Sex Offenses (Not Commercialized)\",\n#   \"Weapon Violations\",\n#   \"Narcotic / Drug Law Violations\",\n#   \"Vandalism/Criminal Mischief\",\n#   \"Prostitution and Commercialized Vice\",\n#   \"Public Drunkenness\"\n# )\n\ncrime_raw <- read_csv(\"data/crime2024.csv\")\n\n# Filter & Transform\ncrime_raw <- crime_raw %>%\n  filter(!is.na(lat) & !is.na(lng))\n\ncrime_q1 <- crime_raw %>%\n  filter(lubridate::month(dispatch_date) %in% 1:3) %>%\n  mutate(\n    crime_date = as.Date(dispatch_date), \n    day_of_week = wday(crime_date), # 1 is Sunday, 7 is Saturday\n    is_crime_weekend = if_else(day_of_week %in% c(1, 7), 1, 0)\n  ) %>%\n    \n  st_as_sf(coords = c(\"lng\", \"lat\"), crs = 4326) %>%\n  st_transform(2272)  \n\n # Filter Apr to Jun\ncrime_sf <- crime_raw %>%\n  filter(lubridate::month(dispatch_date) %in% 4:6)%>%\n  \n  #filter(text_general_code %in% target_crime_types) %>%\n  \n  mutate(\n    crime_date = as.Date(dispatch_date), \n    day_of_week = wday(crime_date), # 1 is Sunday, 7 is Saturday\n    is_crime_weekend = if_else(day_of_week %in% c(1, 7), 1, 0)\n  ) %>%\n  \n  st_as_sf(coords = c(\"lng\", \"lat\"), crs = 4326) %>%\n  st_transform(2272)\n\ncat(\"Total Selected Crimes (Count):\", nrow(crime_sf), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal Selected Crimes (Count): 24184 \n```\n\n\n:::\n:::\n\n\n### 1.2.2 Census data (tidycensus):\n\nTo isolate the true impact of transit ridership on crime, we must first\naccount for the socio-economic context of the neighborhood. A bus stop\nin a distressed area faces different risks than one in a wealthy\nsuburb.\\\nBy integrating 2023 ACS Census data, we control for structural\ndisadvantages—such as poverty rates, unemployment, and housing vacancy.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_api_key(\"42bf8a20a3df1def380f330cf7edad0dd5842ce6\", overwrite = TRUE, install = TRUE)\n```\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load Census data for Philadelphia tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    total_pop = \"B01003_001\",\n    poverty_pop = \"B17001_002\",\n    med_income = \"B19013_001\",\n    ba_degree = \"B15003_022\",\n    total_edu = \"B15003_001\",\n    labor_force = \"B23025_003\",\n    unemployed = \"B23025_005\",\n    total_housing = \"B25002_001\",\n    vacant_housing = \"B25002_003\"\n  ),\n  year = 2023, \n  state = \"PA\",\n  county = \"Philadelphia\",\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  st_transform(2272) %>%\n  mutate(\n    Poverty_Rate = poverty_popE / total_popE,\n    Med_Income = med_incomeE,\n    ba_rate = 100 * ba_degreeE / total_eduE,\n    unemployment_rate = 100 * unemployedE / labor_forceE,\n    vacancy_rate = 100 * vacant_housingE / total_housingE\n  ) %>%\n  dplyr::select(GEOID, Poverty_Rate, Med_Income, ba_rate, unemployment_rate, vacancy_rate)\n```\n:::\n\n\n### 1.2.3 Spatial amenities\n\nWe ingest data from OpenDataPhilly to capture the built environment's\nimpact on safety. This includes `Alcohol Outlets` (potential crime\ngenerators), `Street Lights` (natural surveillance/visibility) and\n`Police Stations` (formal guardianship/deterrence).\n\n-   [Alcohol\n    Outlets](https://github.com/mafichman/cpln_6890/blob/main/plcb_licenses/PHL_PLCB_geocoded.csv)\n\n-   [Street Poles](https://opendataphilly.org/datasets/street-poles/)\n\n-   [Police\n    Stations](https://opendataphilly.org/datasets/police-stations/)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A. Alcohol Outlets (Crime Generators)\nalcohol_sf <- read_csv(\"data/PHL_PLCB_geocoded.csv\") %>%\n  filter(!is.na(lon) & !is.na(lat)) %>%\n  st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326) %>%\n  st_transform(2272)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# B. Street Lights (Guardianship)\nlights_sf <- read_csv(\"data/Street_Poles.csv\") %>%\n  filter(!is.na(X) & !is.na(Y)) %>%\n  st_as_sf(coords = c(\"X\", \"Y\"), crs = 3857) %>%\n  st_transform(2272)\n```\n:::\n\n\nProximity to police stations acts as a proxy for formal guardianship. We\nload these coordinates to later calculate the distance-based deterrence\neffect.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# C. Police Stations (Guardianship) \npolice_sf <- st_read(\"data/Police_Stations.geojson\", quiet = TRUE) %>%\n  st_transform(2272) \n\ncat(\"Total Police Stations:\", nrow(police_sf))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal Police Stations: 20\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Phase 2: Feature Engineering\n\nPhase 2 transforms our raw spatial data into analytical features. A bus\nstop is not just a point on a map; it is the center of a dynamic\nmicro-environment. To capture this, we employ a **400-meter buffer**\napproach—roughly equivalent to a **5-minute walk**, defining the\n'catchment area' for each station.\n\nAfter that, we shift our focus to investigating the aggregate\nrelationships between our independent variables (e.g., ridership, built\nenvironment) and the dependent variable (crime counts). This exploratory\nanalysis allows us to observe baseline correlations and structural\npatterns, providing the necessary empirical support for our subsequent\n**Negative Binomial modeling**.\n\n## 2.1 Buffer creation:\n\n### 2.1.1 400m buffer\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create Buffer(400m)\nbus_buffer <- st_buffer(bus_long, 1312)\n```\n:::\n\n\n### 2.1.2 Crime numbers\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Calculate total count\n# Calculate crime_sf data set covers how many weekdays and weekends\nday_counts <- crime_sf %>%\n  st_drop_geometry() %>%\n  group_by(is_crime_weekend) %>%\n  summarise(n_days = n_distinct(crime_date)) \n\nprint(day_counts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  is_crime_weekend n_days\n             <dbl>  <int>\n1                0     65\n2                1     26\n```\n\n\n:::\n\n```{.r .cell-code}\n# 2. Join and calculate daily crime Rate\ncrime_agg <- st_join(bus_buffer, crime_sf, join = st_intersects) %>%\n  filter(is_weekend == is_crime_weekend) %>%\n  group_by(Stop_Code, is_weekend) %>%\n  summarise(\n    Crime_Total_Count = n() \n  ) %>%\n  st_drop_geometry() %>%\n  \n  left_join(day_counts, by = c(\"is_weekend\" = \"is_crime_weekend\")) %>%\n  mutate(\n    Crime_Daily_Rate = Crime_Total_Count / n_days,\n    \n    # Keep n_days，as negative binomial regresssion offset\n    Exposure_Days = n_days\n  )\n\nhead(crime_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n# Groups:   Stop_Code [3]\n  Stop_Code is_weekend Crime_Total_Count n_days Crime_Daily_Rate Exposure_Days\n      <dbl>      <dbl>             <int>  <int>            <dbl>         <int>\n1         2          0                11     65           0.169             65\n2         2          1                 2     26           0.0769            26\n3         4          0                70     65           1.08              65\n4         4          1                26     26           1                 26\n5         5          0               102     65           1.57              65\n6         5          1                34     26           1.31              26\n```\n\n\n:::\n:::\n\n\n### 2.1.3 Spatial Feature\n\nWe know that a dangerous corner doesn't become safe overnight. To make\nour model fair, we must acknowledge that some stops have a history of\ntrouble.\n\nWe calculated the crime counts for each stop **from the previous season\n(Q1)**. We try to explain: 'Given how dangerous this spot usually is,\ndoes adding more bus riders make it safer or worse?'\n\n\n::: {.cell}\n\n```{.r .cell-code}\nday_counts_q1 <- crime_q1 %>%\n  st_drop_geometry() %>%\n  group_by(is_crime_weekend) %>%\n  summarise(n_days_lag = n_distinct(crime_date)) \n\nprint(day_counts_q1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  is_crime_weekend n_days_lag\n             <dbl>      <int>\n1                0         65\n2                1         26\n```\n\n\n:::\n\n```{.r .cell-code}\ncrime_lag_q1 <- st_join(bus_buffer, crime_q1, join = st_intersects) %>%\n  filter(is_weekend == is_crime_weekend) %>%\n  group_by(Stop_Code, is_weekend) %>%\n  summarise(\n    Crime_Total_Count_lag = n() \n  ) %>%\n  st_drop_geometry() %>%\n  left_join(day_counts_q1, by = c(\"is_weekend\" = \"is_crime_weekend\")) %>%\n  mutate(\n    Crime_Daily_Rate_lag = Crime_Total_Count_lag / n_days_lag,\n    Exposure_Days_lag    = n_days_lag\n  )\n\nhead(crime_lag_q1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n# Groups:   Stop_Code [3]\n  Stop_Code is_weekend Crime_Total_Count_lag n_days_lag Crime_Daily_Rate_lag\n      <dbl>      <dbl>                 <int>      <int>                <dbl>\n1         2          0                     5         65               0.0769\n2         2          1                     2         26               0.0769\n3         4          0                    63         65               0.969 \n4         4          1                    26         26               1     \n5         5          0                    52         65               0.8   \n6         5          1                    27         26               1.04  \n# ℹ 1 more variable: Exposure_Days_lag <int>\n```\n\n\n:::\n:::\n\n\n### 2.1.3 Alcohol Numbers\n\nAlcohol outlets are established 'crime generators.' We load their\nlocations to model areas with higher potential for intoxication-related\nconflicts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalcohol_agg <- st_join(bus_buffer, alcohol_sf, join = st_intersects) %>%\n  group_by(Stop_Code, is_weekend) %>%\n  summarise(Alcohol_Count = n() - 1) %>% # Subtract 1 because st_join is left join (self-intersection NA check)\n  st_drop_geometry()\n```\n:::\n\n\n### 2.1.4 Infrastructure Numbers\n\nStreet lighting is a key component of CPTED (Crime Prevention Through\nEnvironmental Design). We process the location of street poles to\nestimate visibility and natural surveillance levels.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlight_agg <- st_join(bus_buffer, lights_sf, join = st_intersects) %>%\n  group_by(Stop_Code, is_weekend) %>%\n  summarise(Light_Count = n() - 1) %>%\n  st_drop_geometry()\n```\n:::\n\n\n### 2.1.5 Census Demographics\n\nTo control for neighborhood context, we calculated the average:\\\n- `Avg_Poverty`: Rate of economic deprivation.\\\n- `Avg_Income`: Proxy for local wealth and resources.\\\n- `Avg_BA`: Educational attainment.\\\n- `Avg_Unemployment`: Measure of labor market instability.\\\n- `Avg_Vacancy`: Indicator of physical disorder.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Average Census Demographics\ncensus_agg <- st_join(bus_buffer, philly_census, join = st_intersects) %>%\n  group_by(Stop_Code, is_weekend) %>%\n  summarise(\n    Avg_Poverty = mean(Poverty_Rate, na.rm = TRUE),\n    Avg_Income = mean(Med_Income, na.rm = TRUE),\n    Avg_BA = mean(ba_rate, na.rm = TRUE),\n    Avg_Unemployment = mean(unemployment_rate, na.rm = TRUE),\n    Avg_Vacancy = mean(vacancy_rate, na.rm = TRUE)\n  ) %>%\n  st_drop_geometry()\n```\n:::\n\n\n## 2.2 k-Nearest Neighbor features:\n\n### 2.2.1 Police station (KNN-1)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate distance to nearest police station\ndist_matrix <- st_distance(bus_long, police_sf)\n\nbus_long$Dist_Police <- apply(dist_matrix, 1, min) / 5280\n```\n:::\n\n\n## 2.3 Get Police Service Area (PSA) ID for Fixed Effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\npsa_sf <- st_read(\"data/Boundaries_PSA.geojson\", quiet = TRUE) %>%\n  st_transform(2272) %>% \n  dplyr::select(PSA_ID = PSA_NUM) \n\n# Spatial Match: Define each bus stop to PSA\nstop_psa_mapping <- bus_long %>%\n  filter(is_weekend == 0) %>% \n  st_join(psa_sf) %>% # Spatial Join：Point to Polygon\n  st_drop_geometry() %>%\n  dplyr::select(Stop_Code, PSA_ID) %>%\n  \n  distinct(Stop_Code, .keep_all = TRUE)\n\ncat(\"PSA mapping created for\", nrow(stop_psa_mapping), \"stops.\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPSA mapping created for 5884 stops.\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(stop_psa_mapping)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  Stop_Code PSA_ID\n      <dbl> <chr> \n1       759 033   \n2     16397 251   \n3     17921 351   \n4     16054 352   \n5     16102 221   \n6     16104 221   \n```\n\n\n:::\n:::\n\n\n## 2.4 Merge Features into Master Dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_data <- bus_long %>%\n  # Join all aggregated tables\n  left_join(crime_agg,     by = c(\"Stop_Code\", \"is_weekend\")) %>%\n  left_join(crime_lag_q1,  by = c(\"Stop_Code\", \"is_weekend\")) %>%\n  left_join(alcohol_agg,   by = c(\"Stop_Code\", \"is_weekend\")) %>%\n  left_join(light_agg,     by = c(\"Stop_Code\", \"is_weekend\")) %>%\n  left_join(census_agg,    by = c(\"Stop_Code\", \"is_weekend\")) %>%\n  \n  left_join(stop_psa_mapping, by = \"Stop_Code\") %>%\n  \n   mutate(\n    # 1. Handle NAs for Counts\n    Crime_Total_Count = replace_na(Crime_Total_Count, 0),\n    Crime_Daily_Rate  = replace_na(Crime_Daily_Rate, 0),\n\n    # Deal with NA in lag crime\n    Crime_Total_Count_lag = replace_na(Crime_Total_Count_lag, 0),\n    Crime_Daily_Rate_lag  = replace_na(Crime_Daily_Rate_lag, 0),\n\n    Alcohol_Count = replace_na(Alcohol_Count, 0),\n    Light_Count   = replace_na(Light_Count, 0),\n    \n    # 2. Log transform Ridership\n    Log_Ridership = log(Ridership + 1),\n    \n    # 3. Create Factor for Interaction Term\n    is_weekend_factor = factor(is_weekend, levels = c(0, 1), \n                               labels = c(\"Weekday\", \"Weekend\")),\n\n  ) %>%\n  \n  # 4. Clean up\n  filter(!is.na(PSA_ID)) %>%\n  na.omit() \n\ncat(\"Final Panel Dataset Rows:\", nrow(final_data))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFinal Panel Dataset Rows: 11066\n```\n\n\n:::\n:::\n\n\n## 2.5 Check the density of PSA data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Panel Data Rows\npsa_counts <- final_data %>%\n  group_by(PSA_ID) %>%\n  summarise(\n    n_observations = n(),              \n    n_stops = n_distinct(Stop_Code)    \n  ) %>%\n  arrange(n_observations)\n\nprint(head(psa_counts, 10))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 10 features and 3 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 2669882 ymin: 215531.6 xmax: 2715062 ymax: 279357.4\nProjected CRS: NAD83 / Pennsylvania South (ftUS)\n# A tibble: 10 × 4\n   PSA_ID n_observations n_stops                                        geometry\n   <chr>           <int>   <int>                   <MULTIPOINT [US_survey_foot]>\n 1 122                32      16 ((2670537 223892.4), (2670585 223932.8), (2670…\n 2 124                58      29 ((2671643 232878.2), (2672084 233106.1), (2672…\n 3 053                68      42 ((2670063 279330.9), (2670112 279357.4), (2670…\n 4 012                83      44 ((2685082 218564.9), (2685568 218997.3), (2686…\n 5 224                86      43 ((2686092 246848.8), (2686176 246409.7), (2686…\n 6 393                90      45 ((2688934 252812), (2688968 253070.2), (268922…\n 7 181                96      48 ((2669882 237256), (2669902 237214.7), (266998…\n 8 243                96      49 ((2706035 247307.4), (2706350 248302.6), (2706…\n 9 242                98      49 ((2702265 250424.1), (2702297 250520.3), (2702…\n10 052                99      50 ((2671211 266842), (2671303 266812.6), (267140…\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Phase 3: Exploratory Data Analysis\n\n## 3.1 Distribution of Crime and Bus Stop Ridership (histogram)\n\nDoes ridership follow a normal distribution? No. That's why we need\nNegative Binomial.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gridExtra)\np1 <- ggplot(final_data, aes(x = Ridership)) +\n  geom_histogram(fill = \"#3182bd\", bins = 50) +\n  labs(title = \"Distribution of Ridership\", x = \"Daily Boardings\") + plotTheme\n\np2 <- ggplot(final_data, aes(x = Crime_Total_Count)) +\n  geom_histogram(fill = \"#de2d26\", bins = 50) +\n  labs(title = \"Distribution of Crime\", x = \"Crime Count (400m)\") + plotTheme\n\ngrid.arrange(p1, p2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nThe histograms reveal that both Ridership (Left) and Crime Counts\n(Right) follow **a highly right-skewed, 'long-tail' distribution**,\nrather than a normal bell curve. This extreme skewness mathematically\nconfirm that a standard OLS Linear Regression would be biased.\n\nThis visual evidence creates a compelling mandate for using **Negative\nBinomial Regression**, which is specifically designed to handle such\nskewed count data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_crime <- mean(final_data$Crime_Total_Count, na.rm = TRUE)\nvar_crime <- var(final_data$Crime_Total_Count, na.rm = TRUE)\n\ncat(\"Mean:\", mean_crime, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean: 30.91478 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Variance:\", var_crime, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nVariance: 1190.485 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Ratio (Var/Mean):\", var_crime / mean_crime, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRatio (Var/Mean): 38.50861 \n```\n\n\n:::\n:::\n\n\nWhile many bus stops have zero incidents, a few 'hotspots' have very\nhigh counts. This causes **the variance to be much larger than the\nmean**. To address this overdispersion，which violates the core\nassumption of Poisson regression， we employed a **Negative Binomial\nmodel**. This approach allows us to model the data more accurately\nwithout inflating the significance of our findings.\n\n## 3.2 Spatial distribution of crime and Bus Stop Ridership(map)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Extract Coordinates\n\n# A. Bus Stop data\nbus_plot_data <- bus_long %>%\n  filter(is_weekend == 0) %>%   \n  mutate(\n    X = st_coordinates(geometry)[,1],\n    Y = st_coordinates(geometry)[,2]\n  ) %>%\n  st_drop_geometry() \n\n# B. Crime data\ncrime_plot_data <- crime_sf %>%\n  mutate(\n    X = st_coordinates(geometry)[,1],\n    Y = st_coordinates(geometry)[,2]\n  ) %>%\n  st_drop_geometry()\n\n# 2. Create Maps\n\n# Left: Ridership Density\np_ridership <- ggplot() +\n  geom_sf(data = philly_boundary, fill = \"#f5f5f5\", color = \"grey80\") +\n  \n  stat_density_2d(\n    data = bus_plot_data, \n    aes(x = X, y = Y, fill = ..level.., weight = Ridership), \n    geom = \"polygon\", \n    alpha = 0.75\n  ) +\n  \n  scale_fill_distiller(palette = \"Blues\", direction = 1, guide = \"none\") +\n  labs(\n    title = \"Weekday Ridership Hotspots\", \n    subtitle = \"High Transit Activity Zones\"\n  ) +\n  mapTheme\n\n# Right：Crime Density\np_crime_map <- ggplot() +\n  geom_sf(data = philly_boundary, fill = \"#f5f5f5\", color = \"grey80\") +\n  \n  stat_density_2d(\n    data = crime_plot_data, \n    aes(x = X, y = Y, fill = ..level..), \n    geom = \"polygon\", \n    alpha = 0.4,       \n    bins = 30,         \n    adjust = 0.5       \n  ) +\n  \n  scale_fill_distiller(palette = \"Reds\", direction = 1, guide = \"none\") +\n  labs(\n    title = \"Crime Hotspots\", \n    subtitle = \"High Incident Zones\"\n  ) +\n  mapTheme\n\n# 3. Combine Side-by-Side\n\ncombined_map <- p_ridership + p_crime_map +\n  plot_annotation(\n    title = \"Spatial Mismatch Analysis: Eyes on the Street vs. Targets?\",\n    subtitle = \"Left: Where people are (Ridership) | Right: Where crimes happen\",\n    theme = theme(\n      plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n      plot.subtitle = element_text(size = 12, color = \"grey40\", hjust = 0.5)\n    )\n  )\n\ncombined_map\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nTransit activity is **anchored in Center City** and **radiates outward\nalong the major arterials** (Broad St.and Market St.). However, crime\nexhibits a **polycentric distribution**. Beyond the city center, we\nobserve significant high-crime clusters in North and West Philadelphia\n(Kensington/Allegheny).\n\nThis spatial mismatch suggests that **ridership volume alone cannot\nexplain crime risk**. While the downtown core attracts crime due to\nsheer foot traffic ('Targets'), the peripheral hotspots are likely\ndriven by other environmental factors—such as socioeconomic disadvantage\nor the presence of crime generators (e.g., alcohol outlets)—rather than\ntransit volume alone.\n\n## 3.3 Crime vs. Bus Stop Ridership (scatter plots)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbar_plot_data <- final_data %>%\n  st_drop_geometry() %>% \n  group_by(is_weekend_factor) %>% \n  summarise(\n    Avg_Ridership = mean(Ridership, na.rm = TRUE), \n    Avg_Crime_count = mean(Crime_Daily_Rate, na.rm = TRUE)\n  ) %>%\n  # Long\n  pivot_longer(\n    cols = c(Avg_Ridership, Avg_Crime_count),\n    names_to = \"Metric\",\n    values_to = \"Value\"\n  ) %>%\n  mutate(\n    Metric_Label = case_when(\n      Metric == \"Avg_Ridership\" ~ \"Average Ridership\",\n      Metric == \"Avg_Crime_count\" ~ \"Average Crime Count\"\n    )\n  )\n\nggplot(bar_plot_data, aes(x = is_weekend_factor, y = Value, fill = is_weekend_factor)) +\n  geom_col(width = 0.6, alpha = 0.9) +\n  \n  facet_wrap(~Metric_Label, scales = \"free_y\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#3182bd\", \"Weekend\" = \"#de2d26\")) +\n  \n  labs(\n    title = \"Volume vs. Risk: Weekday vs. Weekend\",\n    subtitle = \"Comparison of Average  Ridership and Crime per Stop\",\n    x = \"\", \n    y = \"Average Count\",\n    fill = \"Time Period\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 10, color = \"grey40\", hjust = 0.5),\n    strip.text = element_text(size = 12, face = \"bold\"), \n    axis.text.x = element_text(size = 11, face = \"bold\"),\n    legend.position = \"none\" # \n  )\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Crime vs. Ridership (Interaction Plot)\n\nggplot(final_data, aes(x = Log_Ridership, y = Crime_Daily_Rate, color = is_weekend_factor)) +\n  geom_point(alpha = 0.1, size = 1) +\n  geom_smooth(method = \"glm\", method.args = list(family = \"quasipoisson\"), se = TRUE) +\n  scale_color_manual(values = c(\"Weekday\" = \"#3182bd\", \"Weekend\" = \"#de2d26\")) +\n  labs(\n    title = \"Does Ridership impact Crime differently on Weekends?\",\n    subtitle = \"Interaction Effect (Normalized by Number of Days)\",\n    x = \"Log(Daily Ridership)\",\n    y = \"Average Daily Crime Count (per 400m)\", \n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/eda_interaction-1.png){width=672}\n:::\n:::\n\n\n-   **Crime Follows the Crowd (Bar Chart):**\\\n    The left bar charts show that crime volume drops significantly on\n    weekends, mirroring the drop in ridership shown in the right chart.\n    This confirms that crime is likely driven by opportunity—fewer\n    people on the street simply means fewer targets and fewer conflicts.\n\n-   **The Risk \"Conversion Rate\" is Constant (Scatter Plot):**\\\n    The interaction plot reveals **a consistent positive correlation**\n    between ridership and crime counts across both weekdays and\n    weekends. While the slopes exhibit only minor differences, the\n    methodological value of this split is significant. By comparing the\n    same bus stops during different time periods (Weekday vs. Weekend),\n    we **inherently control for static environmental factors**, such as\n    poverty rates, street lighting, and proximity to alcohol outlets,\n    which remain constant regardless of the day.\\\n    Consequently, this acts as a quasi-experimental control: since the\n    physical environment is fixed, the persistent upward trend suggests\n    that **ridership itself is a direct driver of crime risk**. This\n    supports the 'Targets' hypothesis over the 'Eyes on the Street'\n    theory, indicating that higher passenger volumes attract\n    opportunistic crime regardless of the temporal context.\n\n## 3.4 Crime vs. Spatial & Social features (scatter plots)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\nlibrary(scales)\n\nplot_data <- final_data %>%\n  mutate(\n    log_crime = log(Crime_Daily_Rate + 0.01), # +0.01 to avoid log(0)\n    log_income = log(Avg_Income + 1)\n  )\n\n# --- 1. POI & Infrastructure (Built Environment) ---\n\n# A. Alcohol Outlets\np1 <- ggplot(plot_data, aes(x = Alcohol_Count, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#6A1B9A\") +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Log(Crime) vs. Alcohol Outlets\",\n       subtitle = \"Check for diminishing returns\",\n       x = \"Count of Alcohol Outlets\", y = \"Log(Crime Count)\") +\n  plotTheme\n\n# B. Street Lights\np2 <- ggplot(plot_data, aes(x = Light_Count, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#6A1B9A\") +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Log(Crime) vs. Street Lights\",\n       subtitle = \"Is the relationship linear?\",\n       x = \"Count of Street Lights\", y = \"\") +\n  plotTheme\n\n# C. Distance to Police\np3 <- ggplot(plot_data, aes(x = Dist_Police, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#6A1B9A\") +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  labs(title = \"Log(Crime) vs. Dist to Police\",\n       subtitle = \"Check for U-shape or threshold\",\n       x = \"Distance to Station (Miles)\", y = \"\") +\n  plotTheme\n\n# --- 2. Demographics (Census) ---\n\n# D. Poverty Rate \np4 <- ggplot(plot_data, aes(x = Avg_Poverty, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#3182bd\") +\n  geom_smooth(method = \"loess\", color = \"orange\", se = FALSE) +\n  scale_x_continuous(labels = scales::percent) +\n  labs(title = \"Log(Crime) vs. Poverty Rate\",\n       x = \"Poverty Rate\", y = \"Log(Crime Count)\") +\n  plotTheme\n\n# E. Median Income\np5 <- ggplot(plot_data, aes(x = Avg_Income, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#3182bd\") +\n  geom_smooth(method = \"loess\", color = \"orange\", se = FALSE) +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Log(Crime) vs. Median Income\",\n       subtitle = \"Does wealth shield against crime?\",\n       x = \"Median Household Income\", y = \"\") +\n  plotTheme\n\n# F. Vacancy Rate\np6 <- ggplot(plot_data, aes(x = Avg_Vacancy, y = log_crime)) +\n  geom_point(alpha = 0.1, color = \"#3182bd\") +\n  geom_smooth(method = \"loess\", color = \"orange\", se = FALSE) +\n  scale_x_continuous(labels = scales::percent) +\n  labs(title = \"Log(Crime) vs. Vacancy Rate\",\n       x = \"Housing Vacancy Rate\", y = \"\") +\n  plotTheme\n\n# --- Combine Plots ---\n(p1 | p2 | p3) / (p4 | p5 | p6) +\n  plot_annotation(\n    title = \"Exploratory Analysis: Variable Functional Forms\",\n    subtitle = \"Red Line = Loess Smoother (Non-linear trend)\",\n    theme = theme(plot.title = element_text(size = 16, face = \"bold\"))\n  )\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/3.4_scatter_plots-1.png){width=672}\n:::\n:::\n\n\nBefore finalizing our model, we conducted an extensive exploratory\nanalysis, testing relationships across multiple potential independent\nvariables and their non-linear transformations. While we only present\nthe variables with the most significant statistical relationships and\npolicy implications here, this rigorous process of trial and error was\nessential to ensure the robustness of our final model. The charts above\nrepresent the distilled 'risk signals' identified from this\ncomprehensive screening.\n\n-   `Alcohol Outlets`: The plot shows that crime goes up quickly with\n    the first few alcohol stores. However, as the number of stores gets\n    very high, the line flattens out **(Diminishing marginal returns)**.\n    We will try using a **log transformation** for this feature. This\n    tells the model that the first few stores have a bigger impact than\n    the later ones.\n\n-   `Street Lights`: The red trend line is **not straight**. It goes up\n    as lights increase (usually in busy areas), but then it curves. In\n    later this study, we used a **polynomial (2nd degree) term**. This\n    allows the model to draw a curved line instead of a straight one to\n    fit the data better.\n\n-   `Distance to Police`: The line looks **mostly straight** and goes\n    down slightly, so we kept this variable linear.\n\n-   `Poverty Rate`: As poverty goes up, crime generally goes up. The\n    line is **mostly straight**. We also kept it as a **standard linear\n    variable**.\n\n-   `Median Income`: The line looks a bit like a **\"U\" shape**. Crime is\n    high in low-income areas, drops in middle-income areas, and rises\n    slightly or stays flat in higher-income areas. We added a **squared\n    term (\\^2)**. This helps the model understand that crime can be high\n    at both low and high income levels, but low in the middle.\n\n-   `Vacancy Rate`: The line looks like an **upside-down \"U\"**. Crime\n    goes up as vacancy increases, but when vacancy gets very high (empty\n    neighborhoods), crime actually drops. We also added a squared term\n    (\\^2) for this.\n\n## 3.5 Correlation Matrix of Features for all Features\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggcorrplot)\n\nnumeric_vars <- final_data %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    Crime_Daily_Rate, \n    Ridership, \n    Alcohol_Count, \n    Light_Count, \n    Dist_Police, \n    Avg_Poverty, \n    Avg_Income, \n    Avg_Unemployment,\n    Avg_Vacancy\n  )\n\ncorr_matrix <- cor(numeric_vars, use = \"complete.obs\")\n\nggcorrplot(\n  corr_matrix, \n  method = \"square\", \n  type = \"lower\", \n  lab = TRUE, \n  lab_size = 3, \n  colors = c(\"#6D9EC1\", \"white\", \"#E46726\"), \n  title = \"Correlation Matrix of Features\",\n  ggtheme = theme_minimal()\n)\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n-   The correlation matrix reveals a critical issue of multicollinearity\n    among the socioeconomic predictors. Specifically, Average Poverty\n    Rate (Avg_Poverty) and Median Household Income (Avg_Income) exhibit\n    a strong negative correlation of -0.81. Additionally, Unemployment\n    Rate (Avg_Unemployment) shows a strong negative correlation with\n    Income (-0.70) and a moderately high positive correlation with\n    Poverty (0.66).\n\n-   These high coefficients suggest that **Poverty, Income, and\n    Unemployment** are capturing overlapping dimensions of neighborhood\n    socioeconomic status. While this flags a risk of multicollinearity,\n    correlation coefficients alone are insufficient for removing\n    variables. Therefore, we will proceed to calculate the **Variance\n    Inflation Factor (VIF) in the next step** to rigorously quantify the\n    severity of multicollinearity and determine the appropriate strategy\n    for feature selection or transformation.\n\n## 3.6 Crime distribution in weekdays and weekends\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(final_data, aes(x = is_weekend_factor, y = Crime_Daily_Rate, fill = is_weekend_factor)) +\n  geom_boxplot(alpha = 0.7, outlier.shape = NA) + \n  \n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  \n  coord_cartesian(ylim = c(0, quantile(final_data$Crime_Daily_Rate, 0.95))) +\n  \n  scale_fill_manual(values = c(\"Weekday\" = \"#3182bd\", \"Weekend\" = \"#de2d26\")) +\n  \n  labs(\n    title = \"Daily Crime Risk: Weekday vs. Weekend\",\n    subtitle = \"Comparison of Average Daily Crime Counts per Stop\",\n    x = \"Time Period\",\n    y = \"Average Daily Crime Count (per 400m)\", \n    caption = \"Note: Values represent daily averages to account for fewer weekend days per year.\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n-   **Stability of Crime Volume:** The means (indicated by white\n    diamonds) and medians (solid black lines) for both weekdays and\n    weekends are nearly identical, appearing at approximately the same\n    daily average level (\\~0.6 incidents). This pattern suggests that\n    the aggregate demand for public safety resources at these bus stops\n    does not fluctuate significantly throughout the week.\n\n-   **Justification for Pseudo-Panel Modeling：** While this chart shows\n    crime counts are constant, we know that generally ridership volume\n    typically drops on weekends. If the outcome (crime) remains the same\n    while the input (ridership) decreases, it implies that the risk\n    intensity per rider is likely higher on weekends. Constructing a\n    pseudo-panel allows us to mathematically capture this changing\n    elasticity, rather than averaging it out.\n\n    -   By disaggregating the data into **weekday and weekend\n        observations** for each stop, we create a pseudo-panel structure\n        that acts as a natural control. Since the **physical environment\n        (lighting, poverty, location) remains fixed** for a specific\n        stop, splitting the data allows our model to **isolate ridership\n        as the primary changing variable**, thereby enabling a more\n        robust causal inference about how passenger flows specifically\n        impact crime rates under different density conditions.\n\n------------------------------------------------------------------------\n\n# Phase 4: Model Building\n\n## 4.1 Ridership only:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_1 <- glm.nb(Crime_Total_Count ~ \n                    Log_Ridership + \n                    offset(log(Exposure_Days)), \n                  data = final_data)\nsummary(model_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership + offset(log(Exposure_Days)), \n    data = final_data, init.theta = 1.962937689, link = log)\n\nCoefficients:\n               Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -1.328484   0.018925  -70.20   <2e-16 ***\nLog_Ridership  0.243197   0.004944   49.19   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.9629) family taken to be 1)\n\n    Null deviance: 14335  on 11065  degrees of freedom\nResidual deviance: 11852  on 11064  degrees of freedom\nAIC: 92538\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.9629 \n          Std. Err.:  0.0274 \n\n 2 x log-likelihood:  -92531.6570 \n```\n\n\n:::\n:::\n\n\n-   This baseline model establishes the **fundamental relationship**\n    between transit ridership and crime counts without any confounding\n    factors. It serves as a benchmark to test the raw association.\n    specifically, whether higher passenger volume acts as a \"crime\n    generator\" (providing more potential targets) or a deterrent\n    (providing \"eyes on the street\"). The **offset term** ensures we are\n    modeling the rate of crime per day, accounting for differences in\n    exposure periods.\n\n## 4.2 The Interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_2 <- glm.nb(Crime_Total_Count ~ \n                    Log_Ridership * is_weekend_factor + \n                    offset(log(Exposure_Days)), \n                  data = final_data) \nsummary(model_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n    offset(log(Exposure_Days)), data = final_data, init.theta = 1.968491375, \n    link = log)\n\nCoefficients:\n                                        Estimate Std. Error z value Pr(>|z|)\n(Intercept)                            -1.434242   0.027417 -52.311  < 2e-16\nLog_Ridership                           0.263192   0.006798  38.716  < 2e-16\nis_weekend_factorWeekend                0.186359   0.038085   4.893 9.92e-07\nLog_Ridership:is_weekend_factorWeekend -0.034408   0.010040  -3.427  0.00061\n                                          \n(Intercept)                            ***\nLog_Ridership                          ***\nis_weekend_factorWeekend               ***\nLog_Ridership:is_weekend_factorWeekend ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.9685) family taken to be 1)\n\n    Null deviance: 14371  on 11065  degrees of freedom\nResidual deviance: 11849  on 11062  degrees of freedom\nAIC: 92509\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.9685 \n          Std. Err.:  0.0275 \n\n 2 x log-likelihood:  -92498.9340 \n```\n\n\n:::\n:::\n\n\n-   In this step, we introduce the **interaction term (Log_Ridership \\*\n    is_weekend_factor)** to test our core hypothesis: does the impact of\n    ridership on crime change fundamentally during weekends? This\n    specification allows the model to differentiate the \"commuter\n    effect\" from potentially riskier weekend dynamics. It helps us\n    determine if a specific bus stop becomes more dangerous per rider on\n    weekends, even if the total volume of passengers decreases.\n\n## 4.3 Built Environment and Demographics features:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_3 <- glm.nb(Crime_Total_Count ~ \n                    Log_Ridership * is_weekend_factor + \n                    log(Alcohol_Count + 1) +        \n                    poly(Light_Count, 2) +          \n                    Avg_Poverty +         \n                    Avg_Vacancy + I(Avg_Vacancy^2) +       \n                    Avg_Income + I(Avg_Income^2)  +\n                    Avg_Unemployment +\n                    Dist_Police +\n                    offset(log(Exposure_Days)), \n                  data = final_data)\nsummary(model_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n    log(Alcohol_Count + 1) + poly(Light_Count, 2) + Avg_Poverty + \n    Avg_Vacancy + I(Avg_Vacancy^2) + Avg_Income + I(Avg_Income^2) + \n    Avg_Unemployment + Dist_Police + offset(log(Exposure_Days)), \n    data = final_data, init.theta = 3.809131636, link = log)\n\nCoefficients:\n                                         Estimate Std. Error z value Pr(>|z|)\n(Intercept)                            -8.603e-01  8.710e-02  -9.877  < 2e-16\nLog_Ridership                           1.102e-01  5.485e-03  20.086  < 2e-16\nis_weekend_factorWeekend                4.330e-02  2.965e-02   1.460  0.14416\nlog(Alcohol_Count + 1)                  2.836e-01  7.490e-03  37.869  < 2e-16\npoly(Light_Count, 2)1                   2.074e+01  9.830e-01  21.094  < 2e-16\npoly(Light_Count, 2)2                  -2.401e+00  6.208e-01  -3.867  0.00011\nAvg_Poverty                             1.310e+00  1.157e-01  11.325  < 2e-16\nAvg_Vacancy                             5.836e-03  3.003e-03   1.943  0.05197\nI(Avg_Vacancy^2)                       -1.034e-04  8.434e-05  -1.226  0.22030\nAvg_Income                             -1.162e-05  1.435e-06  -8.097 5.64e-16\nI(Avg_Income^2)                         5.343e-11  7.797e-12   6.852 7.27e-12\nAvg_Unemployment                       -1.235e-02  1.879e-03  -6.575 4.87e-11\nDist_Police                            -1.986e-01  1.149e-02 -17.278  < 2e-16\nLog_Ridership:is_weekend_factorWeekend -2.319e-02  7.718e-03  -3.004  0.00266\n                                          \n(Intercept)                            ***\nLog_Ridership                          ***\nis_weekend_factorWeekend                  \nlog(Alcohol_Count + 1)                 ***\npoly(Light_Count, 2)1                  ***\npoly(Light_Count, 2)2                  ***\nAvg_Poverty                            ***\nAvg_Vacancy                            .  \nI(Avg_Vacancy^2)                          \nAvg_Income                             ***\nI(Avg_Income^2)                        ***\nAvg_Unemployment                       ***\nDist_Police                            ***\nLog_Ridership:is_weekend_factorWeekend ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(3.8091) family taken to be 1)\n\n    Null deviance: 25397  on 11065  degrees of freedom\nResidual deviance: 11556  on 11052  degrees of freedom\nAIC: 85737\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  3.8091 \n          Std. Err.:  0.0607 \n\n 2 x log-likelihood:  -85706.8380 \n```\n\n\n:::\n:::\n\n\n-   We incorporate criminogenic generators (alcohol outlets), potential\n    guardians (street lights), and socioeconomic indicators (income,\n    vacancy, and poverty).\\\n-   By adjusting for these factors, this model rigorously tests whether\n    ridership has a unique impact on crime, or if high-ridership stops\n    simply happen to be located in disadvantaged or commercially dense\n    neighborhoods. This step is crucial for **isolating the specific\n    effect** of the transit network from broader environmental\n    conditions.\n\n## 4.4 Spatial Fixed Effect\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_4 <- glm.nb(Crime_Total_Count ~ \n                    Log_Ridership * is_weekend_factor + \n                    log(Alcohol_Count + 1) +       \n                    poly(Light_Count, 2) +        \n                    Avg_Poverty +        \n                    Avg_Vacancy + I(Avg_Vacancy^2) +      \n                    Avg_Income + I(Avg_Income^2)  +\n                    Avg_Unemployment +\n                    Dist_Police +         \n                    factor(PSA_ID) +    \n                    offset(log(Exposure_Days)), \n                  data = final_data,\n                  control = glm.control(maxit = 100))\nsummary(model_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n    log(Alcohol_Count + 1) + poly(Light_Count, 2) + Avg_Poverty + \n    Avg_Vacancy + I(Avg_Vacancy^2) + Avg_Income + I(Avg_Income^2) + \n    Avg_Unemployment + Dist_Police + factor(PSA_ID) + offset(log(Exposure_Days)), \n    data = final_data, control = glm.control(maxit = 100), init.theta = 4.730969316, \n    link = log)\n\nCoefficients:\n                                         Estimate Std. Error z value Pr(>|z|)\n(Intercept)                            -4.058e-01  1.071e-01  -3.789 0.000151\nLog_Ridership                           9.525e-02  5.201e-03  18.314  < 2e-16\nis_weekend_factorWeekend                2.432e-05  2.758e-02   0.001 0.999296\nlog(Alcohol_Count + 1)                  2.423e-01  8.067e-03  30.036  < 2e-16\npoly(Light_Count, 2)1                   2.468e+01  1.203e+00  20.510  < 2e-16\npoly(Light_Count, 2)2                  -5.178e+00  7.333e-01  -7.062 1.64e-12\nAvg_Poverty                             8.036e-01  1.364e-01   5.891 3.83e-09\nAvg_Vacancy                             9.710e-03  4.093e-03   2.372 0.017672\nI(Avg_Vacancy^2)                       -1.480e-04  9.976e-05  -1.484 0.137899\nAvg_Income                             -1.750e-05  1.684e-06 -10.396  < 2e-16\nI(Avg_Income^2)                         8.873e-11  8.819e-12  10.061  < 2e-16\nAvg_Unemployment                       -1.928e-02  2.160e-03  -8.924  < 2e-16\nDist_Police                            -2.755e-01  1.534e-02 -17.954  < 2e-16\nfactor(PSA_ID)012                       3.774e-02  7.062e-02   0.534 0.593118\nfactor(PSA_ID)021                       5.770e-01  5.888e-02   9.800  < 2e-16\nfactor(PSA_ID)022                       4.204e-01  6.138e-02   6.848 7.49e-12\nfactor(PSA_ID)023                       2.167e-01  5.230e-02   4.144 3.42e-05\nfactor(PSA_ID)031                      -2.512e-01  5.587e-02  -4.496 6.92e-06\nfactor(PSA_ID)032                       1.861e-01  5.190e-02   3.586 0.000336\nfactor(PSA_ID)033                      -1.804e-01  4.656e-02  -3.874 0.000107\nfactor(PSA_ID)051                      -1.158e-01  6.476e-02  -1.788 0.073805\nfactor(PSA_ID)052                      -3.001e-01  7.173e-02  -4.184 2.87e-05\nfactor(PSA_ID)053                      -3.824e-01  8.832e-02  -4.330 1.49e-05\nfactor(PSA_ID)071                       3.128e-01  6.760e-02   4.627 3.71e-06\nfactor(PSA_ID)072                      -2.708e-01  6.293e-02  -4.303 1.69e-05\nfactor(PSA_ID)073                      -3.697e-01  6.517e-02  -5.672 1.41e-08\nfactor(PSA_ID)081                       4.798e-01  6.006e-02   7.989 1.36e-15\nfactor(PSA_ID)082                      -1.388e-01  5.780e-02  -2.402 0.016302\nfactor(PSA_ID)083                      -4.606e-03  6.210e-02  -0.074 0.940871\nfactor(PSA_ID)091                       1.973e-01  5.179e-02   3.811 0.000139\nfactor(PSA_ID)092                       1.249e-01  5.629e-02   2.219 0.026498\nfactor(PSA_ID)093                      -2.243e-02  5.251e-02  -0.427 0.669180\nfactor(PSA_ID)094                       4.995e-01  5.413e-02   9.229  < 2e-16\nfactor(PSA_ID)095                      -1.978e-01  5.810e-02  -3.404 0.000663\nfactor(PSA_ID)121                       4.666e-01  6.270e-02   7.443 9.85e-14\nfactor(PSA_ID)122                      -1.427e-01  1.038e-01  -1.375 0.169163\nfactor(PSA_ID)123                       8.914e-02  6.188e-02   1.441 0.149665\nfactor(PSA_ID)124                       2.368e-01  7.720e-02   3.067 0.002159\nfactor(PSA_ID)141                      -3.889e-02  5.571e-02  -0.698 0.485112\nfactor(PSA_ID)142                      -1.625e-01  6.301e-02  -2.579 0.009916\nfactor(PSA_ID)143                       1.960e-01  5.740e-02   3.415 0.000637\nfactor(PSA_ID)144                      -1.241e-02  6.515e-02  -0.190 0.848975\nfactor(PSA_ID)151                       1.524e-01  5.272e-02   2.891 0.003845\nfactor(PSA_ID)152                       4.628e-01  5.253e-02   8.810  < 2e-16\nfactor(PSA_ID)153                       5.232e-01  5.387e-02   9.713  < 2e-16\nfactor(PSA_ID)161                      -3.663e-02  5.725e-02  -0.640 0.522209\nfactor(PSA_ID)162                      -5.668e-02  5.983e-02  -0.947 0.343485\nfactor(PSA_ID)171                      -1.610e-01  5.428e-02  -2.965 0.003022\nfactor(PSA_ID)172                      -5.680e-01  6.898e-02  -8.234  < 2e-16\nfactor(PSA_ID)173                      -3.975e-01  5.909e-02  -6.727 1.73e-11\nfactor(PSA_ID)181                      -1.636e-01  6.676e-02  -2.451 0.014265\nfactor(PSA_ID)182                       3.990e-02  5.880e-02   0.679 0.497423\nfactor(PSA_ID)183                      -1.393e-01  5.350e-02  -2.603 0.009229\nfactor(PSA_ID)191                       1.965e-01  5.347e-02   3.674 0.000238\nfactor(PSA_ID)192                       1.749e-02  5.921e-02   0.295 0.767637\nfactor(PSA_ID)193                       2.983e-01  5.720e-02   5.215 1.84e-07\nfactor(PSA_ID)221                       2.063e-01  5.666e-02   3.642 0.000271\nfactor(PSA_ID)222                      -1.035e-02  6.510e-02  -0.159 0.873735\nfactor(PSA_ID)223                       2.647e-01  5.970e-02   4.434 9.23e-06\nfactor(PSA_ID)224                       1.685e-01  6.918e-02   2.435 0.014876\nfactor(PSA_ID)241                       1.121e-01  6.299e-02   1.780 0.075073\nfactor(PSA_ID)242                       3.243e-01  6.764e-02   4.795 1.63e-06\nfactor(PSA_ID)243                       8.122e-02  6.635e-02   1.224 0.220954\nfactor(PSA_ID)251                       1.819e-01  6.727e-02   2.704 0.006846\nfactor(PSA_ID)252                      -2.377e-01  6.457e-02  -3.682 0.000232\nfactor(PSA_ID)253                      -3.656e-01  6.789e-02  -5.385 7.25e-08\nfactor(PSA_ID)254                      -5.605e-02  6.495e-02  -0.863 0.388107\nfactor(PSA_ID)261                      -1.929e-01  6.498e-02  -2.969 0.002990\nfactor(PSA_ID)262                       1.561e-01  5.853e-02   2.667 0.007655\nfactor(PSA_ID)263                      -9.630e-02  5.027e-02  -1.916 0.055399\nfactor(PSA_ID)351                      -3.793e-02  5.096e-02  -0.744 0.456679\nfactor(PSA_ID)352                       6.887e-02  5.383e-02   1.279 0.200771\nfactor(PSA_ID)353                      -2.201e-02  5.796e-02  -0.380 0.704186\nfactor(PSA_ID)391                       1.119e-02  5.277e-02   0.212 0.832001\nfactor(PSA_ID)392                      -1.532e-01  5.705e-02  -2.686 0.007233\nfactor(PSA_ID)393                       1.888e-01  6.928e-02   2.725 0.006431\nLog_Ridership:is_weekend_factorWeekend -1.720e-02  7.148e-03  -2.406 0.016114\n                                          \n(Intercept)                            ***\nLog_Ridership                          ***\nis_weekend_factorWeekend                  \nlog(Alcohol_Count + 1)                 ***\npoly(Light_Count, 2)1                  ***\npoly(Light_Count, 2)2                  ***\nAvg_Poverty                            ***\nAvg_Vacancy                            *  \nI(Avg_Vacancy^2)                          \nAvg_Income                             ***\nI(Avg_Income^2)                        ***\nAvg_Unemployment                       ***\nDist_Police                            ***\nfactor(PSA_ID)012                         \nfactor(PSA_ID)021                      ***\nfactor(PSA_ID)022                      ***\nfactor(PSA_ID)023                      ***\nfactor(PSA_ID)031                      ***\nfactor(PSA_ID)032                      ***\nfactor(PSA_ID)033                      ***\nfactor(PSA_ID)051                      .  \nfactor(PSA_ID)052                      ***\nfactor(PSA_ID)053                      ***\nfactor(PSA_ID)071                      ***\nfactor(PSA_ID)072                      ***\nfactor(PSA_ID)073                      ***\nfactor(PSA_ID)081                      ***\nfactor(PSA_ID)082                      *  \nfactor(PSA_ID)083                         \nfactor(PSA_ID)091                      ***\nfactor(PSA_ID)092                      *  \nfactor(PSA_ID)093                         \nfactor(PSA_ID)094                      ***\nfactor(PSA_ID)095                      ***\nfactor(PSA_ID)121                      ***\nfactor(PSA_ID)122                         \nfactor(PSA_ID)123                         \nfactor(PSA_ID)124                      ** \nfactor(PSA_ID)141                         \nfactor(PSA_ID)142                      ** \nfactor(PSA_ID)143                      ***\nfactor(PSA_ID)144                         \nfactor(PSA_ID)151                      ** \nfactor(PSA_ID)152                      ***\nfactor(PSA_ID)153                      ***\nfactor(PSA_ID)161                         \nfactor(PSA_ID)162                         \nfactor(PSA_ID)171                      ** \nfactor(PSA_ID)172                      ***\nfactor(PSA_ID)173                      ***\nfactor(PSA_ID)181                      *  \nfactor(PSA_ID)182                         \nfactor(PSA_ID)183                      ** \nfactor(PSA_ID)191                      ***\nfactor(PSA_ID)192                         \nfactor(PSA_ID)193                      ***\nfactor(PSA_ID)221                      ***\nfactor(PSA_ID)222                         \nfactor(PSA_ID)223                      ***\nfactor(PSA_ID)224                      *  \nfactor(PSA_ID)241                      .  \nfactor(PSA_ID)242                      ***\nfactor(PSA_ID)243                         \nfactor(PSA_ID)251                      ** \nfactor(PSA_ID)252                      ***\nfactor(PSA_ID)253                      ***\nfactor(PSA_ID)254                         \nfactor(PSA_ID)261                      ** \nfactor(PSA_ID)262                      ** \nfactor(PSA_ID)263                      .  \nfactor(PSA_ID)351                         \nfactor(PSA_ID)352                         \nfactor(PSA_ID)353                         \nfactor(PSA_ID)391                         \nfactor(PSA_ID)392                      ** \nfactor(PSA_ID)393                      ** \nLog_Ridership:is_weekend_factorWeekend *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(4.731) family taken to be 1)\n\n    Null deviance: 30304  on 11065  degrees of freedom\nResidual deviance: 11532  on 10989  degrees of freedom\nAIC: 83893\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  4.7310 \n          Std. Err.:  0.0792 \n\n 2 x log-likelihood:  -83736.6850 \n```\n\n\n:::\n:::\n\n\n-   In this robust specification, we introduce **Police Service Area\n    (PSA)** fixed effects to control for unobserved spatial\n    heterogeneity. Unlike census tracts, PSAs are directly relevant to\n    law enforcement strategy, allowing the model to account for\n    differences in patrolling intensity and reporting practices across\n    different police districts. This approach not only improves model\n    fit but also resolves potential overfitting issues associated with\n    smaller spatial units.\n\n## 4.5 Crime Temporal Lag\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_5 <- glm.nb(Crime_Total_Count ~ \n                    Log_Ridership * is_weekend_factor + \n                    log(Alcohol_Count + 1) +       \n                    poly(Light_Count, 2) +        \n                    Avg_Poverty +        \n                    Avg_Vacancy + I(Avg_Vacancy^2) +        \n                    Avg_Income + I(Avg_Income^2)  +\n                    Avg_Unemployment +\n                    Dist_Police +       \n                    factor(PSA_ID) + \n                    log(Crime_Daily_Rate_lag + 0.001) +\n                    offset(log(Exposure_Days)), \n                  data = final_data,\n                  control = glm.control(maxit = 100))\nsummary(model_5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n    log(Alcohol_Count + 1) + poly(Light_Count, 2) + Avg_Poverty + \n    Avg_Vacancy + I(Avg_Vacancy^2) + Avg_Income + I(Avg_Income^2) + \n    Avg_Unemployment + Dist_Police + factor(PSA_ID) + log(Crime_Daily_Rate_lag + \n    0.001) + offset(log(Exposure_Days)), data = final_data, control = glm.control(maxit = 100), \n    init.theta = 13.48398402, link = log)\n\nCoefficients:\n                                         Estimate Std. Error z value Pr(>|z|)\n(Intercept)                             2.557e-01  7.508e-02   3.405 0.000661\nLog_Ridership                           3.097e-02  3.559e-03   8.701  < 2e-16\nis_weekend_factorWeekend                7.513e-03  1.983e-02   0.379 0.704750\nlog(Alcohol_Count + 1)                  6.111e-02  5.773e-03  10.587  < 2e-16\npoly(Light_Count, 2)1                   3.775e+00  8.603e-01   4.388 1.14e-05\npoly(Light_Count, 2)2                  -8.197e-01  4.967e-01  -1.650 0.098911\nAvg_Poverty                             1.727e-01  9.536e-02   1.811 0.070160\nAvg_Vacancy                            -8.960e-03  2.840e-03  -3.155 0.001604\nI(Avg_Vacancy^2)                        2.615e-04  6.921e-05   3.779 0.000158\nAvg_Income                             -8.633e-06  1.166e-06  -7.405 1.31e-13\nI(Avg_Income^2)                         4.994e-11  6.027e-12   8.286  < 2e-16\nAvg_Unemployment                       -1.039e-02  1.539e-03  -6.750 1.48e-11\nDist_Police                            -9.557e-02  1.108e-02  -8.629  < 2e-16\nfactor(PSA_ID)012                      -1.441e-01  5.067e-02  -2.844 0.004459\nfactor(PSA_ID)021                       1.421e-01  3.993e-02   3.558 0.000373\nfactor(PSA_ID)022                       6.487e-02  4.244e-02   1.529 0.126353\nfactor(PSA_ID)023                       5.092e-02  3.636e-02   1.400 0.161366\nfactor(PSA_ID)031                      -2.420e-02  3.758e-02  -0.644 0.519537\nfactor(PSA_ID)032                       3.348e-02  3.519e-02   0.951 0.341369\nfactor(PSA_ID)033                      -7.734e-02  3.133e-02  -2.469 0.013559\nfactor(PSA_ID)051                       5.406e-02  4.560e-02   1.186 0.235803\nfactor(PSA_ID)052                      -1.807e-01  5.194e-02  -3.479 0.000504\nfactor(PSA_ID)053                      -3.275e-01  6.822e-02  -4.801 1.58e-06\nfactor(PSA_ID)071                       2.336e-01  4.844e-02   4.822 1.42e-06\nfactor(PSA_ID)072                      -2.252e-01  4.649e-02  -4.845 1.27e-06\nfactor(PSA_ID)073                      -1.690e-01  4.871e-02  -3.469 0.000521\nfactor(PSA_ID)081                       1.977e-01  4.246e-02   4.655 3.23e-06\nfactor(PSA_ID)082                      -2.421e-01  4.216e-02  -5.742 9.34e-09\nfactor(PSA_ID)083                      -9.608e-02  4.610e-02  -2.084 0.037172\nfactor(PSA_ID)091                      -1.083e-01  3.486e-02  -3.108 0.001886\nfactor(PSA_ID)092                       8.268e-02  3.771e-02   2.193 0.028343\nfactor(PSA_ID)093                       3.994e-02  3.498e-02   1.142 0.253427\nfactor(PSA_ID)094                       2.249e-01  3.584e-02   6.276 3.47e-10\nfactor(PSA_ID)095                      -1.073e-01  3.890e-02  -2.758 0.005810\nfactor(PSA_ID)121                       4.142e-01  4.334e-02   9.557  < 2e-16\nfactor(PSA_ID)122                      -1.703e-01  7.205e-02  -2.363 0.018121\nfactor(PSA_ID)123                      -1.704e-01  4.189e-02  -4.067 4.75e-05\nfactor(PSA_ID)124                       2.026e-01  5.139e-02   3.943 8.05e-05\nfactor(PSA_ID)141                      -1.294e-01  3.887e-02  -3.330 0.000868\nfactor(PSA_ID)142                      -1.265e-01  4.355e-02  -2.905 0.003670\nfactor(PSA_ID)143                      -1.477e-03  4.006e-02  -0.037 0.970583\nfactor(PSA_ID)144                      -8.455e-02  4.711e-02  -1.795 0.072659\nfactor(PSA_ID)151                       1.626e-02  3.617e-02   0.450 0.652963\nfactor(PSA_ID)152                       1.268e-01  3.589e-02   3.532 0.000412\nfactor(PSA_ID)153                       2.305e-01  3.677e-02   6.269 3.62e-10\nfactor(PSA_ID)161                       1.339e-01  3.881e-02   3.449 0.000562\nfactor(PSA_ID)162                       1.178e-01  4.045e-02   2.913 0.003581\nfactor(PSA_ID)171                      -6.720e-02  3.659e-02  -1.836 0.066302\nfactor(PSA_ID)172                      -4.248e-01  4.869e-02  -8.724  < 2e-16\nfactor(PSA_ID)173                      -2.044e-01  3.989e-02  -5.124 2.99e-07\nfactor(PSA_ID)181                      -1.544e-01  4.483e-02  -3.445 0.000572\nfactor(PSA_ID)182                       1.001e-01  3.898e-02   2.569 0.010197\nfactor(PSA_ID)183                      -8.624e-02  3.617e-02  -2.384 0.017118\nfactor(PSA_ID)191                       2.030e-01  3.696e-02   5.493 3.94e-08\nfactor(PSA_ID)192                       6.114e-02  3.944e-02   1.550 0.121118\nfactor(PSA_ID)193                       2.517e-01  3.986e-02   6.315 2.71e-10\nfactor(PSA_ID)221                       6.874e-02  3.797e-02   1.811 0.070214\nfactor(PSA_ID)222                       7.326e-03  4.428e-02   0.165 0.868600\nfactor(PSA_ID)223                      -6.076e-02  3.978e-02  -1.528 0.126626\nfactor(PSA_ID)224                      -1.448e-01  4.634e-02  -3.124 0.001781\nfactor(PSA_ID)241                      -4.814e-02  4.310e-02  -1.117 0.264063\nfactor(PSA_ID)242                      -7.662e-03  4.520e-02  -0.169 0.865409\nfactor(PSA_ID)243                       1.327e-01  4.562e-02   2.908 0.003640\nfactor(PSA_ID)251                       1.919e-01  4.508e-02   4.256 2.08e-05\nfactor(PSA_ID)252                      -4.972e-02  4.469e-02  -1.113 0.265880\nfactor(PSA_ID)253                      -2.549e-01  4.660e-02  -5.469 4.52e-08\nfactor(PSA_ID)254                       4.112e-02  4.372e-02   0.941 0.346951\nfactor(PSA_ID)261                      -7.614e-02  4.393e-02  -1.733 0.083059\nfactor(PSA_ID)262                       5.008e-02  3.908e-02   1.282 0.199990\nfactor(PSA_ID)263                      -6.978e-02  3.389e-02  -2.059 0.039467\nfactor(PSA_ID)351                      -9.185e-02  3.527e-02  -2.604 0.009201\nfactor(PSA_ID)352                       7.575e-02  3.668e-02   2.065 0.038890\nfactor(PSA_ID)353                      -1.149e-01  3.954e-02  -2.905 0.003667\nfactor(PSA_ID)391                      -8.094e-02  3.676e-02  -2.202 0.027682\nfactor(PSA_ID)392                      -7.300e-02  3.878e-02  -1.883 0.059766\nfactor(PSA_ID)393                       4.386e-02  4.647e-02   0.944 0.345290\nlog(Crime_Daily_Rate_lag + 0.001)       7.084e-01  6.903e-03 102.622  < 2e-16\nLog_Ridership:is_weekend_factorWeekend -8.622e-03  5.060e-03  -1.704 0.088411\n                                          \n(Intercept)                            ***\nLog_Ridership                          ***\nis_weekend_factorWeekend                  \nlog(Alcohol_Count + 1)                 ***\npoly(Light_Count, 2)1                  ***\npoly(Light_Count, 2)2                  .  \nAvg_Poverty                            .  \nAvg_Vacancy                            ** \nI(Avg_Vacancy^2)                       ***\nAvg_Income                             ***\nI(Avg_Income^2)                        ***\nAvg_Unemployment                       ***\nDist_Police                            ***\nfactor(PSA_ID)012                      ** \nfactor(PSA_ID)021                      ***\nfactor(PSA_ID)022                         \nfactor(PSA_ID)023                         \nfactor(PSA_ID)031                         \nfactor(PSA_ID)032                         \nfactor(PSA_ID)033                      *  \nfactor(PSA_ID)051                         \nfactor(PSA_ID)052                      ***\nfactor(PSA_ID)053                      ***\nfactor(PSA_ID)071                      ***\nfactor(PSA_ID)072                      ***\nfactor(PSA_ID)073                      ***\nfactor(PSA_ID)081                      ***\nfactor(PSA_ID)082                      ***\nfactor(PSA_ID)083                      *  \nfactor(PSA_ID)091                      ** \nfactor(PSA_ID)092                      *  \nfactor(PSA_ID)093                         \nfactor(PSA_ID)094                      ***\nfactor(PSA_ID)095                      ** \nfactor(PSA_ID)121                      ***\nfactor(PSA_ID)122                      *  \nfactor(PSA_ID)123                      ***\nfactor(PSA_ID)124                      ***\nfactor(PSA_ID)141                      ***\nfactor(PSA_ID)142                      ** \nfactor(PSA_ID)143                         \nfactor(PSA_ID)144                      .  \nfactor(PSA_ID)151                         \nfactor(PSA_ID)152                      ***\nfactor(PSA_ID)153                      ***\nfactor(PSA_ID)161                      ***\nfactor(PSA_ID)162                      ** \nfactor(PSA_ID)171                      .  \nfactor(PSA_ID)172                      ***\nfactor(PSA_ID)173                      ***\nfactor(PSA_ID)181                      ***\nfactor(PSA_ID)182                      *  \nfactor(PSA_ID)183                      *  \nfactor(PSA_ID)191                      ***\nfactor(PSA_ID)192                         \nfactor(PSA_ID)193                      ***\nfactor(PSA_ID)221                      .  \nfactor(PSA_ID)222                         \nfactor(PSA_ID)223                         \nfactor(PSA_ID)224                      ** \nfactor(PSA_ID)241                         \nfactor(PSA_ID)242                         \nfactor(PSA_ID)243                      ** \nfactor(PSA_ID)251                      ***\nfactor(PSA_ID)252                         \nfactor(PSA_ID)253                      ***\nfactor(PSA_ID)254                         \nfactor(PSA_ID)261                      .  \nfactor(PSA_ID)262                         \nfactor(PSA_ID)263                      *  \nfactor(PSA_ID)351                      ** \nfactor(PSA_ID)352                      *  \nfactor(PSA_ID)353                      ** \nfactor(PSA_ID)391                      *  \nfactor(PSA_ID)392                      .  \nfactor(PSA_ID)393                         \nlog(Crime_Daily_Rate_lag + 0.001)      ***\nLog_Ridership:is_weekend_factorWeekend .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(13.484) family taken to be 1)\n\n    Null deviance: 64740  on 11065  degrees of freedom\nResidual deviance: 11871  on 10988  degrees of freedom\nAIC: 76243\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  13.484 \n          Std. Err.:  0.307 \n\n 2 x log-likelihood:  -76085.254 \n```\n\n\n:::\n:::\n\n\n-   The last model incorporates a temporal lag (Log_Crime_Rate_lag),\n    accounting for the historical \"stickiness\" of crime hotspots. By\n    controlling for **past crime** alongside spatial fixed effects, this\n    model offers the most rigorous test, correcting for both spatial\n    dependence and serial correlation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(model_5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                         GVIF Df GVIF^(1/(2*Df))\nLog_Ridership                        2.140750  1        1.463130\nis_weekend_factor                    8.319162  1        2.884296\nlog(Alcohol_Count + 1)               3.845278  1        1.960938\npoly(Light_Count, 2)                11.981538  2        1.860493\nAvg_Poverty                          9.159654  1        3.026492\nAvg_Vacancy                         23.286389  1        4.825597\nI(Avg_Vacancy^2)                    14.466404  1        3.803473\nAvg_Income                          98.553277  1        9.927400\nI(Avg_Income^2)                     63.899807  1        7.993735\nAvg_Unemployment                     3.897398  1        1.974183\nDist_Police                          2.828785  1        1.681899\nfactor(PSA_ID)                    2368.120093 63        1.063606\nlog(Crime_Daily_Rate_lag + 0.001)    2.737960  1        1.654678\nLog_Ridership:is_weekend_factor      8.153167  1        2.855375\n```\n\n\n:::\n:::\n\n\n-   A diagnostic check for multicollinearity in Model 5 revealed\n    significant redundancy among the socioeconomic variables.\n    Specifically, Median Income (`Avg_Income`) exhibited an extremely\n    high Generalized VIF score of 9.92, indicating strong collinearity\n    with Poverty Rate (`Avg_Poverty`). Including both variables\n    introduces noise and destabilizes coefficient estimates, as they\n    essentially measure the same underlying concept of economic\n    disadvantage.\\\n-   Consequently, in the transition to Model 6 (Refined Model), we\n    removed `Avg_Income` and its quadratic term, retaining `Avg_Poverty`\n    as the primary proxy for socioeconomic status due to its stronger\n    theoretical link to crime risk in urban literature. Additionally, we\n    simplified the Street Lights variable from a polynomial to a linear\n    term (`Light_Count`). Given that the model includes robust spatial\n    fixed effects (`PSA_ID`), the complex non-linear variation is\n    already largely absorbed by the spatial controls, making a linear\n    specification for infrastructure more parsimonious and\n    interpretable.\n\n## 4.6 Refine Model 5 and Create Final Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_6 <- glm.nb(Crime_Total_Count ~ \n                             Log_Ridership * is_weekend_factor + \n                             log(Alcohol_Count + 1) +\n                             Light_Count +\n                             Avg_Poverty +   \n                             Avg_Vacancy + I(Avg_Vacancy^2) + \n                             Avg_Unemployment +\n                             Dist_Police +\n                             factor(PSA_ID) + \n                             log(Crime_Daily_Rate_lag + 0.001) +\n                             offset(log(Exposure_Days)), \n                           data = final_data,\n                           control = glm.control(maxit = 100))\n\nsummary(model_6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n    log(Alcohol_Count + 1) + Light_Count + Avg_Poverty + Avg_Vacancy + \n    I(Avg_Vacancy^2) + Avg_Unemployment + Dist_Police + factor(PSA_ID) + \n    log(Crime_Daily_Rate_lag + 0.001) + offset(log(Exposure_Days)), \n    data = final_data, control = glm.control(maxit = 100), init.theta = 13.34075513, \n    link = log)\n\nCoefficients:\n                                         Estimate Std. Error z value Pr(>|z|)\n(Intercept)                            -1.939e-01  4.323e-02  -4.485 7.30e-06\nLog_Ridership                           3.134e-02  3.564e-03   8.793  < 2e-16\nis_weekend_factorWeekend                8.872e-03  1.987e-02   0.447 0.655203\nlog(Alcohol_Count + 1)                  6.276e-02  5.758e-03  10.899  < 2e-16\nLight_Count                             1.154e-04  3.655e-05   3.158 0.001590\nAvg_Poverty                             3.399e-01  7.377e-02   4.607 4.08e-06\nAvg_Vacancy                            -6.985e-03  2.840e-03  -2.460 0.013899\nI(Avg_Vacancy^2)                        2.459e-04  6.941e-05   3.543 0.000396\nAvg_Unemployment                       -9.685e-03  1.477e-03  -6.555 5.55e-11\nDist_Police                            -9.825e-02  1.095e-02  -8.971  < 2e-16\nfactor(PSA_ID)012                      -1.422e-01  5.058e-02  -2.811 0.004946\nfactor(PSA_ID)021                       1.509e-01  3.998e-02   3.773 0.000161\nfactor(PSA_ID)022                       1.014e-01  4.228e-02   2.399 0.016438\nfactor(PSA_ID)023                       6.396e-02  3.636e-02   1.759 0.078605\nfactor(PSA_ID)031                       2.073e-02  3.584e-02   0.578 0.563028\nfactor(PSA_ID)032                       5.317e-02  3.469e-02   1.533 0.125309\nfactor(PSA_ID)033                      -8.258e-02  3.112e-02  -2.654 0.007952\nfactor(PSA_ID)051                       6.217e-02  4.519e-02   1.376 0.168953\nfactor(PSA_ID)052                      -1.710e-01  5.178e-02  -3.302 0.000961\nfactor(PSA_ID)053                      -3.309e-01  6.830e-02  -4.845 1.27e-06\nfactor(PSA_ID)071                       2.547e-01  4.842e-02   5.259 1.45e-07\nfactor(PSA_ID)072                      -2.214e-01  4.646e-02  -4.764 1.89e-06\nfactor(PSA_ID)073                      -1.700e-01  4.882e-02  -3.482 0.000498\nfactor(PSA_ID)081                       2.072e-01  4.248e-02   4.877 1.08e-06\nfactor(PSA_ID)082                      -2.493e-01  4.219e-02  -5.909 3.45e-09\nfactor(PSA_ID)083                      -1.196e-01  4.575e-02  -2.615 0.008924\nfactor(PSA_ID)091                      -9.835e-02  3.360e-02  -2.927 0.003423\nfactor(PSA_ID)092                       1.325e-01  3.576e-02   3.705 0.000212\nfactor(PSA_ID)093                       3.605e-02  3.468e-02   1.040 0.298572\nfactor(PSA_ID)094                       2.110e-01  3.357e-02   6.287 3.25e-10\nfactor(PSA_ID)095                      -3.208e-02  3.647e-02  -0.880 0.379119\nfactor(PSA_ID)121                       4.456e-01  4.336e-02  10.275  < 2e-16\nfactor(PSA_ID)122                      -1.271e-01  7.201e-02  -1.765 0.077630\nfactor(PSA_ID)123                      -1.146e-01  4.141e-02  -2.767 0.005659\nfactor(PSA_ID)124                       2.308e-01  5.113e-02   4.515 6.34e-06\nfactor(PSA_ID)141                      -1.059e-01  3.856e-02  -2.747 0.006022\nfactor(PSA_ID)142                      -8.819e-02  4.343e-02  -2.030 0.042325\nfactor(PSA_ID)143                       2.082e-02  4.008e-02   0.519 0.603501\nfactor(PSA_ID)144                      -5.119e-02  4.695e-02  -1.090 0.275505\nfactor(PSA_ID)151                       4.567e-02  3.592e-02   1.271 0.203590\nfactor(PSA_ID)152                       1.576e-01  3.578e-02   4.404 1.06e-05\nfactor(PSA_ID)153                       2.389e-01  3.681e-02   6.490 8.58e-11\nfactor(PSA_ID)161                       1.985e-01  3.806e-02   5.215 1.84e-07\nfactor(PSA_ID)162                       1.781e-01  3.975e-02   4.480 7.48e-06\nfactor(PSA_ID)171                      -4.983e-02  3.509e-02  -1.420 0.155534\nfactor(PSA_ID)172                      -4.390e-01  4.839e-02  -9.073  < 2e-16\nfactor(PSA_ID)173                      -2.201e-01  3.978e-02  -5.533 3.15e-08\nfactor(PSA_ID)181                      -9.756e-02  4.423e-02  -2.206 0.027403\nfactor(PSA_ID)182                       1.344e-01  3.864e-02   3.479 0.000503\nfactor(PSA_ID)183                      -4.389e-02  3.495e-02  -1.256 0.209178\nfactor(PSA_ID)191                       1.931e-01  3.687e-02   5.237 1.63e-07\nfactor(PSA_ID)192                       1.307e-01  3.848e-02   3.396 0.000684\nfactor(PSA_ID)193                       2.633e-01  3.985e-02   6.608 3.88e-11\nfactor(PSA_ID)221                       1.218e-01  3.758e-02   3.242 0.001189\nfactor(PSA_ID)222                       7.118e-02  4.376e-02   1.627 0.103789\nfactor(PSA_ID)223                      -1.989e-02  3.955e-02  -0.503 0.615088\nfactor(PSA_ID)224                      -1.497e-01  4.627e-02  -3.235 0.001215\nfactor(PSA_ID)241                       1.896e-03  4.282e-02   0.044 0.964684\nfactor(PSA_ID)242                       4.314e-02  4.490e-02   0.961 0.336712\nfactor(PSA_ID)243                       1.449e-01  4.519e-02   3.206 0.001345\nfactor(PSA_ID)251                       2.562e-01  4.454e-02   5.752 8.84e-09\nfactor(PSA_ID)252                       8.936e-03  4.432e-02   0.202 0.840212\nfactor(PSA_ID)253                      -1.611e-01  4.549e-02  -3.540 0.000399\nfactor(PSA_ID)254                       1.288e-01  4.258e-02   3.024 0.002497\nfactor(PSA_ID)261                      -2.606e-02  4.353e-02  -0.599 0.549301\nfactor(PSA_ID)262                       6.579e-02  3.819e-02   1.723 0.084969\nfactor(PSA_ID)263                      -4.964e-02  3.330e-02  -1.491 0.135995\nfactor(PSA_ID)351                      -7.299e-02  3.527e-02  -2.070 0.038487\nfactor(PSA_ID)352                       1.256e-01  3.624e-02   3.466 0.000528\nfactor(PSA_ID)353                      -5.349e-02  3.886e-02  -1.377 0.168638\nfactor(PSA_ID)391                      -4.033e-02  3.657e-02  -1.103 0.270083\nfactor(PSA_ID)392                      -1.015e-02  3.821e-02  -0.266 0.790478\nfactor(PSA_ID)393                       1.247e-01  4.552e-02   2.739 0.006163\nlog(Crime_Daily_Rate_lag + 0.001)       7.118e-01  6.898e-03 103.194  < 2e-16\nLog_Ridership:is_weekend_factorWeekend -8.741e-03  5.073e-03  -1.723 0.084891\n                                          \n(Intercept)                            ***\nLog_Ridership                          ***\nis_weekend_factorWeekend                  \nlog(Alcohol_Count + 1)                 ***\nLight_Count                            ** \nAvg_Poverty                            ***\nAvg_Vacancy                            *  \nI(Avg_Vacancy^2)                       ***\nAvg_Unemployment                       ***\nDist_Police                            ***\nfactor(PSA_ID)012                      ** \nfactor(PSA_ID)021                      ***\nfactor(PSA_ID)022                      *  \nfactor(PSA_ID)023                      .  \nfactor(PSA_ID)031                         \nfactor(PSA_ID)032                         \nfactor(PSA_ID)033                      ** \nfactor(PSA_ID)051                         \nfactor(PSA_ID)052                      ***\nfactor(PSA_ID)053                      ***\nfactor(PSA_ID)071                      ***\nfactor(PSA_ID)072                      ***\nfactor(PSA_ID)073                      ***\nfactor(PSA_ID)081                      ***\nfactor(PSA_ID)082                      ***\nfactor(PSA_ID)083                      ** \nfactor(PSA_ID)091                      ** \nfactor(PSA_ID)092                      ***\nfactor(PSA_ID)093                         \nfactor(PSA_ID)094                      ***\nfactor(PSA_ID)095                         \nfactor(PSA_ID)121                      ***\nfactor(PSA_ID)122                      .  \nfactor(PSA_ID)123                      ** \nfactor(PSA_ID)124                      ***\nfactor(PSA_ID)141                      ** \nfactor(PSA_ID)142                      *  \nfactor(PSA_ID)143                         \nfactor(PSA_ID)144                         \nfactor(PSA_ID)151                         \nfactor(PSA_ID)152                      ***\nfactor(PSA_ID)153                      ***\nfactor(PSA_ID)161                      ***\nfactor(PSA_ID)162                      ***\nfactor(PSA_ID)171                         \nfactor(PSA_ID)172                      ***\nfactor(PSA_ID)173                      ***\nfactor(PSA_ID)181                      *  \nfactor(PSA_ID)182                      ***\nfactor(PSA_ID)183                         \nfactor(PSA_ID)191                      ***\nfactor(PSA_ID)192                      ***\nfactor(PSA_ID)193                      ***\nfactor(PSA_ID)221                      ** \nfactor(PSA_ID)222                         \nfactor(PSA_ID)223                         \nfactor(PSA_ID)224                      ** \nfactor(PSA_ID)241                         \nfactor(PSA_ID)242                         \nfactor(PSA_ID)243                      ** \nfactor(PSA_ID)251                      ***\nfactor(PSA_ID)252                         \nfactor(PSA_ID)253                      ***\nfactor(PSA_ID)254                      ** \nfactor(PSA_ID)261                         \nfactor(PSA_ID)262                      .  \nfactor(PSA_ID)263                         \nfactor(PSA_ID)351                      *  \nfactor(PSA_ID)352                      ***\nfactor(PSA_ID)353                         \nfactor(PSA_ID)391                         \nfactor(PSA_ID)392                         \nfactor(PSA_ID)393                      ** \nlog(Crime_Daily_Rate_lag + 0.001)      ***\nLog_Ridership:is_weekend_factorWeekend .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(13.3408) family taken to be 1)\n\n    Null deviance: 64299  on 11065  degrees of freedom\nResidual deviance: 11874  on 10991  degrees of freedom\nAIC: 76310\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  13.341 \n          Std. Err.:  0.303 \n\n 2 x log-likelihood:  -76157.840 \n```\n\n\n:::\n\n```{.r .cell-code}\nvif(model_6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                        GVIF Df GVIF^(1/(2*Df))\nLog_Ridership                       2.133246  1        1.460563\nis_weekend_factor                   8.301509  1        2.881234\nlog(Alcohol_Count + 1)              3.798142  1        1.948882\nLight_Count                         5.541211  1        2.353978\nAvg_Poverty                         5.428573  1        2.329930\nAvg_Vacancy                        23.126903  1        4.809044\nI(Avg_Vacancy^2)                   14.459269  1        3.802535\nAvg_Unemployment                    3.561355  1        1.887155\nDist_Police                         2.751623  1        1.658802\nfactor(PSA_ID)                    467.133380 63        1.049992\nlog(Crime_Daily_Rate_lag + 0.001)   2.717994  1        1.648634\nLog_Ridership:is_weekend_factor     8.139565  1        2.852992\n```\n\n\n:::\n:::\n\n\n-   After removing the conflicting income variables, Model 6 is now\n    statistically healthy. Most importantly, our core variable,\n    `Log_Ridership`, has a very low GVIF score of 2.13. This is well\n    below the concern threshold (usually 5 or 10), which proves that our\n    main finding that ridership drives crime, is reliable and not\n    distorted by other factors.\\\n-   High scores for Vacancy and the Interaction term are mathematically\n    expected when we use squared terms (like Vacancy\\^2) or\n    interactions. They do not negatively affect the model's ability to\n    predict crime.\n\n## 4.7 Model Comparison Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(modelsummary)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# 1. Modify Coef Map\ncoef_map_refined <- c(\n  \"Log_Ridership\" = \"Ridership (Log)\",\n  \"is_weekend_factorWeekend\" = \"Weekend Effect\",\n  \n  \"Log_Ridership:is_weekend_factorWeekend\" = \"Interaction: Ridership × Weekend\",\n  \"is_weekend_factorWeekend:Log_Ridership\" = \"Interaction: Ridership × Weekend\", \n  \n  \"log(Alcohol_Count + 1)\" = \"Alcohol Outlets\", \n  \"Light_Count\" = \"Street Lights (Linear)\",   \n  \"Avg_Poverty\" = \"Poverty Rate\",             \n  \"Avg_Vacancy\" = \"Vacancy Rate\",\n  \"I(Avg_Vacancy^2)\" = \"Vacancy Rate (Sq)\",\n  \"Avg_Unemployment\" = \"Unemployment Rate\",\n  \"Dist_Police\" = \"Dist to Police Station\",\n  \"log(Crime_Daily_Rate_lag + 0.001)\" = \"Temporal Lag (Prev. Q)\"\n)\n\n# 2. Mapping\np_comparison <- modelplot(\n  list(\n    \"M1: Ridership\" = model_1, \n    \"M2: +Interact\" = model_2,\n    \"M3: +Env/Demo\" = model_3,\n    \"M4: +PSA Fixed\" = model_4, \n    \"M5: +Lag\" = model_5,\n    \"M6: Final\" = model_6 \n  ),\n  coef_map = coef_map_refined, \n\n  coef_omit = \"Intercept\", \n  \n  conf_level = 0.95,\n  size = 0.8 \n) +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Model Evolution: Stability of Key Drivers\",\n    subtitle = \"Comparing coefficients across model iterations (M1-M6)\",\n    x = \"Effect Size (Coefficient Estimate)\",\n    y = \"\",\n    caption = \"Note: To facilitate direct comparison, this plot displays only the variables selected for the Final Refined Model (M6).\"\n  ) +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Dark2\") + \n  theme(\n    legend.position = \"bottom\",\n    plot.title = element_text(face = \"bold\", size = 14),\n    axis.text.y = element_text(size = 10, face = \"bold\", color = \"black\"),\n    panel.grid.minor = element_blank()\n  )\n\np_comparison\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n-   This plot visualizes our journey from a naive baseline to a robust\n    final model. When reading this chart:\n\n    -   **Distance from Red Line:** The further the dot is to the right,\n        the stronger the positive impact on crime.\\\n    -   **Length of the Line:** This represents the Confidence Interval.\n        A longer line means higher uncertainty, often caused by\n        multicollinearity.\n\n-   **Model 1(Ridership Only):** Without controlling for any other\n    factors, ridership appears to be a massive driver of crime. However,\n    this estimate is likely **inflated (biased)** because high-ridership\n    stops are often located in dense, low-income areas. The model is\n    mistakenly attributing the neighborhood effect solely to ridership.\n\n-   **Model 2(+Interaction):** We introduce the Weekend Effect and the\n    interaction term. The main Ridership coefficient increases slightly.\n    This confirms that the relationship isn't identical across the week.\n    By separating weekends, we begin to see that the \"baseline risk\"\n    shifts, validating the need for a pseudo-panel approach, though the\n    core finding (ridership = risk) remains consistent due to its\n    positive coefficient.\n\n-   **Model 3(+Env & Demo):** A dramatic shift occurs. The **Poverty\n    Rate coefficient** appears and is extremely high (purple dot far to\n    the right), while the **Ridership coefficient drops significantly**\n    (moving left). This is the \"Reality Check.\" Once we account for\n    poverty, we realize that socioeconomic status is the primary driver\n    of crime, not just the bus stop itself. Ridership is still a\n    significant risk factor (the coefficient is still positive), but its\n    impact is much smaller than Model 1 suggested.\n\n-   **Model 4(+PSA Fixed Effects):** The Poverty Rate coefficient\n    shrinks (moves left, pink dot) compared to Model 3. By adding PSA\n    (Police Service Area) fixed effects, we control for unobserved\n    neighborhood characteristics (like local culture or police\n    presence). The model **no longer relies solely on \"Poverty\"** to\n    explain crime clusters, making the estimates for specific variables\n    like Alcohol Outlets and Ridership more precise and trustworthy.\n\n-   **Model 5(+Lag):** The Temporal Lag variable appears at the top with\n    a very high positive coefficient. The strongest predictor of future\n    crime is past crime. Adding this variable absorbs a huge amount of\n    variance, creating a very strict test for our other variables.\n\n-   **Model 6(Final Refined):** `Ridership` remains positive and\n    significant (approx 0.1), proving that even after controlling for\n    everything (poverty, history, location), more passengers still equal\n    more targets. `Alcohol` shows a stable positive link.\n    `Dist to Police` shows a negative coefficient (meaning crime is\n    higher closer to stations), but this is probably because there are\n    bias in original dataset where crimes nearby the police stations are\n    more likely to be recorded.\n\n# Phase 5: Model Validation\n\n## 5.1 Compare all 5 models:\n\n### 5.1.1 Create predicted vs. actual plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf1 <- Crime_Total_Count ~ Log_Ridership + offset(log(Exposure_Days))\nf2 <- Crime_Total_Count ~ Log_Ridership * is_weekend_factor + offset(log(Exposure_Days))\nf3 <- Crime_Total_Count ~ Log_Ridership * is_weekend_factor + log(Alcohol_Count + 1) + poly(Light_Count, 2) + Avg_Poverty + Avg_Vacancy + I(Avg_Vacancy^2) + Avg_Income + I(Avg_Income^2) + Avg_Unemployment + Dist_Police + offset(log(Exposure_Days))\n\nf4 <- Crime_Total_Count ~ Log_Ridership * is_weekend_factor + log(Alcohol_Count + 1) + poly(Light_Count, 2) + Avg_Poverty + Avg_Vacancy + I(Avg_Vacancy^2) + Avg_Income + I(Avg_Income^2) + Avg_Unemployment + Dist_Police + factor(PSA_ID) + offset(log(Exposure_Days)) \n\nf5 <- Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n      log(Alcohol_Count + 1) + poly(Light_Count, 2) + \n      Avg_Poverty + Avg_Vacancy + I(Avg_Vacancy^2) + \n      Avg_Income + I(Avg_Income^2) + Avg_Unemployment + \n      Dist_Police + factor(PSA_ID) + \n      log(Crime_Daily_Rate_lag + 0.001) + \n      offset(log(Exposure_Days))\n\nf6 <- Crime_Total_Count ~ Log_Ridership * is_weekend_factor + \n      log(Alcohol_Count + 1) + \n      Light_Count +              \n      Avg_Poverty +              \n      Avg_Vacancy + I(Avg_Vacancy^2) + \n      Avg_Unemployment + \n      Dist_Police + \n      factor(PSA_ID) +         \n      log(Crime_Daily_Rate_lag + 0.001) + \n      offset(log(Exposure_Days))\n\n# 2. Train 6 models\nm1 <- glm.nb(f1, data = final_data)\nm2 <- glm.nb(f2, data = final_data)\nm3 <- glm.nb(f3, data = final_data)\nm4 <- glm.nb(f4, data = final_data)\nm5 <- glm.nb(f5, data = final_data)\nm6 <- glm.nb(f6, data = final_data)\n\n# 3. Gather Predictions\nplot_data <- final_data %>%\n  dplyr::select(Crime_Total_Count) %>%\n  mutate(\n    Model_1_Pred = predict(m1, type = \"response\"),\n    Model_2_Pred = predict(m2, type = \"response\"),\n    Model_3_Pred = predict(m3, type = \"response\"),\n    Model_4_Pred = predict(m4, type = \"response\"),\n    Model_5_Pred = predict(m5, type = \"response\"),\n    Model_6_Pred = predict(m6, type = \"response\"),\n  ) %>%\n  pivot_longer(\n    cols = starts_with(\"Model\"), \n    names_to = \"Model\", \n    values_to = \"Predicted_Count\"\n  )\n\n# 4. Map：Facet Wrap compare 6 models\nggplot(plot_data, aes(x = Predicted_Count, y = Crime_Total_Count)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\", size = 0.8) +\n  \n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  \n  facet_wrap(~Model, ncol = 3) +\n  \n  labs(\n    title = \"Predicted vs. Actual Crime Counts\",\n    subtitle = \"Comparing Model Fit: Final Model (M6) shows robust predictions\",\n    x = \"Predicted Crime Count\",\n    y = \"Actual Crime Count\"\n  ) +\n  theme_bw() +\n  \n  coord_cartesian(xlim = c(0, 50), ylim = c(0, 50))\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n-   This plot also visualizes our journey from a naive baseline to a\n    robust final model.\n\n-   Overall, as more contextual and more spatial information are added,\n    the predicted values align **more closely with the 45° reference\n    line**, indicating improved model fit.\n\n-   Models 1–2 rely mainly on ridership and weekend interaction,\n    resulting in wide dispersion and systematic under-prediction at\n    higher crime levels.\n\n-   Models 3–4 incorporate environmental (alcohol outlets, lighting) and\n    demographic features, producing a noticeably tighter prediction band\n    and capturing more variation across stops.\n\n-   Model 5 adds temporal information (lagged crime rate), which further\n    stabilizes predictions and reduces bias.\n\n-   Compared with Model 5, Model 6 trims several weak or redundant\n    predictors while keeping the key effects. This parsimonious\n    specification makes the model more stable and interpretable and\n    helps reduce potential multicollinearity among highly correlated\n    socioeconomic variables.\n\n### 5.1.2 Report and Compare RMSE, MAE, R²\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\n# 1. Set 5-Fold Cross Validation\nset.seed(999)\nfolds <- createFolds(final_data$Crime_Total_Count, k = 5, list = TRUE)\n\nrun_cv <- function(formula, data, folds) {\n  mae_list <- c()\n  rmse_list <- c()\n  \n  for (i in 1:length(folds)) {\n    # Split Data\n    test_idx <- folds[[i]]\n    train_set <- data[-test_idx, ]\n    test_set  <- data[test_idx, ]\n    \n    # Train Model\n    model <- tryCatch({\n      glm.nb(formula, data = train_set)\n    }, error = function(e) return(NULL))\n    \n    if(!is.null(model)) {\n      preds <- predict(model, newdata = test_set, type = \"response\")\n      \n      # Calculate Errors\n      actuals <- test_set$Crime_Total_Count\n      mae_list <- c(mae_list, mean(abs(actuals - preds)))\n      rmse_list <- c(rmse_list, sqrt(mean((actuals - preds)^2)))\n    }\n  }\n  return(c(mean(mae_list), mean(rmse_list)))\n}\n\n# 2. CV 6 models\nresults_m1 <- run_cv(f1, final_data, folds)\nresults_m2 <- run_cv(f2, final_data, folds)\nresults_m3 <- run_cv(f3, final_data, folds)\nresults_m4 <- run_cv(f4, final_data, folds)\nresults_m5 <- run_cv(f5, final_data, folds)\nresults_m6 <- run_cv(f6, final_data, folds)\n\n# 3. Generate chart\nvalidation_summary <- data.frame(\n  Model = c(\"1. Ridership Only\", \"2. +Interaction\", \"3. +Env & Demo\", \"4. +Spatial Fixed\", \"5. +Temporal lag\", \"6. Refined\"),\n  MAE  = c(results_m1[1], results_m2[1], results_m3[1], results_m4[1], results_m5[1], results_m6[1]),\n  RMSE = c(results_m1[2], results_m2[2], results_m3[2], results_m4[2], results_m5[2], results_m6[2])\n) %>%\n  mutate(\n    Improvement_MAE = (MAE[1] - MAE) / MAE[1]\n  )\n\nkable(validation_summary, digits = 3, caption = \"5-Fold Cross-Validation Metrics\") %>%\n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE) %>%\n  column_spec(4, color = \"green\", bold = TRUE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>5-Fold Cross-Validation Metrics</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE </th>\n   <th style=\"text-align:right;\"> RMSE </th>\n   <th style=\"text-align:right;\"> Improvement_MAE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Ridership Only </td>\n   <td style=\"text-align:right;\"> 17.268 </td>\n   <td style=\"text-align:right;\"> 28.877 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. +Interaction </td>\n   <td style=\"text-align:right;\"> 17.209 </td>\n   <td style=\"text-align:right;\"> 28.868 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. +Env &amp; Demo </td>\n   <td style=\"text-align:right;\"> 12.777 </td>\n   <td style=\"text-align:right;\"> 21.039 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.260 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. +Spatial Fixed </td>\n   <td style=\"text-align:right;\"> 11.409 </td>\n   <td style=\"text-align:right;\"> 18.343 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.339 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. +Temporal lag </td>\n   <td style=\"text-align:right;\"> 7.453 </td>\n   <td style=\"text-align:right;\"> 11.629 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.568 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6. Refined </td>\n   <td style=\"text-align:right;\"> 7.475 </td>\n   <td style=\"text-align:right;\"> 11.662 </td>\n   <td style=\"text-align:right;font-weight: bold;color: green !important;\"> 0.567 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n-   These findings are validated through 5-fold cross-validation, which\n    evaluates each model on unseen data rather than relying solely on\n    in-sample fit. The consistent reduction in MAE and RMSE across folds\n    confirms that the improvements are not artifacts of overfitting but\n    reflect real gains in out-of-sample predictive performance.\n\n-   **Model 1(Ridership Only)**\\\n    The model using only ridership intensity establishes a basic\n    relationship between human activity levels and crime, but its\n    predictive capacity is limited. Ridership alone captures general\n    exposure but cannot explain spatial heterogeneity across stops.\n\n-   **Model 2(+ Interaction)**\\\n    Adding the weekday–weekend interaction improves the model slightly.\n\n-   **Model 3(+ Environment&Demographic)**\\\n    Alcohol outlet density, Lighting conditions poverty, income,\n    vacancy, and unemployment: these variables substantially reduce\n    prediction error, indicating that crime near transit stops is\n    strongly shaped by both environmental risk factors and neighborhood\n    disadvantage.\n\n-   **Model 4(+Spatial Fixed)**\\\n    Introducing police station distance and especially PSA fixed effects\n    further improves performance.\\\n    This suggests that:Crime patterns are partly structured by local\n    policing jurisdictions and there are unobserved spatial factors\n    (culture, enforcement style, land use patterns) that are constant\n    within each PSA.PSA fixed effects absorb these stable spatial\n    characteristics, making the model more robust.\n\n-   **Model 5(Temporal Lag)**\\\n    Including lagged crime rate (previous quarter) yields the largest\n    single improvement. Lagged crime captures temporal persistence—areas\n    that experienced more crime in the past tend to remain active in the\n    present.This is a very strong and stable predictor, dramatically\n    improving accuracy.\n\n-   **Model 6(Refined)**\\\n    Model 6 streamlines the specification by removing weaker or\n    collinear variables.Despite using fewer predictors, its accuracy\n    remains nearly identical to Model 5.\\\n    This indicates that a refined, parsimonious model with reduced\n    multicollinearity can maintain strong predictive performance while\n    improving interpretability and stability.\n\n# Phase 6: Model Diagnostics\n\n### Check assumptions for best model:\n\n## 6.1 Spatial Autocorrelation of Residuals (Moran's I)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_model <- model_6\n\nfinal_data$resid_pearson  <- residuals(best_model, type = \"pearson\")\nfinal_data$resid_deviance <- residuals(best_model, type = \"deviance\")\n\n# Spatial Weights Matrix\ncoords <- st_coordinates(final_data)\nneighbor_nb <- knn2nb(knearneigh(coords, k = 8))\nspatial_weights <- nb2listw(neighbor_nb, style = \"W\")\n\n# Moran's I test\nmoran_result <- moran.test(final_data$resid_pearson, spatial_weights)\n\nprint(moran_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  final_data$resid_pearson  \nweights: spatial_weights    \n\nMoran I statistic standard deviate = 100.73, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     4.518144e-01     -9.037506e-05      2.012726e-05 \n```\n\n\n:::\n:::\n\n\n-   Although we added spatial fixed effect(which is also a way to reduce\n    spatial autocorrelation), the Moran’s I test on the model residuals\n    shows a **strong and highly significant level of spatial\n    autocorrelation** (Moran’s I = 0.452, p \\< 2.2 × 10⁻¹⁶).\\\n    This indicates that the residuals are not randomly distributed\n    across space and that **the model likely fails to capture important\n    spatial dependence structures** in the data.\n\n-   In practical terms, nearby transit stops tend to have\n    **systematically similar over or under predictions**, suggesting the\n    presence of spatially clustered unobserved factors such as local\n    policing practices, neighborhood context, or land-use patterns that\n    are not fully absorbed even after including PSA fixed effects and\n    temporal lag terms.\n\n-   Given the strength of the residual spatial autocorrelation, the\n    results imply that the model could benefit from incorporating\n    explicit spatial components, such as:\n\n    -   spatially lagged variables (SAR, CAR, or SLX terms)\\\n    -   spatial random effects\\\n    -   geographically weighted or spatially varying coefficient\n        structures\\\n\n-   Overall, the Moran’s I result shows that while the model fits well\n    in non-spatial dimensions, unmodeled spatial processes remain\n    significant and should be considered in future extensions.\n\n## 6.2 Spatial Distribution of Residuals\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spatial Distribution of Residuals\nfinal_data$spatial_resid <- residuals(best_model, type = \"deviance\")\n\nggplot() +\n  geom_sf(data = philly_boundary, fill = \"grey95\", color = NA) +\n  \n  geom_sf(data = final_data, \n          aes(color = spatial_resid), \n          size = 0.8, alpha = 0.7) +\n  \n  scale_color_gradient2(\n    low = \"blue\", mid = \"grey90\", high = \"red\",\n    midpoint = 0,\n    name = \"Deviance\\nResidual\",\n    limits = c(-3, 3), \n    oob = scales::squish \n  ) +\n  \n  labs(\n    title = \"Map of Model Residuals\",\n    subtitle = \"Red = Unexpectedly High Crime (Under-predicted)\\nBlue = Unexpectedly Low Crime (Over-predicted)\"\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n-   Red spots (positive deviance residuals):These locations experienced\n    more crime than the model expected.\n\n-   Blue spots (negative deviance residuals):These locations show less\n    crime than predicted.\n\n-   Although the residuals exhibit noticeable spatial clustering, which\n    was confirmed by the significant Moran’s I test, the pattern does\n    not form a clear, interpretable spatial structure.\n\n-   The clusters of over and under prediction **appear scattered across\n    different parts of the city** without aligning with obvious\n    geographic boundaries, transit corridors, or neighborhood divisions.\n\n-   This suggests that while some localized spatial dependence remains\n    in the model, these patterns do not **translate into a single\n    coherent spatial process**.\\\n    In other words, the remaining spatial signal is **weakly structured\n    and heterogeneous**, making it difficult to summarize into a simple\n    spatial rule or trend.\n\n## 6.3 Residual plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_model <- model_6\n\nmodel_data <- data.frame(\n  Fitted = fitted(best_model),\n  Residuals = residuals(best_model, type = \"pearson\")\n)\n\np_resid_fitted <- ggplot(model_data, aes(x = log(Fitted), y = Residuals)) +\n  geom_point(alpha = 0.3, color = \"#6A1B9A\", size = 1.5) + \n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"loess\", color = \"black\", se = FALSE, linewidth = 0.8) +\n  labs(\n    title = \"Residuals vs Fitted Values\",\n    subtitle = \"Checking for systematic bias in the Count Model\",\n    x = \"Log(Fitted Values) - Predicted Crime Count\",\n    y = \"Pearson Residuals\"\n  ) +\n  plotTheme\n\np_resid_fitted\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n-   This plot shows the residuals against the predicted crime counts\n    from the final negative binomial model. Overall, the residuals are\n    **centered around zero without clear curvature or funnel shapes**,\n    suggesting that the model does not suffer from major\n    misspecification or heteroskedasticity.\n\n-   The “striped” patterns come from the **integer nature of crime\n    counts** which is an effect commonly called the **discreteness\n    pattern** in count models. This is not a model problem; it simply\n    reflects that many stations share the same small crime counts ,\n    leading to stacked fitted values. The smooth LOESS line stays close\n    to zero across the range, indicating no strong systematic bias.\n\n-   In short, the residual plot shows that the negative binomial model\n    is behaving as expected for count data, and there is no major\n    evidence of nonlinearity or missing predictors.\n\n## 6.4 Q-Q plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_qq <- ggplot(model_data, aes(sample = Residuals)) +\n  stat_qq(color = \"#6A1B9A\", size = 1.5, alpha = 0.5) +\n  stat_qq_line(color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(\n    title = \"Q-Q Plot of Pearson Residuals\",\n    subtitle = \"Checking for extreme outliers in count data\",\n    x = \"Theoretical Quantiles\",\n    y = \"Sample Quantiles\"\n  ) +\n  plotTheme\n\np_qq\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n-   The Q–Q plot shows that the Pearson residuals follow the theoretical\n    quantiles closely in the middle range, meaning the model captures\n    the main distribution of crime counts well. The deviation at the\n    upper tail indicates a few unusually high-crime stops that the model\n    cannot fully explain—this is common in count data, especially when\n    rare but extreme events occur.\n\n-   Negative Binomial models are designed to handle overdispersion, and\n    the relatively small tail deviation suggests that any remaining\n    overdispersion is limited to a small number of extreme observations\n    rather than a systematic model failure.\n\n-   Overall, the Q–Q plot supports that the model fits the bulk of the\n    data well, with only mild deviations at the extremes. Binomial\n    assumption might still be struggling with extreme overdispersion.\n\n------------------------------------------------------------------------\n\n# Phase 7: Conclusions\n\n## 7.1 The Verdict: \"Targets\" Outweigh \"Eyes on the Street\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(kableExtra)\n\nmodel_final <- model_6 \n\ncoef_name_base <- \"Log_Ridership\"\ncoef_name_interact <- \"Log_Ridership:is_weekend_factorWeekend\"\n\nbeta_base <- coef(model_final)[coef_name_base]        \nbeta_interact <- coef(model_final)[coef_name_interact]\nvcov_matrix <- vcov(model_final)                     \n\n# Calculate real slope in weekends and weekdays\n\n# A. Weekday: Base\nslope_weekday <- beta_base\nse_weekday <- sqrt(vcov_matrix[coef_name_base, coef_name_base])\np_weekday <- 2 * (1 - pnorm(abs(slope_weekday / se_weekday)))\n\n# B. Weekend: Base + Interaction\nslope_weekend <- beta_base + beta_interact\n# Calculate Var: Var(A+B) = Var(A) + Var(B) + 2*Cov(A,B)\nvar_weekend <- vcov_matrix[coef_name_base, coef_name_base] + \n               vcov_matrix[coef_name_interact, coef_name_interact] + \n               2 * vcov_matrix[coef_name_base, coef_name_interact]\nse_weekend <- sqrt(var_weekend)\np_weekend <- 2 * (1 - pnorm(abs(slope_weekend / se_weekend)))\n\nhypothesis_test <- data.frame(\n  Scenario = c(\"Weekday (Commuters)\", \"Weekend (Non-Routine)\"),\n  Impact_Slope = c(slope_weekday, slope_weekend),\n  Std_Error = c(se_weekday, se_weekend),\n  P_Value = c(p_weekday, p_weekend)\n) %>%\n  mutate(\n    Interpretation = case_when(\n      Impact_Slope > 0 & P_Value < 0.05 ~ \"Positive & Significant (Target Hypothesis Supported)\",\n      Impact_Slope < 0 & P_Value < 0.05 ~ \"Negative & Significant (Eyes on Street Supported)\",\n      TRUE ~ \"Not Significant\"\n    ),\n    \n    Impact_Slope = round(Impact_Slope, 3),\n    Std_Error = round(Std_Error, 3),\n    P_Value = ifelse(P_Value < 0.001, \"< 0.001\", round(P_Value, 3))\n  )\n\nkbl(hypothesis_test, caption = \"The Verdict: Does Ridership Drive Crime in Both Contexts?\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"), full_width = F) %>%\n  row_spec(1:2, bold = TRUE, color = \"black\", background = \"#e6f5ff\") %>%\n  footnote(general = \"Slopes > 0 indicate that higher ridership is associated with higher crime counts.\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n<caption>The Verdict: Does Ridership Drive Crime in Both Contexts?</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Scenario </th>\n   <th style=\"text-align:right;\"> Impact_Slope </th>\n   <th style=\"text-align:right;\"> Std_Error </th>\n   <th style=\"text-align:left;\"> P_Value </th>\n   <th style=\"text-align:left;\"> Interpretation </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;color: black !important;background-color: rgba(230, 245, 255, 255) !important;\"> Weekday (Commuters) </td>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: rgba(230, 245, 255, 255) !important;\"> 0.031 </td>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: rgba(230, 245, 255, 255) !important;\"> 0.004 </td>\n   <td style=\"text-align:left;font-weight: bold;color: black !important;background-color: rgba(230, 245, 255, 255) !important;\"> &lt; 0.001 </td>\n   <td style=\"text-align:left;font-weight: bold;color: black !important;background-color: rgba(230, 245, 255, 255) !important;\"> Positive &amp; Significant (Target Hypothesis Supported) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;color: black !important;background-color: rgba(230, 245, 255, 255) !important;\"> Weekend (Non-Routine) </td>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: rgba(230, 245, 255, 255) !important;\"> 0.023 </td>\n   <td style=\"text-align:right;font-weight: bold;color: black !important;background-color: rgba(230, 245, 255, 255) !important;\"> 0.004 </td>\n   <td style=\"text-align:left;font-weight: bold;color: black !important;background-color: rgba(230, 245, 255, 255) !important;\"> &lt; 0.001 </td>\n   <td style=\"text-align:left;font-weight: bold;color: black !important;background-color: rgba(230, 245, 255, 255) !important;\"> Positive &amp; Significant (Target Hypothesis Supported) </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Slopes &gt; 0 indicate that higher ridership is associated with higher crime counts.</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n-   Our analysis provides a definitive answer to the \"Eyes on the\n    Street\" versus \"Targets\" debate within the context of SEPTA bus\n    stops. As illustrated in our final verdict table, ridership exhibits\n    a consistent, positive, and significant correlation with crime\n    counts ($p < 0.001$). Specifically, we observed an impact slope of\n    0.031 for Weekdays (routine commuting) and 0.023 for Weekends\n    (discretionary travel). Crucially, this relationship holds true even\n    after controlling for neighborhood socioeconomic status. This\n    suggests that in Philadelphia, high passenger volume acts primarily\n    as an attractor for opportunistic crime (\"Targets\") rather than a\n    deterrent. Therefore, reliance on passive surveillance by crowds is\n    insufficient; active security measures are required as ridership\n    grows.\n\n## 7.2 Operational Strategy: Precision Policing based on \"Risk Anomalies\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 7.2.1 Top 50 Under-Policed stops\nfinal_data <- final_data %>%\n  mutate(\n    Predicted_Crime = predict(best_model, type = \"response\"),\n    Resid_Raw = Crime_Total_Count - Predicted_Crime\n  )\n\ntop_50_anomalies <- final_data %>%\n  arrange(desc(Resid_Raw)) %>%\n  slice(1:50)\n\nggplot() +\n  geom_sf(data = philly_boundary, fill = \"grey95\", color = \"white\") +\n  geom_sf(data = final_data, color = \"grey80\", size = 0.5, alpha = 0.3) +\n  geom_sf(data = top_50_anomalies, \n          aes(size = Resid_Raw), \n          color = \"steelblue\", \n          alpha = 0.8) +\n\n  scale_size_continuous(name = \"Excess Crimes\\n(Actual - Predicted)\") +\n  \n  labs(\n    title = \"Top 50 Under-policed Stops\",\n    subtitle = \"Locations where actual crime significantly exceeds model predictions.\",\n    caption = \"Blue dots represent stops performing worse than their environment, suggesting there are more police in need.\"\n  ) +\n  mapTheme +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 7.2.2 Top 50 Over-Policed stops\nfinal_data <- final_data %>%\n  mutate(\n    Predicted_Crime = predict(best_model, type = \"response\"),\n    Resid_Raw =  Predicted_Crime - Crime_Total_Count\n  )\n\ntop_50_anomalies <- final_data %>%\n  arrange(desc(Resid_Raw)) %>%\n  slice(1:50)\n\nggplot() +\n  geom_sf(data = philly_boundary, fill = \"grey95\", color = \"white\") +\n  geom_sf(data = final_data, color = \"grey80\", size = 0.5, alpha = 0.3) +\n  geom_sf(data = top_50_anomalies, \n          aes(size = Resid_Raw), \n          color = \"#d73027\", \n          alpha = 0.8) +\n\n  scale_size_continuous(name = \"Excess Crimes\\n(Predicted - Actual)\") +\n  \n  labs(\n    title = \"Top 50 'Over-policed' Stops\",\n    subtitle = \"Locations where actual crime significantly under model predictions.\",\n    caption = \"Red dots represent stations which are statistically risky, but the actual crime counts are actually small. \"\n  ) +\n  mapTheme +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](Final_appendix_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n-   Instead of simply deploying police to the busiest stations (which is\n    inefficient) or the poorest neighborhoods (which reinforces bias),\n    our model offers a \"Precision Policing\" approach based on spatial\n    anomalies. By calculating the residuals—the difference between\n    actual and predicted crime—we spatially distinguished areas of\n    resource saturation from areas of critical need.\n\n-   As shown in our anomaly maps, the \"Over-policed\" stops (Red Dots)\n    are heavily clustered in Center City, indicating that current\n    security measures there are suppressing crime below predicted\n    levels. In sharp contrast, we identified the \"Top 50 Under-policed\n    Stops\" (Blue Dots). These blue anomalies represent locations where\n    actual crime exceeds our model's predictions by up to 90 incidents—a\n    gap that local environmental factors like poverty or lighting cannot\n    explain. We recommend SEPTA Transit Police utilize this \"Hit List\"\n    to reallocate patrol units from the saturated downtown core to these\n    specific outlying hotspots. Focusing resources on these specific\n    anomalies yields the highest marginal return on public safety\n    investment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 7.2.3 Top 10 High-Risk Anomaly Table\n\nlibrary(kableExtra)\n\ntop_10_table <- final_data %>%\n  mutate(\n    Predicted = predict(best_model, type = \"response\"),\n    Residual = Crime_Total_Count - Predicted\n  ) %>%\n  arrange(desc(Residual)) %>%\n  slice(1:10) %>%\n  \n  dplyr::select(\n    \"Bus Stop Name\" = Stop,\n    \"Police District (PSA)\" = PSA_ID,\n    \"Actual Crime\" = Crime_Total_Count,\n    \"Model Predicted\" = Predicted,\n    \"Unexplained Excess\" = Residual\n  )\n\nkbl(top_10_table, digits = 1, caption = \"The 'Hit List': Top 10 Stops with Highest Unexplained Crime Risk\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = F) %>%\n  column_spec(5, bold = TRUE, color = \"white\", background = \"#d73027\") %>%\n \n  footnote(general = \" 'Unexplained Excess' = Actual Crime minus Predicted Crime based on local environment. Positive values indicate specific local security failures.\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n<caption>The 'Hit List': Top 10 Stops with Highest Unexplained Crime Risk</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Bus Stop Name </th>\n   <th style=\"text-align:left;\"> Police District (PSA) </th>\n   <th style=\"text-align:right;\"> Actual Crime </th>\n   <th style=\"text-align:right;\"> Model Predicted </th>\n   <th style=\"text-align:right;\"> Unexplained Excess </th>\n   <th style=\"text-align:left;\"> geometry </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Locust St &amp; 17th St </td>\n   <td style=\"text-align:left;\"> 093 </td>\n   <td style=\"text-align:right;\"> 295 </td>\n   <td style=\"text-align:right;\"> 198.2 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 96.8 </td>\n   <td style=\"text-align:left;\"> POINT (2691904 234766) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Whitby Av &amp; 53rd St </td>\n   <td style=\"text-align:left;\"> 124 </td>\n   <td style=\"text-align:right;\"> 138 </td>\n   <td style=\"text-align:right;\"> 52.3 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 85.7 </td>\n   <td style=\"text-align:left;\"> POINT (2675321 233206.7) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 17th St &amp; Locust St </td>\n   <td style=\"text-align:left;\"> 093 </td>\n   <td style=\"text-align:right;\"> 276 </td>\n   <td style=\"text-align:right;\"> 190.9 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 85.1 </td>\n   <td style=\"text-align:left;\"> POINT (2691903 234716.1) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 54th St &amp; Willows Av </td>\n   <td style=\"text-align:left;\"> 124 </td>\n   <td style=\"text-align:right;\"> 142 </td>\n   <td style=\"text-align:right;\"> 58.2 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 83.8 </td>\n   <td style=\"text-align:left;\"> POINT (2675499 232607.7) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 52nd St &amp; Jefferson St </td>\n   <td style=\"text-align:left;\"> 193 </td>\n   <td style=\"text-align:right;\"> 176 </td>\n   <td style=\"text-align:right;\"> 94.5 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 81.5 </td>\n   <td style=\"text-align:left;\"> POINT (2675925 245535.5) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 54th St &amp; Whitby Av - FS </td>\n   <td style=\"text-align:left;\"> 124 </td>\n   <td style=\"text-align:right;\"> 136 </td>\n   <td style=\"text-align:right;\"> 55.4 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 80.6 </td>\n   <td style=\"text-align:left;\"> POINT (2675117 232954.9) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 54th St &amp; Whitby Av </td>\n   <td style=\"text-align:left;\"> 124 </td>\n   <td style=\"text-align:right;\"> 137 </td>\n   <td style=\"text-align:right;\"> 57.2 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 79.8 </td>\n   <td style=\"text-align:left;\"> POINT (2675141 233000) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Whitby Av &amp; 53rd St - FS </td>\n   <td style=\"text-align:left;\"> 124 </td>\n   <td style=\"text-align:right;\"> 133 </td>\n   <td style=\"text-align:right;\"> 53.5 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 79.5 </td>\n   <td style=\"text-align:left;\"> POINT (2675326 233279) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Jefferson St &amp; 52nd St - FS </td>\n   <td style=\"text-align:left;\"> 193 </td>\n   <td style=\"text-align:right;\"> 176 </td>\n   <td style=\"text-align:right;\"> 98.9 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 77.1 </td>\n   <td style=\"text-align:left;\"> POINT (2675866 245528.4) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 52nd St &amp; Heston St </td>\n   <td style=\"text-align:left;\"> 193 </td>\n   <td style=\"text-align:right;\"> 176 </td>\n   <td style=\"text-align:right;\"> 98.9 </td>\n   <td style=\"text-align:right;font-weight: bold;color: white !important;background-color: rgba(215, 48, 39, 255) !important;\"> 77.1 </td>\n   <td style=\"text-align:left;\"> POINT (2675998 245602.9) </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup>  'Unexplained Excess' = Actual Crime minus Predicted Crime based on local environment. Positive values indicate specific local security failures.</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n-   Beyond general heatmaps, our model generates a granular \"Hit List\"\n    for immediate operational use. As detailed in the Top 10 Stops with\n    Highest Unexplained Crime Risk table, the intersection of Locust St\n    & 17th St stands out as the single most critical anomaly,\n    registering 96.8 excess crimes—incidents that simply cannot be\n    attributed to the surrounding built environment. Furthermore, we\n    observe a disturbing systemic pattern in Police Service Area (PSA)\n    124: it accounts for 5 of the top 10 riskiest locations,\n    particularly along the Whitby Ave and 54th St corridors. This\n    concentration suggests a localized failure in current patrol\n    strategies within PSA 124. We recommend an immediate \"security\n    audit\" for these ten specific coordinates to identify micro-level\n    drivers of risk—such as broken cameras, blind spots, or unmonitored\n    alcoves—that macro-level data might miss.\n\n## 7.3 Beyond Policing: CPTED Interventions for Long-term Safety\n\n-   Our model highlights that policing is not the only solution. Built\n    environment features, specifically Street Light Density and Housing\n    Vacancy, were significant predictors of crime risk. The significance\n    of vacancy rates supports the \"Broken Windows Theory\"—physical\n    disorder invites criminal activity. Therefore, we propose a\n    cross-departmental collaboration between SEPTA and the Philadelphia\n    Department of Streets to prioritize lighting upgrades and blight\n    remediation around high-risk bus stops. These \"Crime Prevention\n    Through Environmental Design\" (CPTED) interventions offer a\n    sustainable, non-punitive strategy to reduce crime risk without\n    increasing arrest rates.\n\n## 7.4 Equity Concern\n\n-   A major concern in crime modeling is the potential to stigmatize\n    disadvantaged communities. We addressed this by incorporating Census\n    Tract Fixed Effects (Phase 4) and controlling for poverty rates.\n    This ensures our model compares bus stops within the same\n    neighborhood context, rather than unfairly comparing a stop in North\n    Philadelphia to one in Center City. However, we acknowledge that our\n    final model still exhibits some spatial autocorrelation (Moran's I\n    $\\approx$ 0.29), indicating that unobserved spatial clusters remain.\n    While the Negative Binomial model effectively handles the\n    over-dispersed count data, future iterations should explore Bayesian\n    Spatial Models to fully resolve the complex spatial dependencies\n    inherent in urban crime data.\n",
    "supporting": [
      "Final_appendix_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}